{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oO2P0NBZEunO",
        "4RovX7MuE98J"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9a22c64b06141edbe686dc29d06d028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c49be1ab54794d04b188583ce7124036",
              "IPY_MODEL_cf48991eaf33427383e964fc76e423d4",
              "IPY_MODEL_d54d75bfacce46b1926f90002f126b16"
            ],
            "layout": "IPY_MODEL_68b57c65a4f24364bc7e4380df2b3b13"
          }
        },
        "c49be1ab54794d04b188583ce7124036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f643cf88a3f74cb0a09013d84f263ca1",
            "placeholder": "​",
            "style": "IPY_MODEL_e5ffad654df74a7a94b09f22e9eadc45",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cf48991eaf33427383e964fc76e423d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486a43d10114428591a22bee3b7a00a8",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e7f1cc474ab43b3809aa908e5210d0f",
            "value": 28
          }
        },
        "d54d75bfacce46b1926f90002f126b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1261128f770f4482b43e0b0c4c6b0ac0",
            "placeholder": "​",
            "style": "IPY_MODEL_73e780c81f434e158ff2ab4f0e4234fc",
            "value": " 28.0/28.0 [00:00&lt;00:00, 895B/s]"
          }
        },
        "68b57c65a4f24364bc7e4380df2b3b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f643cf88a3f74cb0a09013d84f263ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ffad654df74a7a94b09f22e9eadc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "486a43d10114428591a22bee3b7a00a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7f1cc474ab43b3809aa908e5210d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1261128f770f4482b43e0b0c4c6b0ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e780c81f434e158ff2ab4f0e4234fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e162764738c478d9a830c5585fc901f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7566224d76c45e6ab888905dfc603d7",
              "IPY_MODEL_294bbc4461824b4fab92a799cf08fbd3",
              "IPY_MODEL_2b580ba8096647ba9f68eb834c3dcde6"
            ],
            "layout": "IPY_MODEL_e0d44adad4ea4379b97b0ad93d093b61"
          }
        },
        "b7566224d76c45e6ab888905dfc603d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f38e051475b46f7bd4ff47acef1404e",
            "placeholder": "​",
            "style": "IPY_MODEL_47bf900c4c2a48b29a2f26bf0a01dd02",
            "value": "vocab.txt: 100%"
          }
        },
        "294bbc4461824b4fab92a799cf08fbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfaf5618ad894aacab459add8641171b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_280f8926a3204778b74c998bd4fa069d",
            "value": 231508
          }
        },
        "2b580ba8096647ba9f68eb834c3dcde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c073dab32afd4a3b92fd88d427307eec",
            "placeholder": "​",
            "style": "IPY_MODEL_1f114aef54844a1abc8164886a83b260",
            "value": " 232k/232k [00:00&lt;00:00, 2.83MB/s]"
          }
        },
        "e0d44adad4ea4379b97b0ad93d093b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f38e051475b46f7bd4ff47acef1404e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47bf900c4c2a48b29a2f26bf0a01dd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfaf5618ad894aacab459add8641171b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280f8926a3204778b74c998bd4fa069d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c073dab32afd4a3b92fd88d427307eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f114aef54844a1abc8164886a83b260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40435394a5f94025b5311ca60693da5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d10fa3c11df544eeac0dfa6f7a5d0ffd",
              "IPY_MODEL_cb72a77d742b4040950a278fa0c73976",
              "IPY_MODEL_4c424fcced874fd89cd8e867b882c300"
            ],
            "layout": "IPY_MODEL_d1936253308349c2b8ad0e35c81578e7"
          }
        },
        "d10fa3c11df544eeac0dfa6f7a5d0ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e090e26bbe14b34b24fbd7646e90788",
            "placeholder": "​",
            "style": "IPY_MODEL_a900f3ccb82a4d6bbb7787127e06ef04",
            "value": "tokenizer.json: 100%"
          }
        },
        "cb72a77d742b4040950a278fa0c73976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f754bb55c646c99068ce6446b44567",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2420b75ac817412b9a5dc4931386b3b8",
            "value": 466062
          }
        },
        "4c424fcced874fd89cd8e867b882c300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92058f0564364aedb3c637109dd4808d",
            "placeholder": "​",
            "style": "IPY_MODEL_f9abb8dbd3c24ed3b0151b40dfed4b57",
            "value": " 466k/466k [00:00&lt;00:00, 5.61MB/s]"
          }
        },
        "d1936253308349c2b8ad0e35c81578e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e090e26bbe14b34b24fbd7646e90788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a900f3ccb82a4d6bbb7787127e06ef04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57f754bb55c646c99068ce6446b44567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2420b75ac817412b9a5dc4931386b3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92058f0564364aedb3c637109dd4808d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9abb8dbd3c24ed3b0151b40dfed4b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea436f033a134d7d91d536cd016d6843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d452b46cd74d4f9b8a05e5a3726288c0",
              "IPY_MODEL_8c215a878a4c4dd386e33da55652980f",
              "IPY_MODEL_c81e0d0cdab04a6bb3ce4dc8630f8cbf"
            ],
            "layout": "IPY_MODEL_65e85103a11d45cf98510e8aad2f93a1"
          }
        },
        "d452b46cd74d4f9b8a05e5a3726288c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256d9800982d47179e212efc477f2c96",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e34dad963d46d4915faf667168cd29",
            "value": "config.json: 100%"
          }
        },
        "8c215a878a4c4dd386e33da55652980f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75aa27a4aec54348873ab4fbd9e13809",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03bbc37be5dd42ecb17a34fd64460786",
            "value": 570
          }
        },
        "c81e0d0cdab04a6bb3ce4dc8630f8cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea819c94b5214130b18aac9889e96259",
            "placeholder": "​",
            "style": "IPY_MODEL_066e1776ae724343ab35bd136549e5a9",
            "value": " 570/570 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "65e85103a11d45cf98510e8aad2f93a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256d9800982d47179e212efc477f2c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e34dad963d46d4915faf667168cd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75aa27a4aec54348873ab4fbd9e13809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03bbc37be5dd42ecb17a34fd64460786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea819c94b5214130b18aac9889e96259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066e1776ae724343ab35bd136549e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a73dfd3223242d4821aa391cb95eebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb41d7d4eb3e4191aa00b27eeb2fcb67",
              "IPY_MODEL_8aede05e2a6c4b31a05d45daef5f3d04",
              "IPY_MODEL_e5ca1c1b84674afc80ff0eaf167045ef"
            ],
            "layout": "IPY_MODEL_2cee6c9de04242868941dd42cb502559"
          }
        },
        "fb41d7d4eb3e4191aa00b27eeb2fcb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f03c13aa36c41c3b62130f757686d56",
            "placeholder": "​",
            "style": "IPY_MODEL_c48222c7cc0149508a90b137417f342f",
            "value": "model.safetensors: 100%"
          }
        },
        "8aede05e2a6c4b31a05d45daef5f3d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ddb4c0a3a248e48843e1919639ad35",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b8b767e9803401cb90e693b1895c92a",
            "value": 440449768
          }
        },
        "e5ca1c1b84674afc80ff0eaf167045ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf190e37d694d569d63472513038b9e",
            "placeholder": "​",
            "style": "IPY_MODEL_1dde8f0620654c10a23b374f6a6e812e",
            "value": " 440M/440M [00:02&lt;00:00, 180MB/s]"
          }
        },
        "2cee6c9de04242868941dd42cb502559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f03c13aa36c41c3b62130f757686d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48222c7cc0149508a90b137417f342f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34ddb4c0a3a248e48843e1919639ad35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8b767e9803401cb90e693b1895c92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdf190e37d694d569d63472513038b9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dde8f0620654c10a23b374f6a6e812e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classifying  Textual  Data  with  pretrained  Vision  Models through  Transfer  Learning  and  Data Transformations"
      ],
      "metadata": {
        "id": "VDTtnrRUlXxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For implementation of the paper, I used the codes in the author github repository:\n",
        "\n",
        "https://github.com/EddCBen/Classifying-Textual-Data-with-pretrained-Vision-Models-through-Transfer-Learning-and-Data-Transforms"
      ],
      "metadata": {
        "id": "5FbzC8sXlo1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Embeddings for Reviews"
      ],
      "metadata": {
        "id": "EXX-Jbkq_mdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first, we want to generate representations for IMDB dataset using the last six layers of\n",
        "pre-trained BERT-base model:"
      ],
      "metadata": {
        "id": "Y4uob-IcK-kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "fSrRLxRDK-QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "imdb_path = Path(\"/content/drive/MyDrive/IMDB\")\n",
        "df = pd.read_csv(imdb_path / 'IMDB Dataset.csv')\n",
        "sentences = df['review']"
      ],
      "metadata": {
        "id": "xEsPXEZ9Le0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bertModel = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "bertModel.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9a22c64b06141edbe686dc29d06d028",
            "c49be1ab54794d04b188583ce7124036",
            "cf48991eaf33427383e964fc76e423d4",
            "d54d75bfacce46b1926f90002f126b16",
            "68b57c65a4f24364bc7e4380df2b3b13",
            "f643cf88a3f74cb0a09013d84f263ca1",
            "e5ffad654df74a7a94b09f22e9eadc45",
            "486a43d10114428591a22bee3b7a00a8",
            "0e7f1cc474ab43b3809aa908e5210d0f",
            "1261128f770f4482b43e0b0c4c6b0ac0",
            "73e780c81f434e158ff2ab4f0e4234fc",
            "2e162764738c478d9a830c5585fc901f",
            "b7566224d76c45e6ab888905dfc603d7",
            "294bbc4461824b4fab92a799cf08fbd3",
            "2b580ba8096647ba9f68eb834c3dcde6",
            "e0d44adad4ea4379b97b0ad93d093b61",
            "1f38e051475b46f7bd4ff47acef1404e",
            "47bf900c4c2a48b29a2f26bf0a01dd02",
            "bfaf5618ad894aacab459add8641171b",
            "280f8926a3204778b74c998bd4fa069d",
            "c073dab32afd4a3b92fd88d427307eec",
            "1f114aef54844a1abc8164886a83b260",
            "40435394a5f94025b5311ca60693da5f",
            "d10fa3c11df544eeac0dfa6f7a5d0ffd",
            "cb72a77d742b4040950a278fa0c73976",
            "4c424fcced874fd89cd8e867b882c300",
            "d1936253308349c2b8ad0e35c81578e7",
            "3e090e26bbe14b34b24fbd7646e90788",
            "a900f3ccb82a4d6bbb7787127e06ef04",
            "57f754bb55c646c99068ce6446b44567",
            "2420b75ac817412b9a5dc4931386b3b8",
            "92058f0564364aedb3c637109dd4808d",
            "f9abb8dbd3c24ed3b0151b40dfed4b57",
            "ea436f033a134d7d91d536cd016d6843",
            "d452b46cd74d4f9b8a05e5a3726288c0",
            "8c215a878a4c4dd386e33da55652980f",
            "c81e0d0cdab04a6bb3ce4dc8630f8cbf",
            "65e85103a11d45cf98510e8aad2f93a1",
            "256d9800982d47179e212efc477f2c96",
            "a2e34dad963d46d4915faf667168cd29",
            "75aa27a4aec54348873ab4fbd9e13809",
            "03bbc37be5dd42ecb17a34fd64460786",
            "ea819c94b5214130b18aac9889e96259",
            "066e1776ae724343ab35bd136549e5a9",
            "2a73dfd3223242d4821aa391cb95eebf",
            "fb41d7d4eb3e4191aa00b27eeb2fcb67",
            "8aede05e2a6c4b31a05d45daef5f3d04",
            "e5ca1c1b84674afc80ff0eaf167045ef",
            "2cee6c9de04242868941dd42cb502559",
            "5f03c13aa36c41c3b62130f757686d56",
            "c48222c7cc0149508a90b137417f342f",
            "34ddb4c0a3a248e48843e1919639ad35",
            "8b8b767e9803401cb90e693b1895c92a",
            "fdf190e37d694d569d63472513038b9e",
            "1dde8f0620654c10a23b374f6a6e812e"
          ]
        },
        "id": "Tn80fMdvMA0I",
        "outputId": "5edec10e-b4b7-4af8-ea20-bed6be259100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9a22c64b06141edbe686dc29d06d028"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e162764738c478d9a830c5585fc901f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40435394a5f94025b5311ca60693da5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea436f033a134d7d91d536cd016d6843"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a73dfd3223242d4821aa391cb95eebf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding and getting text embeddings from last 6 layers of BERT\n",
        "data_list = []\n",
        "for counter, sent in enumerate(sentences):\n",
        "    print(\"Embedding number : {}\".format(counter))\n",
        "    cls_12layers = []\n",
        "    encoded_sent = tokenizer.encode_plus(\n",
        "                                    sent,\n",
        "                                    add_special_tokens = True,\n",
        "                                    max_length = 512,\n",
        "                                    padding = 'longest',\n",
        "                                    truncation = True,\n",
        "                                    return_attention_mask = True,\n",
        "                                    return_tensors = 'pt',\n",
        "                                    return_length = True\n",
        "                                    )\n",
        "    with torch.no_grad():\n",
        "        bertModel.eval()\n",
        "        output = bertModel.cuda()(encoded_sent['input_ids'].to(torch.device(\"cuda\")))\n",
        "    hidden_states = output.hidden_states[6:]\n",
        "\n",
        "    for i,_ in enumerate(hidden_states):\n",
        "        # output size : 6 * 768\n",
        "        cls_12layers.append(hidden_states[i].squeeze()[0].cpu())\n",
        "    cls_12layers = torch.stack(cls_12layers)\n",
        "    data_list.append(cls_12layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQZPvIXgMLBA",
        "outputId": "286b3a04-d4f5-4ab9-894d-82b7640747bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Embedding number : 45000\n",
            "Embedding number : 45001\n",
            "Embedding number : 45002\n",
            "Embedding number : 45003\n",
            "Embedding number : 45004\n",
            "Embedding number : 45005\n",
            "Embedding number : 45006\n",
            "Embedding number : 45007\n",
            "Embedding number : 45008\n",
            "Embedding number : 45009\n",
            "Embedding number : 45010\n",
            "Embedding number : 45011\n",
            "Embedding number : 45012\n",
            "Embedding number : 45013\n",
            "Embedding number : 45014\n",
            "Embedding number : 45015\n",
            "Embedding number : 45016\n",
            "Embedding number : 45017\n",
            "Embedding number : 45018\n",
            "Embedding number : 45019\n",
            "Embedding number : 45020\n",
            "Embedding number : 45021\n",
            "Embedding number : 45022\n",
            "Embedding number : 45023\n",
            "Embedding number : 45024\n",
            "Embedding number : 45025\n",
            "Embedding number : 45026\n",
            "Embedding number : 45027\n",
            "Embedding number : 45028\n",
            "Embedding number : 45029\n",
            "Embedding number : 45030\n",
            "Embedding number : 45031\n",
            "Embedding number : 45032\n",
            "Embedding number : 45033\n",
            "Embedding number : 45034\n",
            "Embedding number : 45035\n",
            "Embedding number : 45036\n",
            "Embedding number : 45037\n",
            "Embedding number : 45038\n",
            "Embedding number : 45039\n",
            "Embedding number : 45040\n",
            "Embedding number : 45041\n",
            "Embedding number : 45042\n",
            "Embedding number : 45043\n",
            "Embedding number : 45044\n",
            "Embedding number : 45045\n",
            "Embedding number : 45046\n",
            "Embedding number : 45047\n",
            "Embedding number : 45048\n",
            "Embedding number : 45049\n",
            "Embedding number : 45050\n",
            "Embedding number : 45051\n",
            "Embedding number : 45052\n",
            "Embedding number : 45053\n",
            "Embedding number : 45054\n",
            "Embedding number : 45055\n",
            "Embedding number : 45056\n",
            "Embedding number : 45057\n",
            "Embedding number : 45058\n",
            "Embedding number : 45059\n",
            "Embedding number : 45060\n",
            "Embedding number : 45061\n",
            "Embedding number : 45062\n",
            "Embedding number : 45063\n",
            "Embedding number : 45064\n",
            "Embedding number : 45065\n",
            "Embedding number : 45066\n",
            "Embedding number : 45067\n",
            "Embedding number : 45068\n",
            "Embedding number : 45069\n",
            "Embedding number : 45070\n",
            "Embedding number : 45071\n",
            "Embedding number : 45072\n",
            "Embedding number : 45073\n",
            "Embedding number : 45074\n",
            "Embedding number : 45075\n",
            "Embedding number : 45076\n",
            "Embedding number : 45077\n",
            "Embedding number : 45078\n",
            "Embedding number : 45079\n",
            "Embedding number : 45080\n",
            "Embedding number : 45081\n",
            "Embedding number : 45082\n",
            "Embedding number : 45083\n",
            "Embedding number : 45084\n",
            "Embedding number : 45085\n",
            "Embedding number : 45086\n",
            "Embedding number : 45087\n",
            "Embedding number : 45088\n",
            "Embedding number : 45089\n",
            "Embedding number : 45090\n",
            "Embedding number : 45091\n",
            "Embedding number : 45092\n",
            "Embedding number : 45093\n",
            "Embedding number : 45094\n",
            "Embedding number : 45095\n",
            "Embedding number : 45096\n",
            "Embedding number : 45097\n",
            "Embedding number : 45098\n",
            "Embedding number : 45099\n",
            "Embedding number : 45100\n",
            "Embedding number : 45101\n",
            "Embedding number : 45102\n",
            "Embedding number : 45103\n",
            "Embedding number : 45104\n",
            "Embedding number : 45105\n",
            "Embedding number : 45106\n",
            "Embedding number : 45107\n",
            "Embedding number : 45108\n",
            "Embedding number : 45109\n",
            "Embedding number : 45110\n",
            "Embedding number : 45111\n",
            "Embedding number : 45112\n",
            "Embedding number : 45113\n",
            "Embedding number : 45114\n",
            "Embedding number : 45115\n",
            "Embedding number : 45116\n",
            "Embedding number : 45117\n",
            "Embedding number : 45118\n",
            "Embedding number : 45119\n",
            "Embedding number : 45120\n",
            "Embedding number : 45121\n",
            "Embedding number : 45122\n",
            "Embedding number : 45123\n",
            "Embedding number : 45124\n",
            "Embedding number : 45125\n",
            "Embedding number : 45126\n",
            "Embedding number : 45127\n",
            "Embedding number : 45128\n",
            "Embedding number : 45129\n",
            "Embedding number : 45130\n",
            "Embedding number : 45131\n",
            "Embedding number : 45132\n",
            "Embedding number : 45133\n",
            "Embedding number : 45134\n",
            "Embedding number : 45135\n",
            "Embedding number : 45136\n",
            "Embedding number : 45137\n",
            "Embedding number : 45138\n",
            "Embedding number : 45139\n",
            "Embedding number : 45140\n",
            "Embedding number : 45141\n",
            "Embedding number : 45142\n",
            "Embedding number : 45143\n",
            "Embedding number : 45144\n",
            "Embedding number : 45145\n",
            "Embedding number : 45146\n",
            "Embedding number : 45147\n",
            "Embedding number : 45148\n",
            "Embedding number : 45149\n",
            "Embedding number : 45150\n",
            "Embedding number : 45151\n",
            "Embedding number : 45152\n",
            "Embedding number : 45153\n",
            "Embedding number : 45154\n",
            "Embedding number : 45155\n",
            "Embedding number : 45156\n",
            "Embedding number : 45157\n",
            "Embedding number : 45158\n",
            "Embedding number : 45159\n",
            "Embedding number : 45160\n",
            "Embedding number : 45161\n",
            "Embedding number : 45162\n",
            "Embedding number : 45163\n",
            "Embedding number : 45164\n",
            "Embedding number : 45165\n",
            "Embedding number : 45166\n",
            "Embedding number : 45167\n",
            "Embedding number : 45168\n",
            "Embedding number : 45169\n",
            "Embedding number : 45170\n",
            "Embedding number : 45171\n",
            "Embedding number : 45172\n",
            "Embedding number : 45173\n",
            "Embedding number : 45174\n",
            "Embedding number : 45175\n",
            "Embedding number : 45176\n",
            "Embedding number : 45177\n",
            "Embedding number : 45178\n",
            "Embedding number : 45179\n",
            "Embedding number : 45180\n",
            "Embedding number : 45181\n",
            "Embedding number : 45182\n",
            "Embedding number : 45183\n",
            "Embedding number : 45184\n",
            "Embedding number : 45185\n",
            "Embedding number : 45186\n",
            "Embedding number : 45187\n",
            "Embedding number : 45188\n",
            "Embedding number : 45189\n",
            "Embedding number : 45190\n",
            "Embedding number : 45191\n",
            "Embedding number : 45192\n",
            "Embedding number : 45193\n",
            "Embedding number : 45194\n",
            "Embedding number : 45195\n",
            "Embedding number : 45196\n",
            "Embedding number : 45197\n",
            "Embedding number : 45198\n",
            "Embedding number : 45199\n",
            "Embedding number : 45200\n",
            "Embedding number : 45201\n",
            "Embedding number : 45202\n",
            "Embedding number : 45203\n",
            "Embedding number : 45204\n",
            "Embedding number : 45205\n",
            "Embedding number : 45206\n",
            "Embedding number : 45207\n",
            "Embedding number : 45208\n",
            "Embedding number : 45209\n",
            "Embedding number : 45210\n",
            "Embedding number : 45211\n",
            "Embedding number : 45212\n",
            "Embedding number : 45213\n",
            "Embedding number : 45214\n",
            "Embedding number : 45215\n",
            "Embedding number : 45216\n",
            "Embedding number : 45217\n",
            "Embedding number : 45218\n",
            "Embedding number : 45219\n",
            "Embedding number : 45220\n",
            "Embedding number : 45221\n",
            "Embedding number : 45222\n",
            "Embedding number : 45223\n",
            "Embedding number : 45224\n",
            "Embedding number : 45225\n",
            "Embedding number : 45226\n",
            "Embedding number : 45227\n",
            "Embedding number : 45228\n",
            "Embedding number : 45229\n",
            "Embedding number : 45230\n",
            "Embedding number : 45231\n",
            "Embedding number : 45232\n",
            "Embedding number : 45233\n",
            "Embedding number : 45234\n",
            "Embedding number : 45235\n",
            "Embedding number : 45236\n",
            "Embedding number : 45237\n",
            "Embedding number : 45238\n",
            "Embedding number : 45239\n",
            "Embedding number : 45240\n",
            "Embedding number : 45241\n",
            "Embedding number : 45242\n",
            "Embedding number : 45243\n",
            "Embedding number : 45244\n",
            "Embedding number : 45245\n",
            "Embedding number : 45246\n",
            "Embedding number : 45247\n",
            "Embedding number : 45248\n",
            "Embedding number : 45249\n",
            "Embedding number : 45250\n",
            "Embedding number : 45251\n",
            "Embedding number : 45252\n",
            "Embedding number : 45253\n",
            "Embedding number : 45254\n",
            "Embedding number : 45255\n",
            "Embedding number : 45256\n",
            "Embedding number : 45257\n",
            "Embedding number : 45258\n",
            "Embedding number : 45259\n",
            "Embedding number : 45260\n",
            "Embedding number : 45261\n",
            "Embedding number : 45262\n",
            "Embedding number : 45263\n",
            "Embedding number : 45264\n",
            "Embedding number : 45265\n",
            "Embedding number : 45266\n",
            "Embedding number : 45267\n",
            "Embedding number : 45268\n",
            "Embedding number : 45269\n",
            "Embedding number : 45270\n",
            "Embedding number : 45271\n",
            "Embedding number : 45272\n",
            "Embedding number : 45273\n",
            "Embedding number : 45274\n",
            "Embedding number : 45275\n",
            "Embedding number : 45276\n",
            "Embedding number : 45277\n",
            "Embedding number : 45278\n",
            "Embedding number : 45279\n",
            "Embedding number : 45280\n",
            "Embedding number : 45281\n",
            "Embedding number : 45282\n",
            "Embedding number : 45283\n",
            "Embedding number : 45284\n",
            "Embedding number : 45285\n",
            "Embedding number : 45286\n",
            "Embedding number : 45287\n",
            "Embedding number : 45288\n",
            "Embedding number : 45289\n",
            "Embedding number : 45290\n",
            "Embedding number : 45291\n",
            "Embedding number : 45292\n",
            "Embedding number : 45293\n",
            "Embedding number : 45294\n",
            "Embedding number : 45295\n",
            "Embedding number : 45296\n",
            "Embedding number : 45297\n",
            "Embedding number : 45298\n",
            "Embedding number : 45299\n",
            "Embedding number : 45300\n",
            "Embedding number : 45301\n",
            "Embedding number : 45302\n",
            "Embedding number : 45303\n",
            "Embedding number : 45304\n",
            "Embedding number : 45305\n",
            "Embedding number : 45306\n",
            "Embedding number : 45307\n",
            "Embedding number : 45308\n",
            "Embedding number : 45309\n",
            "Embedding number : 45310\n",
            "Embedding number : 45311\n",
            "Embedding number : 45312\n",
            "Embedding number : 45313\n",
            "Embedding number : 45314\n",
            "Embedding number : 45315\n",
            "Embedding number : 45316\n",
            "Embedding number : 45317\n",
            "Embedding number : 45318\n",
            "Embedding number : 45319\n",
            "Embedding number : 45320\n",
            "Embedding number : 45321\n",
            "Embedding number : 45322\n",
            "Embedding number : 45323\n",
            "Embedding number : 45324\n",
            "Embedding number : 45325\n",
            "Embedding number : 45326\n",
            "Embedding number : 45327\n",
            "Embedding number : 45328\n",
            "Embedding number : 45329\n",
            "Embedding number : 45330\n",
            "Embedding number : 45331\n",
            "Embedding number : 45332\n",
            "Embedding number : 45333\n",
            "Embedding number : 45334\n",
            "Embedding number : 45335\n",
            "Embedding number : 45336\n",
            "Embedding number : 45337\n",
            "Embedding number : 45338\n",
            "Embedding number : 45339\n",
            "Embedding number : 45340\n",
            "Embedding number : 45341\n",
            "Embedding number : 45342\n",
            "Embedding number : 45343\n",
            "Embedding number : 45344\n",
            "Embedding number : 45345\n",
            "Embedding number : 45346\n",
            "Embedding number : 45347\n",
            "Embedding number : 45348\n",
            "Embedding number : 45349\n",
            "Embedding number : 45350\n",
            "Embedding number : 45351\n",
            "Embedding number : 45352\n",
            "Embedding number : 45353\n",
            "Embedding number : 45354\n",
            "Embedding number : 45355\n",
            "Embedding number : 45356\n",
            "Embedding number : 45357\n",
            "Embedding number : 45358\n",
            "Embedding number : 45359\n",
            "Embedding number : 45360\n",
            "Embedding number : 45361\n",
            "Embedding number : 45362\n",
            "Embedding number : 45363\n",
            "Embedding number : 45364\n",
            "Embedding number : 45365\n",
            "Embedding number : 45366\n",
            "Embedding number : 45367\n",
            "Embedding number : 45368\n",
            "Embedding number : 45369\n",
            "Embedding number : 45370\n",
            "Embedding number : 45371\n",
            "Embedding number : 45372\n",
            "Embedding number : 45373\n",
            "Embedding number : 45374\n",
            "Embedding number : 45375\n",
            "Embedding number : 45376\n",
            "Embedding number : 45377\n",
            "Embedding number : 45378\n",
            "Embedding number : 45379\n",
            "Embedding number : 45380\n",
            "Embedding number : 45381\n",
            "Embedding number : 45382\n",
            "Embedding number : 45383\n",
            "Embedding number : 45384\n",
            "Embedding number : 45385\n",
            "Embedding number : 45386\n",
            "Embedding number : 45387\n",
            "Embedding number : 45388\n",
            "Embedding number : 45389\n",
            "Embedding number : 45390\n",
            "Embedding number : 45391\n",
            "Embedding number : 45392\n",
            "Embedding number : 45393\n",
            "Embedding number : 45394\n",
            "Embedding number : 45395\n",
            "Embedding number : 45396\n",
            "Embedding number : 45397\n",
            "Embedding number : 45398\n",
            "Embedding number : 45399\n",
            "Embedding number : 45400\n",
            "Embedding number : 45401\n",
            "Embedding number : 45402\n",
            "Embedding number : 45403\n",
            "Embedding number : 45404\n",
            "Embedding number : 45405\n",
            "Embedding number : 45406\n",
            "Embedding number : 45407\n",
            "Embedding number : 45408\n",
            "Embedding number : 45409\n",
            "Embedding number : 45410\n",
            "Embedding number : 45411\n",
            "Embedding number : 45412\n",
            "Embedding number : 45413\n",
            "Embedding number : 45414\n",
            "Embedding number : 45415\n",
            "Embedding number : 45416\n",
            "Embedding number : 45417\n",
            "Embedding number : 45418\n",
            "Embedding number : 45419\n",
            "Embedding number : 45420\n",
            "Embedding number : 45421\n",
            "Embedding number : 45422\n",
            "Embedding number : 45423\n",
            "Embedding number : 45424\n",
            "Embedding number : 45425\n",
            "Embedding number : 45426\n",
            "Embedding number : 45427\n",
            "Embedding number : 45428\n",
            "Embedding number : 45429\n",
            "Embedding number : 45430\n",
            "Embedding number : 45431\n",
            "Embedding number : 45432\n",
            "Embedding number : 45433\n",
            "Embedding number : 45434\n",
            "Embedding number : 45435\n",
            "Embedding number : 45436\n",
            "Embedding number : 45437\n",
            "Embedding number : 45438\n",
            "Embedding number : 45439\n",
            "Embedding number : 45440\n",
            "Embedding number : 45441\n",
            "Embedding number : 45442\n",
            "Embedding number : 45443\n",
            "Embedding number : 45444\n",
            "Embedding number : 45445\n",
            "Embedding number : 45446\n",
            "Embedding number : 45447\n",
            "Embedding number : 45448\n",
            "Embedding number : 45449\n",
            "Embedding number : 45450\n",
            "Embedding number : 45451\n",
            "Embedding number : 45452\n",
            "Embedding number : 45453\n",
            "Embedding number : 45454\n",
            "Embedding number : 45455\n",
            "Embedding number : 45456\n",
            "Embedding number : 45457\n",
            "Embedding number : 45458\n",
            "Embedding number : 45459\n",
            "Embedding number : 45460\n",
            "Embedding number : 45461\n",
            "Embedding number : 45462\n",
            "Embedding number : 45463\n",
            "Embedding number : 45464\n",
            "Embedding number : 45465\n",
            "Embedding number : 45466\n",
            "Embedding number : 45467\n",
            "Embedding number : 45468\n",
            "Embedding number : 45469\n",
            "Embedding number : 45470\n",
            "Embedding number : 45471\n",
            "Embedding number : 45472\n",
            "Embedding number : 45473\n",
            "Embedding number : 45474\n",
            "Embedding number : 45475\n",
            "Embedding number : 45476\n",
            "Embedding number : 45477\n",
            "Embedding number : 45478\n",
            "Embedding number : 45479\n",
            "Embedding number : 45480\n",
            "Embedding number : 45481\n",
            "Embedding number : 45482\n",
            "Embedding number : 45483\n",
            "Embedding number : 45484\n",
            "Embedding number : 45485\n",
            "Embedding number : 45486\n",
            "Embedding number : 45487\n",
            "Embedding number : 45488\n",
            "Embedding number : 45489\n",
            "Embedding number : 45490\n",
            "Embedding number : 45491\n",
            "Embedding number : 45492\n",
            "Embedding number : 45493\n",
            "Embedding number : 45494\n",
            "Embedding number : 45495\n",
            "Embedding number : 45496\n",
            "Embedding number : 45497\n",
            "Embedding number : 45498\n",
            "Embedding number : 45499\n",
            "Embedding number : 45500\n",
            "Embedding number : 45501\n",
            "Embedding number : 45502\n",
            "Embedding number : 45503\n",
            "Embedding number : 45504\n",
            "Embedding number : 45505\n",
            "Embedding number : 45506\n",
            "Embedding number : 45507\n",
            "Embedding number : 45508\n",
            "Embedding number : 45509\n",
            "Embedding number : 45510\n",
            "Embedding number : 45511\n",
            "Embedding number : 45512\n",
            "Embedding number : 45513\n",
            "Embedding number : 45514\n",
            "Embedding number : 45515\n",
            "Embedding number : 45516\n",
            "Embedding number : 45517\n",
            "Embedding number : 45518\n",
            "Embedding number : 45519\n",
            "Embedding number : 45520\n",
            "Embedding number : 45521\n",
            "Embedding number : 45522\n",
            "Embedding number : 45523\n",
            "Embedding number : 45524\n",
            "Embedding number : 45525\n",
            "Embedding number : 45526\n",
            "Embedding number : 45527\n",
            "Embedding number : 45528\n",
            "Embedding number : 45529\n",
            "Embedding number : 45530\n",
            "Embedding number : 45531\n",
            "Embedding number : 45532\n",
            "Embedding number : 45533\n",
            "Embedding number : 45534\n",
            "Embedding number : 45535\n",
            "Embedding number : 45536\n",
            "Embedding number : 45537\n",
            "Embedding number : 45538\n",
            "Embedding number : 45539\n",
            "Embedding number : 45540\n",
            "Embedding number : 45541\n",
            "Embedding number : 45542\n",
            "Embedding number : 45543\n",
            "Embedding number : 45544\n",
            "Embedding number : 45545\n",
            "Embedding number : 45546\n",
            "Embedding number : 45547\n",
            "Embedding number : 45548\n",
            "Embedding number : 45549\n",
            "Embedding number : 45550\n",
            "Embedding number : 45551\n",
            "Embedding number : 45552\n",
            "Embedding number : 45553\n",
            "Embedding number : 45554\n",
            "Embedding number : 45555\n",
            "Embedding number : 45556\n",
            "Embedding number : 45557\n",
            "Embedding number : 45558\n",
            "Embedding number : 45559\n",
            "Embedding number : 45560\n",
            "Embedding number : 45561\n",
            "Embedding number : 45562\n",
            "Embedding number : 45563\n",
            "Embedding number : 45564\n",
            "Embedding number : 45565\n",
            "Embedding number : 45566\n",
            "Embedding number : 45567\n",
            "Embedding number : 45568\n",
            "Embedding number : 45569\n",
            "Embedding number : 45570\n",
            "Embedding number : 45571\n",
            "Embedding number : 45572\n",
            "Embedding number : 45573\n",
            "Embedding number : 45574\n",
            "Embedding number : 45575\n",
            "Embedding number : 45576\n",
            "Embedding number : 45577\n",
            "Embedding number : 45578\n",
            "Embedding number : 45579\n",
            "Embedding number : 45580\n",
            "Embedding number : 45581\n",
            "Embedding number : 45582\n",
            "Embedding number : 45583\n",
            "Embedding number : 45584\n",
            "Embedding number : 45585\n",
            "Embedding number : 45586\n",
            "Embedding number : 45587\n",
            "Embedding number : 45588\n",
            "Embedding number : 45589\n",
            "Embedding number : 45590\n",
            "Embedding number : 45591\n",
            "Embedding number : 45592\n",
            "Embedding number : 45593\n",
            "Embedding number : 45594\n",
            "Embedding number : 45595\n",
            "Embedding number : 45596\n",
            "Embedding number : 45597\n",
            "Embedding number : 45598\n",
            "Embedding number : 45599\n",
            "Embedding number : 45600\n",
            "Embedding number : 45601\n",
            "Embedding number : 45602\n",
            "Embedding number : 45603\n",
            "Embedding number : 45604\n",
            "Embedding number : 45605\n",
            "Embedding number : 45606\n",
            "Embedding number : 45607\n",
            "Embedding number : 45608\n",
            "Embedding number : 45609\n",
            "Embedding number : 45610\n",
            "Embedding number : 45611\n",
            "Embedding number : 45612\n",
            "Embedding number : 45613\n",
            "Embedding number : 45614\n",
            "Embedding number : 45615\n",
            "Embedding number : 45616\n",
            "Embedding number : 45617\n",
            "Embedding number : 45618\n",
            "Embedding number : 45619\n",
            "Embedding number : 45620\n",
            "Embedding number : 45621\n",
            "Embedding number : 45622\n",
            "Embedding number : 45623\n",
            "Embedding number : 45624\n",
            "Embedding number : 45625\n",
            "Embedding number : 45626\n",
            "Embedding number : 45627\n",
            "Embedding number : 45628\n",
            "Embedding number : 45629\n",
            "Embedding number : 45630\n",
            "Embedding number : 45631\n",
            "Embedding number : 45632\n",
            "Embedding number : 45633\n",
            "Embedding number : 45634\n",
            "Embedding number : 45635\n",
            "Embedding number : 45636\n",
            "Embedding number : 45637\n",
            "Embedding number : 45638\n",
            "Embedding number : 45639\n",
            "Embedding number : 45640\n",
            "Embedding number : 45641\n",
            "Embedding number : 45642\n",
            "Embedding number : 45643\n",
            "Embedding number : 45644\n",
            "Embedding number : 45645\n",
            "Embedding number : 45646\n",
            "Embedding number : 45647\n",
            "Embedding number : 45648\n",
            "Embedding number : 45649\n",
            "Embedding number : 45650\n",
            "Embedding number : 45651\n",
            "Embedding number : 45652\n",
            "Embedding number : 45653\n",
            "Embedding number : 45654\n",
            "Embedding number : 45655\n",
            "Embedding number : 45656\n",
            "Embedding number : 45657\n",
            "Embedding number : 45658\n",
            "Embedding number : 45659\n",
            "Embedding number : 45660\n",
            "Embedding number : 45661\n",
            "Embedding number : 45662\n",
            "Embedding number : 45663\n",
            "Embedding number : 45664\n",
            "Embedding number : 45665\n",
            "Embedding number : 45666\n",
            "Embedding number : 45667\n",
            "Embedding number : 45668\n",
            "Embedding number : 45669\n",
            "Embedding number : 45670\n",
            "Embedding number : 45671\n",
            "Embedding number : 45672\n",
            "Embedding number : 45673\n",
            "Embedding number : 45674\n",
            "Embedding number : 45675\n",
            "Embedding number : 45676\n",
            "Embedding number : 45677\n",
            "Embedding number : 45678\n",
            "Embedding number : 45679\n",
            "Embedding number : 45680\n",
            "Embedding number : 45681\n",
            "Embedding number : 45682\n",
            "Embedding number : 45683\n",
            "Embedding number : 45684\n",
            "Embedding number : 45685\n",
            "Embedding number : 45686\n",
            "Embedding number : 45687\n",
            "Embedding number : 45688\n",
            "Embedding number : 45689\n",
            "Embedding number : 45690\n",
            "Embedding number : 45691\n",
            "Embedding number : 45692\n",
            "Embedding number : 45693\n",
            "Embedding number : 45694\n",
            "Embedding number : 45695\n",
            "Embedding number : 45696\n",
            "Embedding number : 45697\n",
            "Embedding number : 45698\n",
            "Embedding number : 45699\n",
            "Embedding number : 45700\n",
            "Embedding number : 45701\n",
            "Embedding number : 45702\n",
            "Embedding number : 45703\n",
            "Embedding number : 45704\n",
            "Embedding number : 45705\n",
            "Embedding number : 45706\n",
            "Embedding number : 45707\n",
            "Embedding number : 45708\n",
            "Embedding number : 45709\n",
            "Embedding number : 45710\n",
            "Embedding number : 45711\n",
            "Embedding number : 45712\n",
            "Embedding number : 45713\n",
            "Embedding number : 45714\n",
            "Embedding number : 45715\n",
            "Embedding number : 45716\n",
            "Embedding number : 45717\n",
            "Embedding number : 45718\n",
            "Embedding number : 45719\n",
            "Embedding number : 45720\n",
            "Embedding number : 45721\n",
            "Embedding number : 45722\n",
            "Embedding number : 45723\n",
            "Embedding number : 45724\n",
            "Embedding number : 45725\n",
            "Embedding number : 45726\n",
            "Embedding number : 45727\n",
            "Embedding number : 45728\n",
            "Embedding number : 45729\n",
            "Embedding number : 45730\n",
            "Embedding number : 45731\n",
            "Embedding number : 45732\n",
            "Embedding number : 45733\n",
            "Embedding number : 45734\n",
            "Embedding number : 45735\n",
            "Embedding number : 45736\n",
            "Embedding number : 45737\n",
            "Embedding number : 45738\n",
            "Embedding number : 45739\n",
            "Embedding number : 45740\n",
            "Embedding number : 45741\n",
            "Embedding number : 45742\n",
            "Embedding number : 45743\n",
            "Embedding number : 45744\n",
            "Embedding number : 45745\n",
            "Embedding number : 45746\n",
            "Embedding number : 45747\n",
            "Embedding number : 45748\n",
            "Embedding number : 45749\n",
            "Embedding number : 45750\n",
            "Embedding number : 45751\n",
            "Embedding number : 45752\n",
            "Embedding number : 45753\n",
            "Embedding number : 45754\n",
            "Embedding number : 45755\n",
            "Embedding number : 45756\n",
            "Embedding number : 45757\n",
            "Embedding number : 45758\n",
            "Embedding number : 45759\n",
            "Embedding number : 45760\n",
            "Embedding number : 45761\n",
            "Embedding number : 45762\n",
            "Embedding number : 45763\n",
            "Embedding number : 45764\n",
            "Embedding number : 45765\n",
            "Embedding number : 45766\n",
            "Embedding number : 45767\n",
            "Embedding number : 45768\n",
            "Embedding number : 45769\n",
            "Embedding number : 45770\n",
            "Embedding number : 45771\n",
            "Embedding number : 45772\n",
            "Embedding number : 45773\n",
            "Embedding number : 45774\n",
            "Embedding number : 45775\n",
            "Embedding number : 45776\n",
            "Embedding number : 45777\n",
            "Embedding number : 45778\n",
            "Embedding number : 45779\n",
            "Embedding number : 45780\n",
            "Embedding number : 45781\n",
            "Embedding number : 45782\n",
            "Embedding number : 45783\n",
            "Embedding number : 45784\n",
            "Embedding number : 45785\n",
            "Embedding number : 45786\n",
            "Embedding number : 45787\n",
            "Embedding number : 45788\n",
            "Embedding number : 45789\n",
            "Embedding number : 45790\n",
            "Embedding number : 45791\n",
            "Embedding number : 45792\n",
            "Embedding number : 45793\n",
            "Embedding number : 45794\n",
            "Embedding number : 45795\n",
            "Embedding number : 45796\n",
            "Embedding number : 45797\n",
            "Embedding number : 45798\n",
            "Embedding number : 45799\n",
            "Embedding number : 45800\n",
            "Embedding number : 45801\n",
            "Embedding number : 45802\n",
            "Embedding number : 45803\n",
            "Embedding number : 45804\n",
            "Embedding number : 45805\n",
            "Embedding number : 45806\n",
            "Embedding number : 45807\n",
            "Embedding number : 45808\n",
            "Embedding number : 45809\n",
            "Embedding number : 45810\n",
            "Embedding number : 45811\n",
            "Embedding number : 45812\n",
            "Embedding number : 45813\n",
            "Embedding number : 45814\n",
            "Embedding number : 45815\n",
            "Embedding number : 45816\n",
            "Embedding number : 45817\n",
            "Embedding number : 45818\n",
            "Embedding number : 45819\n",
            "Embedding number : 45820\n",
            "Embedding number : 45821\n",
            "Embedding number : 45822\n",
            "Embedding number : 45823\n",
            "Embedding number : 45824\n",
            "Embedding number : 45825\n",
            "Embedding number : 45826\n",
            "Embedding number : 45827\n",
            "Embedding number : 45828\n",
            "Embedding number : 45829\n",
            "Embedding number : 45830\n",
            "Embedding number : 45831\n",
            "Embedding number : 45832\n",
            "Embedding number : 45833\n",
            "Embedding number : 45834\n",
            "Embedding number : 45835\n",
            "Embedding number : 45836\n",
            "Embedding number : 45837\n",
            "Embedding number : 45838\n",
            "Embedding number : 45839\n",
            "Embedding number : 45840\n",
            "Embedding number : 45841\n",
            "Embedding number : 45842\n",
            "Embedding number : 45843\n",
            "Embedding number : 45844\n",
            "Embedding number : 45845\n",
            "Embedding number : 45846\n",
            "Embedding number : 45847\n",
            "Embedding number : 45848\n",
            "Embedding number : 45849\n",
            "Embedding number : 45850\n",
            "Embedding number : 45851\n",
            "Embedding number : 45852\n",
            "Embedding number : 45853\n",
            "Embedding number : 45854\n",
            "Embedding number : 45855\n",
            "Embedding number : 45856\n",
            "Embedding number : 45857\n",
            "Embedding number : 45858\n",
            "Embedding number : 45859\n",
            "Embedding number : 45860\n",
            "Embedding number : 45861\n",
            "Embedding number : 45862\n",
            "Embedding number : 45863\n",
            "Embedding number : 45864\n",
            "Embedding number : 45865\n",
            "Embedding number : 45866\n",
            "Embedding number : 45867\n",
            "Embedding number : 45868\n",
            "Embedding number : 45869\n",
            "Embedding number : 45870\n",
            "Embedding number : 45871\n",
            "Embedding number : 45872\n",
            "Embedding number : 45873\n",
            "Embedding number : 45874\n",
            "Embedding number : 45875\n",
            "Embedding number : 45876\n",
            "Embedding number : 45877\n",
            "Embedding number : 45878\n",
            "Embedding number : 45879\n",
            "Embedding number : 45880\n",
            "Embedding number : 45881\n",
            "Embedding number : 45882\n",
            "Embedding number : 45883\n",
            "Embedding number : 45884\n",
            "Embedding number : 45885\n",
            "Embedding number : 45886\n",
            "Embedding number : 45887\n",
            "Embedding number : 45888\n",
            "Embedding number : 45889\n",
            "Embedding number : 45890\n",
            "Embedding number : 45891\n",
            "Embedding number : 45892\n",
            "Embedding number : 45893\n",
            "Embedding number : 45894\n",
            "Embedding number : 45895\n",
            "Embedding number : 45896\n",
            "Embedding number : 45897\n",
            "Embedding number : 45898\n",
            "Embedding number : 45899\n",
            "Embedding number : 45900\n",
            "Embedding number : 45901\n",
            "Embedding number : 45902\n",
            "Embedding number : 45903\n",
            "Embedding number : 45904\n",
            "Embedding number : 45905\n",
            "Embedding number : 45906\n",
            "Embedding number : 45907\n",
            "Embedding number : 45908\n",
            "Embedding number : 45909\n",
            "Embedding number : 45910\n",
            "Embedding number : 45911\n",
            "Embedding number : 45912\n",
            "Embedding number : 45913\n",
            "Embedding number : 45914\n",
            "Embedding number : 45915\n",
            "Embedding number : 45916\n",
            "Embedding number : 45917\n",
            "Embedding number : 45918\n",
            "Embedding number : 45919\n",
            "Embedding number : 45920\n",
            "Embedding number : 45921\n",
            "Embedding number : 45922\n",
            "Embedding number : 45923\n",
            "Embedding number : 45924\n",
            "Embedding number : 45925\n",
            "Embedding number : 45926\n",
            "Embedding number : 45927\n",
            "Embedding number : 45928\n",
            "Embedding number : 45929\n",
            "Embedding number : 45930\n",
            "Embedding number : 45931\n",
            "Embedding number : 45932\n",
            "Embedding number : 45933\n",
            "Embedding number : 45934\n",
            "Embedding number : 45935\n",
            "Embedding number : 45936\n",
            "Embedding number : 45937\n",
            "Embedding number : 45938\n",
            "Embedding number : 45939\n",
            "Embedding number : 45940\n",
            "Embedding number : 45941\n",
            "Embedding number : 45942\n",
            "Embedding number : 45943\n",
            "Embedding number : 45944\n",
            "Embedding number : 45945\n",
            "Embedding number : 45946\n",
            "Embedding number : 45947\n",
            "Embedding number : 45948\n",
            "Embedding number : 45949\n",
            "Embedding number : 45950\n",
            "Embedding number : 45951\n",
            "Embedding number : 45952\n",
            "Embedding number : 45953\n",
            "Embedding number : 45954\n",
            "Embedding number : 45955\n",
            "Embedding number : 45956\n",
            "Embedding number : 45957\n",
            "Embedding number : 45958\n",
            "Embedding number : 45959\n",
            "Embedding number : 45960\n",
            "Embedding number : 45961\n",
            "Embedding number : 45962\n",
            "Embedding number : 45963\n",
            "Embedding number : 45964\n",
            "Embedding number : 45965\n",
            "Embedding number : 45966\n",
            "Embedding number : 45967\n",
            "Embedding number : 45968\n",
            "Embedding number : 45969\n",
            "Embedding number : 45970\n",
            "Embedding number : 45971\n",
            "Embedding number : 45972\n",
            "Embedding number : 45973\n",
            "Embedding number : 45974\n",
            "Embedding number : 45975\n",
            "Embedding number : 45976\n",
            "Embedding number : 45977\n",
            "Embedding number : 45978\n",
            "Embedding number : 45979\n",
            "Embedding number : 45980\n",
            "Embedding number : 45981\n",
            "Embedding number : 45982\n",
            "Embedding number : 45983\n",
            "Embedding number : 45984\n",
            "Embedding number : 45985\n",
            "Embedding number : 45986\n",
            "Embedding number : 45987\n",
            "Embedding number : 45988\n",
            "Embedding number : 45989\n",
            "Embedding number : 45990\n",
            "Embedding number : 45991\n",
            "Embedding number : 45992\n",
            "Embedding number : 45993\n",
            "Embedding number : 45994\n",
            "Embedding number : 45995\n",
            "Embedding number : 45996\n",
            "Embedding number : 45997\n",
            "Embedding number : 45998\n",
            "Embedding number : 45999\n",
            "Embedding number : 46000\n",
            "Embedding number : 46001\n",
            "Embedding number : 46002\n",
            "Embedding number : 46003\n",
            "Embedding number : 46004\n",
            "Embedding number : 46005\n",
            "Embedding number : 46006\n",
            "Embedding number : 46007\n",
            "Embedding number : 46008\n",
            "Embedding number : 46009\n",
            "Embedding number : 46010\n",
            "Embedding number : 46011\n",
            "Embedding number : 46012\n",
            "Embedding number : 46013\n",
            "Embedding number : 46014\n",
            "Embedding number : 46015\n",
            "Embedding number : 46016\n",
            "Embedding number : 46017\n",
            "Embedding number : 46018\n",
            "Embedding number : 46019\n",
            "Embedding number : 46020\n",
            "Embedding number : 46021\n",
            "Embedding number : 46022\n",
            "Embedding number : 46023\n",
            "Embedding number : 46024\n",
            "Embedding number : 46025\n",
            "Embedding number : 46026\n",
            "Embedding number : 46027\n",
            "Embedding number : 46028\n",
            "Embedding number : 46029\n",
            "Embedding number : 46030\n",
            "Embedding number : 46031\n",
            "Embedding number : 46032\n",
            "Embedding number : 46033\n",
            "Embedding number : 46034\n",
            "Embedding number : 46035\n",
            "Embedding number : 46036\n",
            "Embedding number : 46037\n",
            "Embedding number : 46038\n",
            "Embedding number : 46039\n",
            "Embedding number : 46040\n",
            "Embedding number : 46041\n",
            "Embedding number : 46042\n",
            "Embedding number : 46043\n",
            "Embedding number : 46044\n",
            "Embedding number : 46045\n",
            "Embedding number : 46046\n",
            "Embedding number : 46047\n",
            "Embedding number : 46048\n",
            "Embedding number : 46049\n",
            "Embedding number : 46050\n",
            "Embedding number : 46051\n",
            "Embedding number : 46052\n",
            "Embedding number : 46053\n",
            "Embedding number : 46054\n",
            "Embedding number : 46055\n",
            "Embedding number : 46056\n",
            "Embedding number : 46057\n",
            "Embedding number : 46058\n",
            "Embedding number : 46059\n",
            "Embedding number : 46060\n",
            "Embedding number : 46061\n",
            "Embedding number : 46062\n",
            "Embedding number : 46063\n",
            "Embedding number : 46064\n",
            "Embedding number : 46065\n",
            "Embedding number : 46066\n",
            "Embedding number : 46067\n",
            "Embedding number : 46068\n",
            "Embedding number : 46069\n",
            "Embedding number : 46070\n",
            "Embedding number : 46071\n",
            "Embedding number : 46072\n",
            "Embedding number : 46073\n",
            "Embedding number : 46074\n",
            "Embedding number : 46075\n",
            "Embedding number : 46076\n",
            "Embedding number : 46077\n",
            "Embedding number : 46078\n",
            "Embedding number : 46079\n",
            "Embedding number : 46080\n",
            "Embedding number : 46081\n",
            "Embedding number : 46082\n",
            "Embedding number : 46083\n",
            "Embedding number : 46084\n",
            "Embedding number : 46085\n",
            "Embedding number : 46086\n",
            "Embedding number : 46087\n",
            "Embedding number : 46088\n",
            "Embedding number : 46089\n",
            "Embedding number : 46090\n",
            "Embedding number : 46091\n",
            "Embedding number : 46092\n",
            "Embedding number : 46093\n",
            "Embedding number : 46094\n",
            "Embedding number : 46095\n",
            "Embedding number : 46096\n",
            "Embedding number : 46097\n",
            "Embedding number : 46098\n",
            "Embedding number : 46099\n",
            "Embedding number : 46100\n",
            "Embedding number : 46101\n",
            "Embedding number : 46102\n",
            "Embedding number : 46103\n",
            "Embedding number : 46104\n",
            "Embedding number : 46105\n",
            "Embedding number : 46106\n",
            "Embedding number : 46107\n",
            "Embedding number : 46108\n",
            "Embedding number : 46109\n",
            "Embedding number : 46110\n",
            "Embedding number : 46111\n",
            "Embedding number : 46112\n",
            "Embedding number : 46113\n",
            "Embedding number : 46114\n",
            "Embedding number : 46115\n",
            "Embedding number : 46116\n",
            "Embedding number : 46117\n",
            "Embedding number : 46118\n",
            "Embedding number : 46119\n",
            "Embedding number : 46120\n",
            "Embedding number : 46121\n",
            "Embedding number : 46122\n",
            "Embedding number : 46123\n",
            "Embedding number : 46124\n",
            "Embedding number : 46125\n",
            "Embedding number : 46126\n",
            "Embedding number : 46127\n",
            "Embedding number : 46128\n",
            "Embedding number : 46129\n",
            "Embedding number : 46130\n",
            "Embedding number : 46131\n",
            "Embedding number : 46132\n",
            "Embedding number : 46133\n",
            "Embedding number : 46134\n",
            "Embedding number : 46135\n",
            "Embedding number : 46136\n",
            "Embedding number : 46137\n",
            "Embedding number : 46138\n",
            "Embedding number : 46139\n",
            "Embedding number : 46140\n",
            "Embedding number : 46141\n",
            "Embedding number : 46142\n",
            "Embedding number : 46143\n",
            "Embedding number : 46144\n",
            "Embedding number : 46145\n",
            "Embedding number : 46146\n",
            "Embedding number : 46147\n",
            "Embedding number : 46148\n",
            "Embedding number : 46149\n",
            "Embedding number : 46150\n",
            "Embedding number : 46151\n",
            "Embedding number : 46152\n",
            "Embedding number : 46153\n",
            "Embedding number : 46154\n",
            "Embedding number : 46155\n",
            "Embedding number : 46156\n",
            "Embedding number : 46157\n",
            "Embedding number : 46158\n",
            "Embedding number : 46159\n",
            "Embedding number : 46160\n",
            "Embedding number : 46161\n",
            "Embedding number : 46162\n",
            "Embedding number : 46163\n",
            "Embedding number : 46164\n",
            "Embedding number : 46165\n",
            "Embedding number : 46166\n",
            "Embedding number : 46167\n",
            "Embedding number : 46168\n",
            "Embedding number : 46169\n",
            "Embedding number : 46170\n",
            "Embedding number : 46171\n",
            "Embedding number : 46172\n",
            "Embedding number : 46173\n",
            "Embedding number : 46174\n",
            "Embedding number : 46175\n",
            "Embedding number : 46176\n",
            "Embedding number : 46177\n",
            "Embedding number : 46178\n",
            "Embedding number : 46179\n",
            "Embedding number : 46180\n",
            "Embedding number : 46181\n",
            "Embedding number : 46182\n",
            "Embedding number : 46183\n",
            "Embedding number : 46184\n",
            "Embedding number : 46185\n",
            "Embedding number : 46186\n",
            "Embedding number : 46187\n",
            "Embedding number : 46188\n",
            "Embedding number : 46189\n",
            "Embedding number : 46190\n",
            "Embedding number : 46191\n",
            "Embedding number : 46192\n",
            "Embedding number : 46193\n",
            "Embedding number : 46194\n",
            "Embedding number : 46195\n",
            "Embedding number : 46196\n",
            "Embedding number : 46197\n",
            "Embedding number : 46198\n",
            "Embedding number : 46199\n",
            "Embedding number : 46200\n",
            "Embedding number : 46201\n",
            "Embedding number : 46202\n",
            "Embedding number : 46203\n",
            "Embedding number : 46204\n",
            "Embedding number : 46205\n",
            "Embedding number : 46206\n",
            "Embedding number : 46207\n",
            "Embedding number : 46208\n",
            "Embedding number : 46209\n",
            "Embedding number : 46210\n",
            "Embedding number : 46211\n",
            "Embedding number : 46212\n",
            "Embedding number : 46213\n",
            "Embedding number : 46214\n",
            "Embedding number : 46215\n",
            "Embedding number : 46216\n",
            "Embedding number : 46217\n",
            "Embedding number : 46218\n",
            "Embedding number : 46219\n",
            "Embedding number : 46220\n",
            "Embedding number : 46221\n",
            "Embedding number : 46222\n",
            "Embedding number : 46223\n",
            "Embedding number : 46224\n",
            "Embedding number : 46225\n",
            "Embedding number : 46226\n",
            "Embedding number : 46227\n",
            "Embedding number : 46228\n",
            "Embedding number : 46229\n",
            "Embedding number : 46230\n",
            "Embedding number : 46231\n",
            "Embedding number : 46232\n",
            "Embedding number : 46233\n",
            "Embedding number : 46234\n",
            "Embedding number : 46235\n",
            "Embedding number : 46236\n",
            "Embedding number : 46237\n",
            "Embedding number : 46238\n",
            "Embedding number : 46239\n",
            "Embedding number : 46240\n",
            "Embedding number : 46241\n",
            "Embedding number : 46242\n",
            "Embedding number : 46243\n",
            "Embedding number : 46244\n",
            "Embedding number : 46245\n",
            "Embedding number : 46246\n",
            "Embedding number : 46247\n",
            "Embedding number : 46248\n",
            "Embedding number : 46249\n",
            "Embedding number : 46250\n",
            "Embedding number : 46251\n",
            "Embedding number : 46252\n",
            "Embedding number : 46253\n",
            "Embedding number : 46254\n",
            "Embedding number : 46255\n",
            "Embedding number : 46256\n",
            "Embedding number : 46257\n",
            "Embedding number : 46258\n",
            "Embedding number : 46259\n",
            "Embedding number : 46260\n",
            "Embedding number : 46261\n",
            "Embedding number : 46262\n",
            "Embedding number : 46263\n",
            "Embedding number : 46264\n",
            "Embedding number : 46265\n",
            "Embedding number : 46266\n",
            "Embedding number : 46267\n",
            "Embedding number : 46268\n",
            "Embedding number : 46269\n",
            "Embedding number : 46270\n",
            "Embedding number : 46271\n",
            "Embedding number : 46272\n",
            "Embedding number : 46273\n",
            "Embedding number : 46274\n",
            "Embedding number : 46275\n",
            "Embedding number : 46276\n",
            "Embedding number : 46277\n",
            "Embedding number : 46278\n",
            "Embedding number : 46279\n",
            "Embedding number : 46280\n",
            "Embedding number : 46281\n",
            "Embedding number : 46282\n",
            "Embedding number : 46283\n",
            "Embedding number : 46284\n",
            "Embedding number : 46285\n",
            "Embedding number : 46286\n",
            "Embedding number : 46287\n",
            "Embedding number : 46288\n",
            "Embedding number : 46289\n",
            "Embedding number : 46290\n",
            "Embedding number : 46291\n",
            "Embedding number : 46292\n",
            "Embedding number : 46293\n",
            "Embedding number : 46294\n",
            "Embedding number : 46295\n",
            "Embedding number : 46296\n",
            "Embedding number : 46297\n",
            "Embedding number : 46298\n",
            "Embedding number : 46299\n",
            "Embedding number : 46300\n",
            "Embedding number : 46301\n",
            "Embedding number : 46302\n",
            "Embedding number : 46303\n",
            "Embedding number : 46304\n",
            "Embedding number : 46305\n",
            "Embedding number : 46306\n",
            "Embedding number : 46307\n",
            "Embedding number : 46308\n",
            "Embedding number : 46309\n",
            "Embedding number : 46310\n",
            "Embedding number : 46311\n",
            "Embedding number : 46312\n",
            "Embedding number : 46313\n",
            "Embedding number : 46314\n",
            "Embedding number : 46315\n",
            "Embedding number : 46316\n",
            "Embedding number : 46317\n",
            "Embedding number : 46318\n",
            "Embedding number : 46319\n",
            "Embedding number : 46320\n",
            "Embedding number : 46321\n",
            "Embedding number : 46322\n",
            "Embedding number : 46323\n",
            "Embedding number : 46324\n",
            "Embedding number : 46325\n",
            "Embedding number : 46326\n",
            "Embedding number : 46327\n",
            "Embedding number : 46328\n",
            "Embedding number : 46329\n",
            "Embedding number : 46330\n",
            "Embedding number : 46331\n",
            "Embedding number : 46332\n",
            "Embedding number : 46333\n",
            "Embedding number : 46334\n",
            "Embedding number : 46335\n",
            "Embedding number : 46336\n",
            "Embedding number : 46337\n",
            "Embedding number : 46338\n",
            "Embedding number : 46339\n",
            "Embedding number : 46340\n",
            "Embedding number : 46341\n",
            "Embedding number : 46342\n",
            "Embedding number : 46343\n",
            "Embedding number : 46344\n",
            "Embedding number : 46345\n",
            "Embedding number : 46346\n",
            "Embedding number : 46347\n",
            "Embedding number : 46348\n",
            "Embedding number : 46349\n",
            "Embedding number : 46350\n",
            "Embedding number : 46351\n",
            "Embedding number : 46352\n",
            "Embedding number : 46353\n",
            "Embedding number : 46354\n",
            "Embedding number : 46355\n",
            "Embedding number : 46356\n",
            "Embedding number : 46357\n",
            "Embedding number : 46358\n",
            "Embedding number : 46359\n",
            "Embedding number : 46360\n",
            "Embedding number : 46361\n",
            "Embedding number : 46362\n",
            "Embedding number : 46363\n",
            "Embedding number : 46364\n",
            "Embedding number : 46365\n",
            "Embedding number : 46366\n",
            "Embedding number : 46367\n",
            "Embedding number : 46368\n",
            "Embedding number : 46369\n",
            "Embedding number : 46370\n",
            "Embedding number : 46371\n",
            "Embedding number : 46372\n",
            "Embedding number : 46373\n",
            "Embedding number : 46374\n",
            "Embedding number : 46375\n",
            "Embedding number : 46376\n",
            "Embedding number : 46377\n",
            "Embedding number : 46378\n",
            "Embedding number : 46379\n",
            "Embedding number : 46380\n",
            "Embedding number : 46381\n",
            "Embedding number : 46382\n",
            "Embedding number : 46383\n",
            "Embedding number : 46384\n",
            "Embedding number : 46385\n",
            "Embedding number : 46386\n",
            "Embedding number : 46387\n",
            "Embedding number : 46388\n",
            "Embedding number : 46389\n",
            "Embedding number : 46390\n",
            "Embedding number : 46391\n",
            "Embedding number : 46392\n",
            "Embedding number : 46393\n",
            "Embedding number : 46394\n",
            "Embedding number : 46395\n",
            "Embedding number : 46396\n",
            "Embedding number : 46397\n",
            "Embedding number : 46398\n",
            "Embedding number : 46399\n",
            "Embedding number : 46400\n",
            "Embedding number : 46401\n",
            "Embedding number : 46402\n",
            "Embedding number : 46403\n",
            "Embedding number : 46404\n",
            "Embedding number : 46405\n",
            "Embedding number : 46406\n",
            "Embedding number : 46407\n",
            "Embedding number : 46408\n",
            "Embedding number : 46409\n",
            "Embedding number : 46410\n",
            "Embedding number : 46411\n",
            "Embedding number : 46412\n",
            "Embedding number : 46413\n",
            "Embedding number : 46414\n",
            "Embedding number : 46415\n",
            "Embedding number : 46416\n",
            "Embedding number : 46417\n",
            "Embedding number : 46418\n",
            "Embedding number : 46419\n",
            "Embedding number : 46420\n",
            "Embedding number : 46421\n",
            "Embedding number : 46422\n",
            "Embedding number : 46423\n",
            "Embedding number : 46424\n",
            "Embedding number : 46425\n",
            "Embedding number : 46426\n",
            "Embedding number : 46427\n",
            "Embedding number : 46428\n",
            "Embedding number : 46429\n",
            "Embedding number : 46430\n",
            "Embedding number : 46431\n",
            "Embedding number : 46432\n",
            "Embedding number : 46433\n",
            "Embedding number : 46434\n",
            "Embedding number : 46435\n",
            "Embedding number : 46436\n",
            "Embedding number : 46437\n",
            "Embedding number : 46438\n",
            "Embedding number : 46439\n",
            "Embedding number : 46440\n",
            "Embedding number : 46441\n",
            "Embedding number : 46442\n",
            "Embedding number : 46443\n",
            "Embedding number : 46444\n",
            "Embedding number : 46445\n",
            "Embedding number : 46446\n",
            "Embedding number : 46447\n",
            "Embedding number : 46448\n",
            "Embedding number : 46449\n",
            "Embedding number : 46450\n",
            "Embedding number : 46451\n",
            "Embedding number : 46452\n",
            "Embedding number : 46453\n",
            "Embedding number : 46454\n",
            "Embedding number : 46455\n",
            "Embedding number : 46456\n",
            "Embedding number : 46457\n",
            "Embedding number : 46458\n",
            "Embedding number : 46459\n",
            "Embedding number : 46460\n",
            "Embedding number : 46461\n",
            "Embedding number : 46462\n",
            "Embedding number : 46463\n",
            "Embedding number : 46464\n",
            "Embedding number : 46465\n",
            "Embedding number : 46466\n",
            "Embedding number : 46467\n",
            "Embedding number : 46468\n",
            "Embedding number : 46469\n",
            "Embedding number : 46470\n",
            "Embedding number : 46471\n",
            "Embedding number : 46472\n",
            "Embedding number : 46473\n",
            "Embedding number : 46474\n",
            "Embedding number : 46475\n",
            "Embedding number : 46476\n",
            "Embedding number : 46477\n",
            "Embedding number : 46478\n",
            "Embedding number : 46479\n",
            "Embedding number : 46480\n",
            "Embedding number : 46481\n",
            "Embedding number : 46482\n",
            "Embedding number : 46483\n",
            "Embedding number : 46484\n",
            "Embedding number : 46485\n",
            "Embedding number : 46486\n",
            "Embedding number : 46487\n",
            "Embedding number : 46488\n",
            "Embedding number : 46489\n",
            "Embedding number : 46490\n",
            "Embedding number : 46491\n",
            "Embedding number : 46492\n",
            "Embedding number : 46493\n",
            "Embedding number : 46494\n",
            "Embedding number : 46495\n",
            "Embedding number : 46496\n",
            "Embedding number : 46497\n",
            "Embedding number : 46498\n",
            "Embedding number : 46499\n",
            "Embedding number : 46500\n",
            "Embedding number : 46501\n",
            "Embedding number : 46502\n",
            "Embedding number : 46503\n",
            "Embedding number : 46504\n",
            "Embedding number : 46505\n",
            "Embedding number : 46506\n",
            "Embedding number : 46507\n",
            "Embedding number : 46508\n",
            "Embedding number : 46509\n",
            "Embedding number : 46510\n",
            "Embedding number : 46511\n",
            "Embedding number : 46512\n",
            "Embedding number : 46513\n",
            "Embedding number : 46514\n",
            "Embedding number : 46515\n",
            "Embedding number : 46516\n",
            "Embedding number : 46517\n",
            "Embedding number : 46518\n",
            "Embedding number : 46519\n",
            "Embedding number : 46520\n",
            "Embedding number : 46521\n",
            "Embedding number : 46522\n",
            "Embedding number : 46523\n",
            "Embedding number : 46524\n",
            "Embedding number : 46525\n",
            "Embedding number : 46526\n",
            "Embedding number : 46527\n",
            "Embedding number : 46528\n",
            "Embedding number : 46529\n",
            "Embedding number : 46530\n",
            "Embedding number : 46531\n",
            "Embedding number : 46532\n",
            "Embedding number : 46533\n",
            "Embedding number : 46534\n",
            "Embedding number : 46535\n",
            "Embedding number : 46536\n",
            "Embedding number : 46537\n",
            "Embedding number : 46538\n",
            "Embedding number : 46539\n",
            "Embedding number : 46540\n",
            "Embedding number : 46541\n",
            "Embedding number : 46542\n",
            "Embedding number : 46543\n",
            "Embedding number : 46544\n",
            "Embedding number : 46545\n",
            "Embedding number : 46546\n",
            "Embedding number : 46547\n",
            "Embedding number : 46548\n",
            "Embedding number : 46549\n",
            "Embedding number : 46550\n",
            "Embedding number : 46551\n",
            "Embedding number : 46552\n",
            "Embedding number : 46553\n",
            "Embedding number : 46554\n",
            "Embedding number : 46555\n",
            "Embedding number : 46556\n",
            "Embedding number : 46557\n",
            "Embedding number : 46558\n",
            "Embedding number : 46559\n",
            "Embedding number : 46560\n",
            "Embedding number : 46561\n",
            "Embedding number : 46562\n",
            "Embedding number : 46563\n",
            "Embedding number : 46564\n",
            "Embedding number : 46565\n",
            "Embedding number : 46566\n",
            "Embedding number : 46567\n",
            "Embedding number : 46568\n",
            "Embedding number : 46569\n",
            "Embedding number : 46570\n",
            "Embedding number : 46571\n",
            "Embedding number : 46572\n",
            "Embedding number : 46573\n",
            "Embedding number : 46574\n",
            "Embedding number : 46575\n",
            "Embedding number : 46576\n",
            "Embedding number : 46577\n",
            "Embedding number : 46578\n",
            "Embedding number : 46579\n",
            "Embedding number : 46580\n",
            "Embedding number : 46581\n",
            "Embedding number : 46582\n",
            "Embedding number : 46583\n",
            "Embedding number : 46584\n",
            "Embedding number : 46585\n",
            "Embedding number : 46586\n",
            "Embedding number : 46587\n",
            "Embedding number : 46588\n",
            "Embedding number : 46589\n",
            "Embedding number : 46590\n",
            "Embedding number : 46591\n",
            "Embedding number : 46592\n",
            "Embedding number : 46593\n",
            "Embedding number : 46594\n",
            "Embedding number : 46595\n",
            "Embedding number : 46596\n",
            "Embedding number : 46597\n",
            "Embedding number : 46598\n",
            "Embedding number : 46599\n",
            "Embedding number : 46600\n",
            "Embedding number : 46601\n",
            "Embedding number : 46602\n",
            "Embedding number : 46603\n",
            "Embedding number : 46604\n",
            "Embedding number : 46605\n",
            "Embedding number : 46606\n",
            "Embedding number : 46607\n",
            "Embedding number : 46608\n",
            "Embedding number : 46609\n",
            "Embedding number : 46610\n",
            "Embedding number : 46611\n",
            "Embedding number : 46612\n",
            "Embedding number : 46613\n",
            "Embedding number : 46614\n",
            "Embedding number : 46615\n",
            "Embedding number : 46616\n",
            "Embedding number : 46617\n",
            "Embedding number : 46618\n",
            "Embedding number : 46619\n",
            "Embedding number : 46620\n",
            "Embedding number : 46621\n",
            "Embedding number : 46622\n",
            "Embedding number : 46623\n",
            "Embedding number : 46624\n",
            "Embedding number : 46625\n",
            "Embedding number : 46626\n",
            "Embedding number : 46627\n",
            "Embedding number : 46628\n",
            "Embedding number : 46629\n",
            "Embedding number : 46630\n",
            "Embedding number : 46631\n",
            "Embedding number : 46632\n",
            "Embedding number : 46633\n",
            "Embedding number : 46634\n",
            "Embedding number : 46635\n",
            "Embedding number : 46636\n",
            "Embedding number : 46637\n",
            "Embedding number : 46638\n",
            "Embedding number : 46639\n",
            "Embedding number : 46640\n",
            "Embedding number : 46641\n",
            "Embedding number : 46642\n",
            "Embedding number : 46643\n",
            "Embedding number : 46644\n",
            "Embedding number : 46645\n",
            "Embedding number : 46646\n",
            "Embedding number : 46647\n",
            "Embedding number : 46648\n",
            "Embedding number : 46649\n",
            "Embedding number : 46650\n",
            "Embedding number : 46651\n",
            "Embedding number : 46652\n",
            "Embedding number : 46653\n",
            "Embedding number : 46654\n",
            "Embedding number : 46655\n",
            "Embedding number : 46656\n",
            "Embedding number : 46657\n",
            "Embedding number : 46658\n",
            "Embedding number : 46659\n",
            "Embedding number : 46660\n",
            "Embedding number : 46661\n",
            "Embedding number : 46662\n",
            "Embedding number : 46663\n",
            "Embedding number : 46664\n",
            "Embedding number : 46665\n",
            "Embedding number : 46666\n",
            "Embedding number : 46667\n",
            "Embedding number : 46668\n",
            "Embedding number : 46669\n",
            "Embedding number : 46670\n",
            "Embedding number : 46671\n",
            "Embedding number : 46672\n",
            "Embedding number : 46673\n",
            "Embedding number : 46674\n",
            "Embedding number : 46675\n",
            "Embedding number : 46676\n",
            "Embedding number : 46677\n",
            "Embedding number : 46678\n",
            "Embedding number : 46679\n",
            "Embedding number : 46680\n",
            "Embedding number : 46681\n",
            "Embedding number : 46682\n",
            "Embedding number : 46683\n",
            "Embedding number : 46684\n",
            "Embedding number : 46685\n",
            "Embedding number : 46686\n",
            "Embedding number : 46687\n",
            "Embedding number : 46688\n",
            "Embedding number : 46689\n",
            "Embedding number : 46690\n",
            "Embedding number : 46691\n",
            "Embedding number : 46692\n",
            "Embedding number : 46693\n",
            "Embedding number : 46694\n",
            "Embedding number : 46695\n",
            "Embedding number : 46696\n",
            "Embedding number : 46697\n",
            "Embedding number : 46698\n",
            "Embedding number : 46699\n",
            "Embedding number : 46700\n",
            "Embedding number : 46701\n",
            "Embedding number : 46702\n",
            "Embedding number : 46703\n",
            "Embedding number : 46704\n",
            "Embedding number : 46705\n",
            "Embedding number : 46706\n",
            "Embedding number : 46707\n",
            "Embedding number : 46708\n",
            "Embedding number : 46709\n",
            "Embedding number : 46710\n",
            "Embedding number : 46711\n",
            "Embedding number : 46712\n",
            "Embedding number : 46713\n",
            "Embedding number : 46714\n",
            "Embedding number : 46715\n",
            "Embedding number : 46716\n",
            "Embedding number : 46717\n",
            "Embedding number : 46718\n",
            "Embedding number : 46719\n",
            "Embedding number : 46720\n",
            "Embedding number : 46721\n",
            "Embedding number : 46722\n",
            "Embedding number : 46723\n",
            "Embedding number : 46724\n",
            "Embedding number : 46725\n",
            "Embedding number : 46726\n",
            "Embedding number : 46727\n",
            "Embedding number : 46728\n",
            "Embedding number : 46729\n",
            "Embedding number : 46730\n",
            "Embedding number : 46731\n",
            "Embedding number : 46732\n",
            "Embedding number : 46733\n",
            "Embedding number : 46734\n",
            "Embedding number : 46735\n",
            "Embedding number : 46736\n",
            "Embedding number : 46737\n",
            "Embedding number : 46738\n",
            "Embedding number : 46739\n",
            "Embedding number : 46740\n",
            "Embedding number : 46741\n",
            "Embedding number : 46742\n",
            "Embedding number : 46743\n",
            "Embedding number : 46744\n",
            "Embedding number : 46745\n",
            "Embedding number : 46746\n",
            "Embedding number : 46747\n",
            "Embedding number : 46748\n",
            "Embedding number : 46749\n",
            "Embedding number : 46750\n",
            "Embedding number : 46751\n",
            "Embedding number : 46752\n",
            "Embedding number : 46753\n",
            "Embedding number : 46754\n",
            "Embedding number : 46755\n",
            "Embedding number : 46756\n",
            "Embedding number : 46757\n",
            "Embedding number : 46758\n",
            "Embedding number : 46759\n",
            "Embedding number : 46760\n",
            "Embedding number : 46761\n",
            "Embedding number : 46762\n",
            "Embedding number : 46763\n",
            "Embedding number : 46764\n",
            "Embedding number : 46765\n",
            "Embedding number : 46766\n",
            "Embedding number : 46767\n",
            "Embedding number : 46768\n",
            "Embedding number : 46769\n",
            "Embedding number : 46770\n",
            "Embedding number : 46771\n",
            "Embedding number : 46772\n",
            "Embedding number : 46773\n",
            "Embedding number : 46774\n",
            "Embedding number : 46775\n",
            "Embedding number : 46776\n",
            "Embedding number : 46777\n",
            "Embedding number : 46778\n",
            "Embedding number : 46779\n",
            "Embedding number : 46780\n",
            "Embedding number : 46781\n",
            "Embedding number : 46782\n",
            "Embedding number : 46783\n",
            "Embedding number : 46784\n",
            "Embedding number : 46785\n",
            "Embedding number : 46786\n",
            "Embedding number : 46787\n",
            "Embedding number : 46788\n",
            "Embedding number : 46789\n",
            "Embedding number : 46790\n",
            "Embedding number : 46791\n",
            "Embedding number : 46792\n",
            "Embedding number : 46793\n",
            "Embedding number : 46794\n",
            "Embedding number : 46795\n",
            "Embedding number : 46796\n",
            "Embedding number : 46797\n",
            "Embedding number : 46798\n",
            "Embedding number : 46799\n",
            "Embedding number : 46800\n",
            "Embedding number : 46801\n",
            "Embedding number : 46802\n",
            "Embedding number : 46803\n",
            "Embedding number : 46804\n",
            "Embedding number : 46805\n",
            "Embedding number : 46806\n",
            "Embedding number : 46807\n",
            "Embedding number : 46808\n",
            "Embedding number : 46809\n",
            "Embedding number : 46810\n",
            "Embedding number : 46811\n",
            "Embedding number : 46812\n",
            "Embedding number : 46813\n",
            "Embedding number : 46814\n",
            "Embedding number : 46815\n",
            "Embedding number : 46816\n",
            "Embedding number : 46817\n",
            "Embedding number : 46818\n",
            "Embedding number : 46819\n",
            "Embedding number : 46820\n",
            "Embedding number : 46821\n",
            "Embedding number : 46822\n",
            "Embedding number : 46823\n",
            "Embedding number : 46824\n",
            "Embedding number : 46825\n",
            "Embedding number : 46826\n",
            "Embedding number : 46827\n",
            "Embedding number : 46828\n",
            "Embedding number : 46829\n",
            "Embedding number : 46830\n",
            "Embedding number : 46831\n",
            "Embedding number : 46832\n",
            "Embedding number : 46833\n",
            "Embedding number : 46834\n",
            "Embedding number : 46835\n",
            "Embedding number : 46836\n",
            "Embedding number : 46837\n",
            "Embedding number : 46838\n",
            "Embedding number : 46839\n",
            "Embedding number : 46840\n",
            "Embedding number : 46841\n",
            "Embedding number : 46842\n",
            "Embedding number : 46843\n",
            "Embedding number : 46844\n",
            "Embedding number : 46845\n",
            "Embedding number : 46846\n",
            "Embedding number : 46847\n",
            "Embedding number : 46848\n",
            "Embedding number : 46849\n",
            "Embedding number : 46850\n",
            "Embedding number : 46851\n",
            "Embedding number : 46852\n",
            "Embedding number : 46853\n",
            "Embedding number : 46854\n",
            "Embedding number : 46855\n",
            "Embedding number : 46856\n",
            "Embedding number : 46857\n",
            "Embedding number : 46858\n",
            "Embedding number : 46859\n",
            "Embedding number : 46860\n",
            "Embedding number : 46861\n",
            "Embedding number : 46862\n",
            "Embedding number : 46863\n",
            "Embedding number : 46864\n",
            "Embedding number : 46865\n",
            "Embedding number : 46866\n",
            "Embedding number : 46867\n",
            "Embedding number : 46868\n",
            "Embedding number : 46869\n",
            "Embedding number : 46870\n",
            "Embedding number : 46871\n",
            "Embedding number : 46872\n",
            "Embedding number : 46873\n",
            "Embedding number : 46874\n",
            "Embedding number : 46875\n",
            "Embedding number : 46876\n",
            "Embedding number : 46877\n",
            "Embedding number : 46878\n",
            "Embedding number : 46879\n",
            "Embedding number : 46880\n",
            "Embedding number : 46881\n",
            "Embedding number : 46882\n",
            "Embedding number : 46883\n",
            "Embedding number : 46884\n",
            "Embedding number : 46885\n",
            "Embedding number : 46886\n",
            "Embedding number : 46887\n",
            "Embedding number : 46888\n",
            "Embedding number : 46889\n",
            "Embedding number : 46890\n",
            "Embedding number : 46891\n",
            "Embedding number : 46892\n",
            "Embedding number : 46893\n",
            "Embedding number : 46894\n",
            "Embedding number : 46895\n",
            "Embedding number : 46896\n",
            "Embedding number : 46897\n",
            "Embedding number : 46898\n",
            "Embedding number : 46899\n",
            "Embedding number : 46900\n",
            "Embedding number : 46901\n",
            "Embedding number : 46902\n",
            "Embedding number : 46903\n",
            "Embedding number : 46904\n",
            "Embedding number : 46905\n",
            "Embedding number : 46906\n",
            "Embedding number : 46907\n",
            "Embedding number : 46908\n",
            "Embedding number : 46909\n",
            "Embedding number : 46910\n",
            "Embedding number : 46911\n",
            "Embedding number : 46912\n",
            "Embedding number : 46913\n",
            "Embedding number : 46914\n",
            "Embedding number : 46915\n",
            "Embedding number : 46916\n",
            "Embedding number : 46917\n",
            "Embedding number : 46918\n",
            "Embedding number : 46919\n",
            "Embedding number : 46920\n",
            "Embedding number : 46921\n",
            "Embedding number : 46922\n",
            "Embedding number : 46923\n",
            "Embedding number : 46924\n",
            "Embedding number : 46925\n",
            "Embedding number : 46926\n",
            "Embedding number : 46927\n",
            "Embedding number : 46928\n",
            "Embedding number : 46929\n",
            "Embedding number : 46930\n",
            "Embedding number : 46931\n",
            "Embedding number : 46932\n",
            "Embedding number : 46933\n",
            "Embedding number : 46934\n",
            "Embedding number : 46935\n",
            "Embedding number : 46936\n",
            "Embedding number : 46937\n",
            "Embedding number : 46938\n",
            "Embedding number : 46939\n",
            "Embedding number : 46940\n",
            "Embedding number : 46941\n",
            "Embedding number : 46942\n",
            "Embedding number : 46943\n",
            "Embedding number : 46944\n",
            "Embedding number : 46945\n",
            "Embedding number : 46946\n",
            "Embedding number : 46947\n",
            "Embedding number : 46948\n",
            "Embedding number : 46949\n",
            "Embedding number : 46950\n",
            "Embedding number : 46951\n",
            "Embedding number : 46952\n",
            "Embedding number : 46953\n",
            "Embedding number : 46954\n",
            "Embedding number : 46955\n",
            "Embedding number : 46956\n",
            "Embedding number : 46957\n",
            "Embedding number : 46958\n",
            "Embedding number : 46959\n",
            "Embedding number : 46960\n",
            "Embedding number : 46961\n",
            "Embedding number : 46962\n",
            "Embedding number : 46963\n",
            "Embedding number : 46964\n",
            "Embedding number : 46965\n",
            "Embedding number : 46966\n",
            "Embedding number : 46967\n",
            "Embedding number : 46968\n",
            "Embedding number : 46969\n",
            "Embedding number : 46970\n",
            "Embedding number : 46971\n",
            "Embedding number : 46972\n",
            "Embedding number : 46973\n",
            "Embedding number : 46974\n",
            "Embedding number : 46975\n",
            "Embedding number : 46976\n",
            "Embedding number : 46977\n",
            "Embedding number : 46978\n",
            "Embedding number : 46979\n",
            "Embedding number : 46980\n",
            "Embedding number : 46981\n",
            "Embedding number : 46982\n",
            "Embedding number : 46983\n",
            "Embedding number : 46984\n",
            "Embedding number : 46985\n",
            "Embedding number : 46986\n",
            "Embedding number : 46987\n",
            "Embedding number : 46988\n",
            "Embedding number : 46989\n",
            "Embedding number : 46990\n",
            "Embedding number : 46991\n",
            "Embedding number : 46992\n",
            "Embedding number : 46993\n",
            "Embedding number : 46994\n",
            "Embedding number : 46995\n",
            "Embedding number : 46996\n",
            "Embedding number : 46997\n",
            "Embedding number : 46998\n",
            "Embedding number : 46999\n",
            "Embedding number : 47000\n",
            "Embedding number : 47001\n",
            "Embedding number : 47002\n",
            "Embedding number : 47003\n",
            "Embedding number : 47004\n",
            "Embedding number : 47005\n",
            "Embedding number : 47006\n",
            "Embedding number : 47007\n",
            "Embedding number : 47008\n",
            "Embedding number : 47009\n",
            "Embedding number : 47010\n",
            "Embedding number : 47011\n",
            "Embedding number : 47012\n",
            "Embedding number : 47013\n",
            "Embedding number : 47014\n",
            "Embedding number : 47015\n",
            "Embedding number : 47016\n",
            "Embedding number : 47017\n",
            "Embedding number : 47018\n",
            "Embedding number : 47019\n",
            "Embedding number : 47020\n",
            "Embedding number : 47021\n",
            "Embedding number : 47022\n",
            "Embedding number : 47023\n",
            "Embedding number : 47024\n",
            "Embedding number : 47025\n",
            "Embedding number : 47026\n",
            "Embedding number : 47027\n",
            "Embedding number : 47028\n",
            "Embedding number : 47029\n",
            "Embedding number : 47030\n",
            "Embedding number : 47031\n",
            "Embedding number : 47032\n",
            "Embedding number : 47033\n",
            "Embedding number : 47034\n",
            "Embedding number : 47035\n",
            "Embedding number : 47036\n",
            "Embedding number : 47037\n",
            "Embedding number : 47038\n",
            "Embedding number : 47039\n",
            "Embedding number : 47040\n",
            "Embedding number : 47041\n",
            "Embedding number : 47042\n",
            "Embedding number : 47043\n",
            "Embedding number : 47044\n",
            "Embedding number : 47045\n",
            "Embedding number : 47046\n",
            "Embedding number : 47047\n",
            "Embedding number : 47048\n",
            "Embedding number : 47049\n",
            "Embedding number : 47050\n",
            "Embedding number : 47051\n",
            "Embedding number : 47052\n",
            "Embedding number : 47053\n",
            "Embedding number : 47054\n",
            "Embedding number : 47055\n",
            "Embedding number : 47056\n",
            "Embedding number : 47057\n",
            "Embedding number : 47058\n",
            "Embedding number : 47059\n",
            "Embedding number : 47060\n",
            "Embedding number : 47061\n",
            "Embedding number : 47062\n",
            "Embedding number : 47063\n",
            "Embedding number : 47064\n",
            "Embedding number : 47065\n",
            "Embedding number : 47066\n",
            "Embedding number : 47067\n",
            "Embedding number : 47068\n",
            "Embedding number : 47069\n",
            "Embedding number : 47070\n",
            "Embedding number : 47071\n",
            "Embedding number : 47072\n",
            "Embedding number : 47073\n",
            "Embedding number : 47074\n",
            "Embedding number : 47075\n",
            "Embedding number : 47076\n",
            "Embedding number : 47077\n",
            "Embedding number : 47078\n",
            "Embedding number : 47079\n",
            "Embedding number : 47080\n",
            "Embedding number : 47081\n",
            "Embedding number : 47082\n",
            "Embedding number : 47083\n",
            "Embedding number : 47084\n",
            "Embedding number : 47085\n",
            "Embedding number : 47086\n",
            "Embedding number : 47087\n",
            "Embedding number : 47088\n",
            "Embedding number : 47089\n",
            "Embedding number : 47090\n",
            "Embedding number : 47091\n",
            "Embedding number : 47092\n",
            "Embedding number : 47093\n",
            "Embedding number : 47094\n",
            "Embedding number : 47095\n",
            "Embedding number : 47096\n",
            "Embedding number : 47097\n",
            "Embedding number : 47098\n",
            "Embedding number : 47099\n",
            "Embedding number : 47100\n",
            "Embedding number : 47101\n",
            "Embedding number : 47102\n",
            "Embedding number : 47103\n",
            "Embedding number : 47104\n",
            "Embedding number : 47105\n",
            "Embedding number : 47106\n",
            "Embedding number : 47107\n",
            "Embedding number : 47108\n",
            "Embedding number : 47109\n",
            "Embedding number : 47110\n",
            "Embedding number : 47111\n",
            "Embedding number : 47112\n",
            "Embedding number : 47113\n",
            "Embedding number : 47114\n",
            "Embedding number : 47115\n",
            "Embedding number : 47116\n",
            "Embedding number : 47117\n",
            "Embedding number : 47118\n",
            "Embedding number : 47119\n",
            "Embedding number : 47120\n",
            "Embedding number : 47121\n",
            "Embedding number : 47122\n",
            "Embedding number : 47123\n",
            "Embedding number : 47124\n",
            "Embedding number : 47125\n",
            "Embedding number : 47126\n",
            "Embedding number : 47127\n",
            "Embedding number : 47128\n",
            "Embedding number : 47129\n",
            "Embedding number : 47130\n",
            "Embedding number : 47131\n",
            "Embedding number : 47132\n",
            "Embedding number : 47133\n",
            "Embedding number : 47134\n",
            "Embedding number : 47135\n",
            "Embedding number : 47136\n",
            "Embedding number : 47137\n",
            "Embedding number : 47138\n",
            "Embedding number : 47139\n",
            "Embedding number : 47140\n",
            "Embedding number : 47141\n",
            "Embedding number : 47142\n",
            "Embedding number : 47143\n",
            "Embedding number : 47144\n",
            "Embedding number : 47145\n",
            "Embedding number : 47146\n",
            "Embedding number : 47147\n",
            "Embedding number : 47148\n",
            "Embedding number : 47149\n",
            "Embedding number : 47150\n",
            "Embedding number : 47151\n",
            "Embedding number : 47152\n",
            "Embedding number : 47153\n",
            "Embedding number : 47154\n",
            "Embedding number : 47155\n",
            "Embedding number : 47156\n",
            "Embedding number : 47157\n",
            "Embedding number : 47158\n",
            "Embedding number : 47159\n",
            "Embedding number : 47160\n",
            "Embedding number : 47161\n",
            "Embedding number : 47162\n",
            "Embedding number : 47163\n",
            "Embedding number : 47164\n",
            "Embedding number : 47165\n",
            "Embedding number : 47166\n",
            "Embedding number : 47167\n",
            "Embedding number : 47168\n",
            "Embedding number : 47169\n",
            "Embedding number : 47170\n",
            "Embedding number : 47171\n",
            "Embedding number : 47172\n",
            "Embedding number : 47173\n",
            "Embedding number : 47174\n",
            "Embedding number : 47175\n",
            "Embedding number : 47176\n",
            "Embedding number : 47177\n",
            "Embedding number : 47178\n",
            "Embedding number : 47179\n",
            "Embedding number : 47180\n",
            "Embedding number : 47181\n",
            "Embedding number : 47182\n",
            "Embedding number : 47183\n",
            "Embedding number : 47184\n",
            "Embedding number : 47185\n",
            "Embedding number : 47186\n",
            "Embedding number : 47187\n",
            "Embedding number : 47188\n",
            "Embedding number : 47189\n",
            "Embedding number : 47190\n",
            "Embedding number : 47191\n",
            "Embedding number : 47192\n",
            "Embedding number : 47193\n",
            "Embedding number : 47194\n",
            "Embedding number : 47195\n",
            "Embedding number : 47196\n",
            "Embedding number : 47197\n",
            "Embedding number : 47198\n",
            "Embedding number : 47199\n",
            "Embedding number : 47200\n",
            "Embedding number : 47201\n",
            "Embedding number : 47202\n",
            "Embedding number : 47203\n",
            "Embedding number : 47204\n",
            "Embedding number : 47205\n",
            "Embedding number : 47206\n",
            "Embedding number : 47207\n",
            "Embedding number : 47208\n",
            "Embedding number : 47209\n",
            "Embedding number : 47210\n",
            "Embedding number : 47211\n",
            "Embedding number : 47212\n",
            "Embedding number : 47213\n",
            "Embedding number : 47214\n",
            "Embedding number : 47215\n",
            "Embedding number : 47216\n",
            "Embedding number : 47217\n",
            "Embedding number : 47218\n",
            "Embedding number : 47219\n",
            "Embedding number : 47220\n",
            "Embedding number : 47221\n",
            "Embedding number : 47222\n",
            "Embedding number : 47223\n",
            "Embedding number : 47224\n",
            "Embedding number : 47225\n",
            "Embedding number : 47226\n",
            "Embedding number : 47227\n",
            "Embedding number : 47228\n",
            "Embedding number : 47229\n",
            "Embedding number : 47230\n",
            "Embedding number : 47231\n",
            "Embedding number : 47232\n",
            "Embedding number : 47233\n",
            "Embedding number : 47234\n",
            "Embedding number : 47235\n",
            "Embedding number : 47236\n",
            "Embedding number : 47237\n",
            "Embedding number : 47238\n",
            "Embedding number : 47239\n",
            "Embedding number : 47240\n",
            "Embedding number : 47241\n",
            "Embedding number : 47242\n",
            "Embedding number : 47243\n",
            "Embedding number : 47244\n",
            "Embedding number : 47245\n",
            "Embedding number : 47246\n",
            "Embedding number : 47247\n",
            "Embedding number : 47248\n",
            "Embedding number : 47249\n",
            "Embedding number : 47250\n",
            "Embedding number : 47251\n",
            "Embedding number : 47252\n",
            "Embedding number : 47253\n",
            "Embedding number : 47254\n",
            "Embedding number : 47255\n",
            "Embedding number : 47256\n",
            "Embedding number : 47257\n",
            "Embedding number : 47258\n",
            "Embedding number : 47259\n",
            "Embedding number : 47260\n",
            "Embedding number : 47261\n",
            "Embedding number : 47262\n",
            "Embedding number : 47263\n",
            "Embedding number : 47264\n",
            "Embedding number : 47265\n",
            "Embedding number : 47266\n",
            "Embedding number : 47267\n",
            "Embedding number : 47268\n",
            "Embedding number : 47269\n",
            "Embedding number : 47270\n",
            "Embedding number : 47271\n",
            "Embedding number : 47272\n",
            "Embedding number : 47273\n",
            "Embedding number : 47274\n",
            "Embedding number : 47275\n",
            "Embedding number : 47276\n",
            "Embedding number : 47277\n",
            "Embedding number : 47278\n",
            "Embedding number : 47279\n",
            "Embedding number : 47280\n",
            "Embedding number : 47281\n",
            "Embedding number : 47282\n",
            "Embedding number : 47283\n",
            "Embedding number : 47284\n",
            "Embedding number : 47285\n",
            "Embedding number : 47286\n",
            "Embedding number : 47287\n",
            "Embedding number : 47288\n",
            "Embedding number : 47289\n",
            "Embedding number : 47290\n",
            "Embedding number : 47291\n",
            "Embedding number : 47292\n",
            "Embedding number : 47293\n",
            "Embedding number : 47294\n",
            "Embedding number : 47295\n",
            "Embedding number : 47296\n",
            "Embedding number : 47297\n",
            "Embedding number : 47298\n",
            "Embedding number : 47299\n",
            "Embedding number : 47300\n",
            "Embedding number : 47301\n",
            "Embedding number : 47302\n",
            "Embedding number : 47303\n",
            "Embedding number : 47304\n",
            "Embedding number : 47305\n",
            "Embedding number : 47306\n",
            "Embedding number : 47307\n",
            "Embedding number : 47308\n",
            "Embedding number : 47309\n",
            "Embedding number : 47310\n",
            "Embedding number : 47311\n",
            "Embedding number : 47312\n",
            "Embedding number : 47313\n",
            "Embedding number : 47314\n",
            "Embedding number : 47315\n",
            "Embedding number : 47316\n",
            "Embedding number : 47317\n",
            "Embedding number : 47318\n",
            "Embedding number : 47319\n",
            "Embedding number : 47320\n",
            "Embedding number : 47321\n",
            "Embedding number : 47322\n",
            "Embedding number : 47323\n",
            "Embedding number : 47324\n",
            "Embedding number : 47325\n",
            "Embedding number : 47326\n",
            "Embedding number : 47327\n",
            "Embedding number : 47328\n",
            "Embedding number : 47329\n",
            "Embedding number : 47330\n",
            "Embedding number : 47331\n",
            "Embedding number : 47332\n",
            "Embedding number : 47333\n",
            "Embedding number : 47334\n",
            "Embedding number : 47335\n",
            "Embedding number : 47336\n",
            "Embedding number : 47337\n",
            "Embedding number : 47338\n",
            "Embedding number : 47339\n",
            "Embedding number : 47340\n",
            "Embedding number : 47341\n",
            "Embedding number : 47342\n",
            "Embedding number : 47343\n",
            "Embedding number : 47344\n",
            "Embedding number : 47345\n",
            "Embedding number : 47346\n",
            "Embedding number : 47347\n",
            "Embedding number : 47348\n",
            "Embedding number : 47349\n",
            "Embedding number : 47350\n",
            "Embedding number : 47351\n",
            "Embedding number : 47352\n",
            "Embedding number : 47353\n",
            "Embedding number : 47354\n",
            "Embedding number : 47355\n",
            "Embedding number : 47356\n",
            "Embedding number : 47357\n",
            "Embedding number : 47358\n",
            "Embedding number : 47359\n",
            "Embedding number : 47360\n",
            "Embedding number : 47361\n",
            "Embedding number : 47362\n",
            "Embedding number : 47363\n",
            "Embedding number : 47364\n",
            "Embedding number : 47365\n",
            "Embedding number : 47366\n",
            "Embedding number : 47367\n",
            "Embedding number : 47368\n",
            "Embedding number : 47369\n",
            "Embedding number : 47370\n",
            "Embedding number : 47371\n",
            "Embedding number : 47372\n",
            "Embedding number : 47373\n",
            "Embedding number : 47374\n",
            "Embedding number : 47375\n",
            "Embedding number : 47376\n",
            "Embedding number : 47377\n",
            "Embedding number : 47378\n",
            "Embedding number : 47379\n",
            "Embedding number : 47380\n",
            "Embedding number : 47381\n",
            "Embedding number : 47382\n",
            "Embedding number : 47383\n",
            "Embedding number : 47384\n",
            "Embedding number : 47385\n",
            "Embedding number : 47386\n",
            "Embedding number : 47387\n",
            "Embedding number : 47388\n",
            "Embedding number : 47389\n",
            "Embedding number : 47390\n",
            "Embedding number : 47391\n",
            "Embedding number : 47392\n",
            "Embedding number : 47393\n",
            "Embedding number : 47394\n",
            "Embedding number : 47395\n",
            "Embedding number : 47396\n",
            "Embedding number : 47397\n",
            "Embedding number : 47398\n",
            "Embedding number : 47399\n",
            "Embedding number : 47400\n",
            "Embedding number : 47401\n",
            "Embedding number : 47402\n",
            "Embedding number : 47403\n",
            "Embedding number : 47404\n",
            "Embedding number : 47405\n",
            "Embedding number : 47406\n",
            "Embedding number : 47407\n",
            "Embedding number : 47408\n",
            "Embedding number : 47409\n",
            "Embedding number : 47410\n",
            "Embedding number : 47411\n",
            "Embedding number : 47412\n",
            "Embedding number : 47413\n",
            "Embedding number : 47414\n",
            "Embedding number : 47415\n",
            "Embedding number : 47416\n",
            "Embedding number : 47417\n",
            "Embedding number : 47418\n",
            "Embedding number : 47419\n",
            "Embedding number : 47420\n",
            "Embedding number : 47421\n",
            "Embedding number : 47422\n",
            "Embedding number : 47423\n",
            "Embedding number : 47424\n",
            "Embedding number : 47425\n",
            "Embedding number : 47426\n",
            "Embedding number : 47427\n",
            "Embedding number : 47428\n",
            "Embedding number : 47429\n",
            "Embedding number : 47430\n",
            "Embedding number : 47431\n",
            "Embedding number : 47432\n",
            "Embedding number : 47433\n",
            "Embedding number : 47434\n",
            "Embedding number : 47435\n",
            "Embedding number : 47436\n",
            "Embedding number : 47437\n",
            "Embedding number : 47438\n",
            "Embedding number : 47439\n",
            "Embedding number : 47440\n",
            "Embedding number : 47441\n",
            "Embedding number : 47442\n",
            "Embedding number : 47443\n",
            "Embedding number : 47444\n",
            "Embedding number : 47445\n",
            "Embedding number : 47446\n",
            "Embedding number : 47447\n",
            "Embedding number : 47448\n",
            "Embedding number : 47449\n",
            "Embedding number : 47450\n",
            "Embedding number : 47451\n",
            "Embedding number : 47452\n",
            "Embedding number : 47453\n",
            "Embedding number : 47454\n",
            "Embedding number : 47455\n",
            "Embedding number : 47456\n",
            "Embedding number : 47457\n",
            "Embedding number : 47458\n",
            "Embedding number : 47459\n",
            "Embedding number : 47460\n",
            "Embedding number : 47461\n",
            "Embedding number : 47462\n",
            "Embedding number : 47463\n",
            "Embedding number : 47464\n",
            "Embedding number : 47465\n",
            "Embedding number : 47466\n",
            "Embedding number : 47467\n",
            "Embedding number : 47468\n",
            "Embedding number : 47469\n",
            "Embedding number : 47470\n",
            "Embedding number : 47471\n",
            "Embedding number : 47472\n",
            "Embedding number : 47473\n",
            "Embedding number : 47474\n",
            "Embedding number : 47475\n",
            "Embedding number : 47476\n",
            "Embedding number : 47477\n",
            "Embedding number : 47478\n",
            "Embedding number : 47479\n",
            "Embedding number : 47480\n",
            "Embedding number : 47481\n",
            "Embedding number : 47482\n",
            "Embedding number : 47483\n",
            "Embedding number : 47484\n",
            "Embedding number : 47485\n",
            "Embedding number : 47486\n",
            "Embedding number : 47487\n",
            "Embedding number : 47488\n",
            "Embedding number : 47489\n",
            "Embedding number : 47490\n",
            "Embedding number : 47491\n",
            "Embedding number : 47492\n",
            "Embedding number : 47493\n",
            "Embedding number : 47494\n",
            "Embedding number : 47495\n",
            "Embedding number : 47496\n",
            "Embedding number : 47497\n",
            "Embedding number : 47498\n",
            "Embedding number : 47499\n",
            "Embedding number : 47500\n",
            "Embedding number : 47501\n",
            "Embedding number : 47502\n",
            "Embedding number : 47503\n",
            "Embedding number : 47504\n",
            "Embedding number : 47505\n",
            "Embedding number : 47506\n",
            "Embedding number : 47507\n",
            "Embedding number : 47508\n",
            "Embedding number : 47509\n",
            "Embedding number : 47510\n",
            "Embedding number : 47511\n",
            "Embedding number : 47512\n",
            "Embedding number : 47513\n",
            "Embedding number : 47514\n",
            "Embedding number : 47515\n",
            "Embedding number : 47516\n",
            "Embedding number : 47517\n",
            "Embedding number : 47518\n",
            "Embedding number : 47519\n",
            "Embedding number : 47520\n",
            "Embedding number : 47521\n",
            "Embedding number : 47522\n",
            "Embedding number : 47523\n",
            "Embedding number : 47524\n",
            "Embedding number : 47525\n",
            "Embedding number : 47526\n",
            "Embedding number : 47527\n",
            "Embedding number : 47528\n",
            "Embedding number : 47529\n",
            "Embedding number : 47530\n",
            "Embedding number : 47531\n",
            "Embedding number : 47532\n",
            "Embedding number : 47533\n",
            "Embedding number : 47534\n",
            "Embedding number : 47535\n",
            "Embedding number : 47536\n",
            "Embedding number : 47537\n",
            "Embedding number : 47538\n",
            "Embedding number : 47539\n",
            "Embedding number : 47540\n",
            "Embedding number : 47541\n",
            "Embedding number : 47542\n",
            "Embedding number : 47543\n",
            "Embedding number : 47544\n",
            "Embedding number : 47545\n",
            "Embedding number : 47546\n",
            "Embedding number : 47547\n",
            "Embedding number : 47548\n",
            "Embedding number : 47549\n",
            "Embedding number : 47550\n",
            "Embedding number : 47551\n",
            "Embedding number : 47552\n",
            "Embedding number : 47553\n",
            "Embedding number : 47554\n",
            "Embedding number : 47555\n",
            "Embedding number : 47556\n",
            "Embedding number : 47557\n",
            "Embedding number : 47558\n",
            "Embedding number : 47559\n",
            "Embedding number : 47560\n",
            "Embedding number : 47561\n",
            "Embedding number : 47562\n",
            "Embedding number : 47563\n",
            "Embedding number : 47564\n",
            "Embedding number : 47565\n",
            "Embedding number : 47566\n",
            "Embedding number : 47567\n",
            "Embedding number : 47568\n",
            "Embedding number : 47569\n",
            "Embedding number : 47570\n",
            "Embedding number : 47571\n",
            "Embedding number : 47572\n",
            "Embedding number : 47573\n",
            "Embedding number : 47574\n",
            "Embedding number : 47575\n",
            "Embedding number : 47576\n",
            "Embedding number : 47577\n",
            "Embedding number : 47578\n",
            "Embedding number : 47579\n",
            "Embedding number : 47580\n",
            "Embedding number : 47581\n",
            "Embedding number : 47582\n",
            "Embedding number : 47583\n",
            "Embedding number : 47584\n",
            "Embedding number : 47585\n",
            "Embedding number : 47586\n",
            "Embedding number : 47587\n",
            "Embedding number : 47588\n",
            "Embedding number : 47589\n",
            "Embedding number : 47590\n",
            "Embedding number : 47591\n",
            "Embedding number : 47592\n",
            "Embedding number : 47593\n",
            "Embedding number : 47594\n",
            "Embedding number : 47595\n",
            "Embedding number : 47596\n",
            "Embedding number : 47597\n",
            "Embedding number : 47598\n",
            "Embedding number : 47599\n",
            "Embedding number : 47600\n",
            "Embedding number : 47601\n",
            "Embedding number : 47602\n",
            "Embedding number : 47603\n",
            "Embedding number : 47604\n",
            "Embedding number : 47605\n",
            "Embedding number : 47606\n",
            "Embedding number : 47607\n",
            "Embedding number : 47608\n",
            "Embedding number : 47609\n",
            "Embedding number : 47610\n",
            "Embedding number : 47611\n",
            "Embedding number : 47612\n",
            "Embedding number : 47613\n",
            "Embedding number : 47614\n",
            "Embedding number : 47615\n",
            "Embedding number : 47616\n",
            "Embedding number : 47617\n",
            "Embedding number : 47618\n",
            "Embedding number : 47619\n",
            "Embedding number : 47620\n",
            "Embedding number : 47621\n",
            "Embedding number : 47622\n",
            "Embedding number : 47623\n",
            "Embedding number : 47624\n",
            "Embedding number : 47625\n",
            "Embedding number : 47626\n",
            "Embedding number : 47627\n",
            "Embedding number : 47628\n",
            "Embedding number : 47629\n",
            "Embedding number : 47630\n",
            "Embedding number : 47631\n",
            "Embedding number : 47632\n",
            "Embedding number : 47633\n",
            "Embedding number : 47634\n",
            "Embedding number : 47635\n",
            "Embedding number : 47636\n",
            "Embedding number : 47637\n",
            "Embedding number : 47638\n",
            "Embedding number : 47639\n",
            "Embedding number : 47640\n",
            "Embedding number : 47641\n",
            "Embedding number : 47642\n",
            "Embedding number : 47643\n",
            "Embedding number : 47644\n",
            "Embedding number : 47645\n",
            "Embedding number : 47646\n",
            "Embedding number : 47647\n",
            "Embedding number : 47648\n",
            "Embedding number : 47649\n",
            "Embedding number : 47650\n",
            "Embedding number : 47651\n",
            "Embedding number : 47652\n",
            "Embedding number : 47653\n",
            "Embedding number : 47654\n",
            "Embedding number : 47655\n",
            "Embedding number : 47656\n",
            "Embedding number : 47657\n",
            "Embedding number : 47658\n",
            "Embedding number : 47659\n",
            "Embedding number : 47660\n",
            "Embedding number : 47661\n",
            "Embedding number : 47662\n",
            "Embedding number : 47663\n",
            "Embedding number : 47664\n",
            "Embedding number : 47665\n",
            "Embedding number : 47666\n",
            "Embedding number : 47667\n",
            "Embedding number : 47668\n",
            "Embedding number : 47669\n",
            "Embedding number : 47670\n",
            "Embedding number : 47671\n",
            "Embedding number : 47672\n",
            "Embedding number : 47673\n",
            "Embedding number : 47674\n",
            "Embedding number : 47675\n",
            "Embedding number : 47676\n",
            "Embedding number : 47677\n",
            "Embedding number : 47678\n",
            "Embedding number : 47679\n",
            "Embedding number : 47680\n",
            "Embedding number : 47681\n",
            "Embedding number : 47682\n",
            "Embedding number : 47683\n",
            "Embedding number : 47684\n",
            "Embedding number : 47685\n",
            "Embedding number : 47686\n",
            "Embedding number : 47687\n",
            "Embedding number : 47688\n",
            "Embedding number : 47689\n",
            "Embedding number : 47690\n",
            "Embedding number : 47691\n",
            "Embedding number : 47692\n",
            "Embedding number : 47693\n",
            "Embedding number : 47694\n",
            "Embedding number : 47695\n",
            "Embedding number : 47696\n",
            "Embedding number : 47697\n",
            "Embedding number : 47698\n",
            "Embedding number : 47699\n",
            "Embedding number : 47700\n",
            "Embedding number : 47701\n",
            "Embedding number : 47702\n",
            "Embedding number : 47703\n",
            "Embedding number : 47704\n",
            "Embedding number : 47705\n",
            "Embedding number : 47706\n",
            "Embedding number : 47707\n",
            "Embedding number : 47708\n",
            "Embedding number : 47709\n",
            "Embedding number : 47710\n",
            "Embedding number : 47711\n",
            "Embedding number : 47712\n",
            "Embedding number : 47713\n",
            "Embedding number : 47714\n",
            "Embedding number : 47715\n",
            "Embedding number : 47716\n",
            "Embedding number : 47717\n",
            "Embedding number : 47718\n",
            "Embedding number : 47719\n",
            "Embedding number : 47720\n",
            "Embedding number : 47721\n",
            "Embedding number : 47722\n",
            "Embedding number : 47723\n",
            "Embedding number : 47724\n",
            "Embedding number : 47725\n",
            "Embedding number : 47726\n",
            "Embedding number : 47727\n",
            "Embedding number : 47728\n",
            "Embedding number : 47729\n",
            "Embedding number : 47730\n",
            "Embedding number : 47731\n",
            "Embedding number : 47732\n",
            "Embedding number : 47733\n",
            "Embedding number : 47734\n",
            "Embedding number : 47735\n",
            "Embedding number : 47736\n",
            "Embedding number : 47737\n",
            "Embedding number : 47738\n",
            "Embedding number : 47739\n",
            "Embedding number : 47740\n",
            "Embedding number : 47741\n",
            "Embedding number : 47742\n",
            "Embedding number : 47743\n",
            "Embedding number : 47744\n",
            "Embedding number : 47745\n",
            "Embedding number : 47746\n",
            "Embedding number : 47747\n",
            "Embedding number : 47748\n",
            "Embedding number : 47749\n",
            "Embedding number : 47750\n",
            "Embedding number : 47751\n",
            "Embedding number : 47752\n",
            "Embedding number : 47753\n",
            "Embedding number : 47754\n",
            "Embedding number : 47755\n",
            "Embedding number : 47756\n",
            "Embedding number : 47757\n",
            "Embedding number : 47758\n",
            "Embedding number : 47759\n",
            "Embedding number : 47760\n",
            "Embedding number : 47761\n",
            "Embedding number : 47762\n",
            "Embedding number : 47763\n",
            "Embedding number : 47764\n",
            "Embedding number : 47765\n",
            "Embedding number : 47766\n",
            "Embedding number : 47767\n",
            "Embedding number : 47768\n",
            "Embedding number : 47769\n",
            "Embedding number : 47770\n",
            "Embedding number : 47771\n",
            "Embedding number : 47772\n",
            "Embedding number : 47773\n",
            "Embedding number : 47774\n",
            "Embedding number : 47775\n",
            "Embedding number : 47776\n",
            "Embedding number : 47777\n",
            "Embedding number : 47778\n",
            "Embedding number : 47779\n",
            "Embedding number : 47780\n",
            "Embedding number : 47781\n",
            "Embedding number : 47782\n",
            "Embedding number : 47783\n",
            "Embedding number : 47784\n",
            "Embedding number : 47785\n",
            "Embedding number : 47786\n",
            "Embedding number : 47787\n",
            "Embedding number : 47788\n",
            "Embedding number : 47789\n",
            "Embedding number : 47790\n",
            "Embedding number : 47791\n",
            "Embedding number : 47792\n",
            "Embedding number : 47793\n",
            "Embedding number : 47794\n",
            "Embedding number : 47795\n",
            "Embedding number : 47796\n",
            "Embedding number : 47797\n",
            "Embedding number : 47798\n",
            "Embedding number : 47799\n",
            "Embedding number : 47800\n",
            "Embedding number : 47801\n",
            "Embedding number : 47802\n",
            "Embedding number : 47803\n",
            "Embedding number : 47804\n",
            "Embedding number : 47805\n",
            "Embedding number : 47806\n",
            "Embedding number : 47807\n",
            "Embedding number : 47808\n",
            "Embedding number : 47809\n",
            "Embedding number : 47810\n",
            "Embedding number : 47811\n",
            "Embedding number : 47812\n",
            "Embedding number : 47813\n",
            "Embedding number : 47814\n",
            "Embedding number : 47815\n",
            "Embedding number : 47816\n",
            "Embedding number : 47817\n",
            "Embedding number : 47818\n",
            "Embedding number : 47819\n",
            "Embedding number : 47820\n",
            "Embedding number : 47821\n",
            "Embedding number : 47822\n",
            "Embedding number : 47823\n",
            "Embedding number : 47824\n",
            "Embedding number : 47825\n",
            "Embedding number : 47826\n",
            "Embedding number : 47827\n",
            "Embedding number : 47828\n",
            "Embedding number : 47829\n",
            "Embedding number : 47830\n",
            "Embedding number : 47831\n",
            "Embedding number : 47832\n",
            "Embedding number : 47833\n",
            "Embedding number : 47834\n",
            "Embedding number : 47835\n",
            "Embedding number : 47836\n",
            "Embedding number : 47837\n",
            "Embedding number : 47838\n",
            "Embedding number : 47839\n",
            "Embedding number : 47840\n",
            "Embedding number : 47841\n",
            "Embedding number : 47842\n",
            "Embedding number : 47843\n",
            "Embedding number : 47844\n",
            "Embedding number : 47845\n",
            "Embedding number : 47846\n",
            "Embedding number : 47847\n",
            "Embedding number : 47848\n",
            "Embedding number : 47849\n",
            "Embedding number : 47850\n",
            "Embedding number : 47851\n",
            "Embedding number : 47852\n",
            "Embedding number : 47853\n",
            "Embedding number : 47854\n",
            "Embedding number : 47855\n",
            "Embedding number : 47856\n",
            "Embedding number : 47857\n",
            "Embedding number : 47858\n",
            "Embedding number : 47859\n",
            "Embedding number : 47860\n",
            "Embedding number : 47861\n",
            "Embedding number : 47862\n",
            "Embedding number : 47863\n",
            "Embedding number : 47864\n",
            "Embedding number : 47865\n",
            "Embedding number : 47866\n",
            "Embedding number : 47867\n",
            "Embedding number : 47868\n",
            "Embedding number : 47869\n",
            "Embedding number : 47870\n",
            "Embedding number : 47871\n",
            "Embedding number : 47872\n",
            "Embedding number : 47873\n",
            "Embedding number : 47874\n",
            "Embedding number : 47875\n",
            "Embedding number : 47876\n",
            "Embedding number : 47877\n",
            "Embedding number : 47878\n",
            "Embedding number : 47879\n",
            "Embedding number : 47880\n",
            "Embedding number : 47881\n",
            "Embedding number : 47882\n",
            "Embedding number : 47883\n",
            "Embedding number : 47884\n",
            "Embedding number : 47885\n",
            "Embedding number : 47886\n",
            "Embedding number : 47887\n",
            "Embedding number : 47888\n",
            "Embedding number : 47889\n",
            "Embedding number : 47890\n",
            "Embedding number : 47891\n",
            "Embedding number : 47892\n",
            "Embedding number : 47893\n",
            "Embedding number : 47894\n",
            "Embedding number : 47895\n",
            "Embedding number : 47896\n",
            "Embedding number : 47897\n",
            "Embedding number : 47898\n",
            "Embedding number : 47899\n",
            "Embedding number : 47900\n",
            "Embedding number : 47901\n",
            "Embedding number : 47902\n",
            "Embedding number : 47903\n",
            "Embedding number : 47904\n",
            "Embedding number : 47905\n",
            "Embedding number : 47906\n",
            "Embedding number : 47907\n",
            "Embedding number : 47908\n",
            "Embedding number : 47909\n",
            "Embedding number : 47910\n",
            "Embedding number : 47911\n",
            "Embedding number : 47912\n",
            "Embedding number : 47913\n",
            "Embedding number : 47914\n",
            "Embedding number : 47915\n",
            "Embedding number : 47916\n",
            "Embedding number : 47917\n",
            "Embedding number : 47918\n",
            "Embedding number : 47919\n",
            "Embedding number : 47920\n",
            "Embedding number : 47921\n",
            "Embedding number : 47922\n",
            "Embedding number : 47923\n",
            "Embedding number : 47924\n",
            "Embedding number : 47925\n",
            "Embedding number : 47926\n",
            "Embedding number : 47927\n",
            "Embedding number : 47928\n",
            "Embedding number : 47929\n",
            "Embedding number : 47930\n",
            "Embedding number : 47931\n",
            "Embedding number : 47932\n",
            "Embedding number : 47933\n",
            "Embedding number : 47934\n",
            "Embedding number : 47935\n",
            "Embedding number : 47936\n",
            "Embedding number : 47937\n",
            "Embedding number : 47938\n",
            "Embedding number : 47939\n",
            "Embedding number : 47940\n",
            "Embedding number : 47941\n",
            "Embedding number : 47942\n",
            "Embedding number : 47943\n",
            "Embedding number : 47944\n",
            "Embedding number : 47945\n",
            "Embedding number : 47946\n",
            "Embedding number : 47947\n",
            "Embedding number : 47948\n",
            "Embedding number : 47949\n",
            "Embedding number : 47950\n",
            "Embedding number : 47951\n",
            "Embedding number : 47952\n",
            "Embedding number : 47953\n",
            "Embedding number : 47954\n",
            "Embedding number : 47955\n",
            "Embedding number : 47956\n",
            "Embedding number : 47957\n",
            "Embedding number : 47958\n",
            "Embedding number : 47959\n",
            "Embedding number : 47960\n",
            "Embedding number : 47961\n",
            "Embedding number : 47962\n",
            "Embedding number : 47963\n",
            "Embedding number : 47964\n",
            "Embedding number : 47965\n",
            "Embedding number : 47966\n",
            "Embedding number : 47967\n",
            "Embedding number : 47968\n",
            "Embedding number : 47969\n",
            "Embedding number : 47970\n",
            "Embedding number : 47971\n",
            "Embedding number : 47972\n",
            "Embedding number : 47973\n",
            "Embedding number : 47974\n",
            "Embedding number : 47975\n",
            "Embedding number : 47976\n",
            "Embedding number : 47977\n",
            "Embedding number : 47978\n",
            "Embedding number : 47979\n",
            "Embedding number : 47980\n",
            "Embedding number : 47981\n",
            "Embedding number : 47982\n",
            "Embedding number : 47983\n",
            "Embedding number : 47984\n",
            "Embedding number : 47985\n",
            "Embedding number : 47986\n",
            "Embedding number : 47987\n",
            "Embedding number : 47988\n",
            "Embedding number : 47989\n",
            "Embedding number : 47990\n",
            "Embedding number : 47991\n",
            "Embedding number : 47992\n",
            "Embedding number : 47993\n",
            "Embedding number : 47994\n",
            "Embedding number : 47995\n",
            "Embedding number : 47996\n",
            "Embedding number : 47997\n",
            "Embedding number : 47998\n",
            "Embedding number : 47999\n",
            "Embedding number : 48000\n",
            "Embedding number : 48001\n",
            "Embedding number : 48002\n",
            "Embedding number : 48003\n",
            "Embedding number : 48004\n",
            "Embedding number : 48005\n",
            "Embedding number : 48006\n",
            "Embedding number : 48007\n",
            "Embedding number : 48008\n",
            "Embedding number : 48009\n",
            "Embedding number : 48010\n",
            "Embedding number : 48011\n",
            "Embedding number : 48012\n",
            "Embedding number : 48013\n",
            "Embedding number : 48014\n",
            "Embedding number : 48015\n",
            "Embedding number : 48016\n",
            "Embedding number : 48017\n",
            "Embedding number : 48018\n",
            "Embedding number : 48019\n",
            "Embedding number : 48020\n",
            "Embedding number : 48021\n",
            "Embedding number : 48022\n",
            "Embedding number : 48023\n",
            "Embedding number : 48024\n",
            "Embedding number : 48025\n",
            "Embedding number : 48026\n",
            "Embedding number : 48027\n",
            "Embedding number : 48028\n",
            "Embedding number : 48029\n",
            "Embedding number : 48030\n",
            "Embedding number : 48031\n",
            "Embedding number : 48032\n",
            "Embedding number : 48033\n",
            "Embedding number : 48034\n",
            "Embedding number : 48035\n",
            "Embedding number : 48036\n",
            "Embedding number : 48037\n",
            "Embedding number : 48038\n",
            "Embedding number : 48039\n",
            "Embedding number : 48040\n",
            "Embedding number : 48041\n",
            "Embedding number : 48042\n",
            "Embedding number : 48043\n",
            "Embedding number : 48044\n",
            "Embedding number : 48045\n",
            "Embedding number : 48046\n",
            "Embedding number : 48047\n",
            "Embedding number : 48048\n",
            "Embedding number : 48049\n",
            "Embedding number : 48050\n",
            "Embedding number : 48051\n",
            "Embedding number : 48052\n",
            "Embedding number : 48053\n",
            "Embedding number : 48054\n",
            "Embedding number : 48055\n",
            "Embedding number : 48056\n",
            "Embedding number : 48057\n",
            "Embedding number : 48058\n",
            "Embedding number : 48059\n",
            "Embedding number : 48060\n",
            "Embedding number : 48061\n",
            "Embedding number : 48062\n",
            "Embedding number : 48063\n",
            "Embedding number : 48064\n",
            "Embedding number : 48065\n",
            "Embedding number : 48066\n",
            "Embedding number : 48067\n",
            "Embedding number : 48068\n",
            "Embedding number : 48069\n",
            "Embedding number : 48070\n",
            "Embedding number : 48071\n",
            "Embedding number : 48072\n",
            "Embedding number : 48073\n",
            "Embedding number : 48074\n",
            "Embedding number : 48075\n",
            "Embedding number : 48076\n",
            "Embedding number : 48077\n",
            "Embedding number : 48078\n",
            "Embedding number : 48079\n",
            "Embedding number : 48080\n",
            "Embedding number : 48081\n",
            "Embedding number : 48082\n",
            "Embedding number : 48083\n",
            "Embedding number : 48084\n",
            "Embedding number : 48085\n",
            "Embedding number : 48086\n",
            "Embedding number : 48087\n",
            "Embedding number : 48088\n",
            "Embedding number : 48089\n",
            "Embedding number : 48090\n",
            "Embedding number : 48091\n",
            "Embedding number : 48092\n",
            "Embedding number : 48093\n",
            "Embedding number : 48094\n",
            "Embedding number : 48095\n",
            "Embedding number : 48096\n",
            "Embedding number : 48097\n",
            "Embedding number : 48098\n",
            "Embedding number : 48099\n",
            "Embedding number : 48100\n",
            "Embedding number : 48101\n",
            "Embedding number : 48102\n",
            "Embedding number : 48103\n",
            "Embedding number : 48104\n",
            "Embedding number : 48105\n",
            "Embedding number : 48106\n",
            "Embedding number : 48107\n",
            "Embedding number : 48108\n",
            "Embedding number : 48109\n",
            "Embedding number : 48110\n",
            "Embedding number : 48111\n",
            "Embedding number : 48112\n",
            "Embedding number : 48113\n",
            "Embedding number : 48114\n",
            "Embedding number : 48115\n",
            "Embedding number : 48116\n",
            "Embedding number : 48117\n",
            "Embedding number : 48118\n",
            "Embedding number : 48119\n",
            "Embedding number : 48120\n",
            "Embedding number : 48121\n",
            "Embedding number : 48122\n",
            "Embedding number : 48123\n",
            "Embedding number : 48124\n",
            "Embedding number : 48125\n",
            "Embedding number : 48126\n",
            "Embedding number : 48127\n",
            "Embedding number : 48128\n",
            "Embedding number : 48129\n",
            "Embedding number : 48130\n",
            "Embedding number : 48131\n",
            "Embedding number : 48132\n",
            "Embedding number : 48133\n",
            "Embedding number : 48134\n",
            "Embedding number : 48135\n",
            "Embedding number : 48136\n",
            "Embedding number : 48137\n",
            "Embedding number : 48138\n",
            "Embedding number : 48139\n",
            "Embedding number : 48140\n",
            "Embedding number : 48141\n",
            "Embedding number : 48142\n",
            "Embedding number : 48143\n",
            "Embedding number : 48144\n",
            "Embedding number : 48145\n",
            "Embedding number : 48146\n",
            "Embedding number : 48147\n",
            "Embedding number : 48148\n",
            "Embedding number : 48149\n",
            "Embedding number : 48150\n",
            "Embedding number : 48151\n",
            "Embedding number : 48152\n",
            "Embedding number : 48153\n",
            "Embedding number : 48154\n",
            "Embedding number : 48155\n",
            "Embedding number : 48156\n",
            "Embedding number : 48157\n",
            "Embedding number : 48158\n",
            "Embedding number : 48159\n",
            "Embedding number : 48160\n",
            "Embedding number : 48161\n",
            "Embedding number : 48162\n",
            "Embedding number : 48163\n",
            "Embedding number : 48164\n",
            "Embedding number : 48165\n",
            "Embedding number : 48166\n",
            "Embedding number : 48167\n",
            "Embedding number : 48168\n",
            "Embedding number : 48169\n",
            "Embedding number : 48170\n",
            "Embedding number : 48171\n",
            "Embedding number : 48172\n",
            "Embedding number : 48173\n",
            "Embedding number : 48174\n",
            "Embedding number : 48175\n",
            "Embedding number : 48176\n",
            "Embedding number : 48177\n",
            "Embedding number : 48178\n",
            "Embedding number : 48179\n",
            "Embedding number : 48180\n",
            "Embedding number : 48181\n",
            "Embedding number : 48182\n",
            "Embedding number : 48183\n",
            "Embedding number : 48184\n",
            "Embedding number : 48185\n",
            "Embedding number : 48186\n",
            "Embedding number : 48187\n",
            "Embedding number : 48188\n",
            "Embedding number : 48189\n",
            "Embedding number : 48190\n",
            "Embedding number : 48191\n",
            "Embedding number : 48192\n",
            "Embedding number : 48193\n",
            "Embedding number : 48194\n",
            "Embedding number : 48195\n",
            "Embedding number : 48196\n",
            "Embedding number : 48197\n",
            "Embedding number : 48198\n",
            "Embedding number : 48199\n",
            "Embedding number : 48200\n",
            "Embedding number : 48201\n",
            "Embedding number : 48202\n",
            "Embedding number : 48203\n",
            "Embedding number : 48204\n",
            "Embedding number : 48205\n",
            "Embedding number : 48206\n",
            "Embedding number : 48207\n",
            "Embedding number : 48208\n",
            "Embedding number : 48209\n",
            "Embedding number : 48210\n",
            "Embedding number : 48211\n",
            "Embedding number : 48212\n",
            "Embedding number : 48213\n",
            "Embedding number : 48214\n",
            "Embedding number : 48215\n",
            "Embedding number : 48216\n",
            "Embedding number : 48217\n",
            "Embedding number : 48218\n",
            "Embedding number : 48219\n",
            "Embedding number : 48220\n",
            "Embedding number : 48221\n",
            "Embedding number : 48222\n",
            "Embedding number : 48223\n",
            "Embedding number : 48224\n",
            "Embedding number : 48225\n",
            "Embedding number : 48226\n",
            "Embedding number : 48227\n",
            "Embedding number : 48228\n",
            "Embedding number : 48229\n",
            "Embedding number : 48230\n",
            "Embedding number : 48231\n",
            "Embedding number : 48232\n",
            "Embedding number : 48233\n",
            "Embedding number : 48234\n",
            "Embedding number : 48235\n",
            "Embedding number : 48236\n",
            "Embedding number : 48237\n",
            "Embedding number : 48238\n",
            "Embedding number : 48239\n",
            "Embedding number : 48240\n",
            "Embedding number : 48241\n",
            "Embedding number : 48242\n",
            "Embedding number : 48243\n",
            "Embedding number : 48244\n",
            "Embedding number : 48245\n",
            "Embedding number : 48246\n",
            "Embedding number : 48247\n",
            "Embedding number : 48248\n",
            "Embedding number : 48249\n",
            "Embedding number : 48250\n",
            "Embedding number : 48251\n",
            "Embedding number : 48252\n",
            "Embedding number : 48253\n",
            "Embedding number : 48254\n",
            "Embedding number : 48255\n",
            "Embedding number : 48256\n",
            "Embedding number : 48257\n",
            "Embedding number : 48258\n",
            "Embedding number : 48259\n",
            "Embedding number : 48260\n",
            "Embedding number : 48261\n",
            "Embedding number : 48262\n",
            "Embedding number : 48263\n",
            "Embedding number : 48264\n",
            "Embedding number : 48265\n",
            "Embedding number : 48266\n",
            "Embedding number : 48267\n",
            "Embedding number : 48268\n",
            "Embedding number : 48269\n",
            "Embedding number : 48270\n",
            "Embedding number : 48271\n",
            "Embedding number : 48272\n",
            "Embedding number : 48273\n",
            "Embedding number : 48274\n",
            "Embedding number : 48275\n",
            "Embedding number : 48276\n",
            "Embedding number : 48277\n",
            "Embedding number : 48278\n",
            "Embedding number : 48279\n",
            "Embedding number : 48280\n",
            "Embedding number : 48281\n",
            "Embedding number : 48282\n",
            "Embedding number : 48283\n",
            "Embedding number : 48284\n",
            "Embedding number : 48285\n",
            "Embedding number : 48286\n",
            "Embedding number : 48287\n",
            "Embedding number : 48288\n",
            "Embedding number : 48289\n",
            "Embedding number : 48290\n",
            "Embedding number : 48291\n",
            "Embedding number : 48292\n",
            "Embedding number : 48293\n",
            "Embedding number : 48294\n",
            "Embedding number : 48295\n",
            "Embedding number : 48296\n",
            "Embedding number : 48297\n",
            "Embedding number : 48298\n",
            "Embedding number : 48299\n",
            "Embedding number : 48300\n",
            "Embedding number : 48301\n",
            "Embedding number : 48302\n",
            "Embedding number : 48303\n",
            "Embedding number : 48304\n",
            "Embedding number : 48305\n",
            "Embedding number : 48306\n",
            "Embedding number : 48307\n",
            "Embedding number : 48308\n",
            "Embedding number : 48309\n",
            "Embedding number : 48310\n",
            "Embedding number : 48311\n",
            "Embedding number : 48312\n",
            "Embedding number : 48313\n",
            "Embedding number : 48314\n",
            "Embedding number : 48315\n",
            "Embedding number : 48316\n",
            "Embedding number : 48317\n",
            "Embedding number : 48318\n",
            "Embedding number : 48319\n",
            "Embedding number : 48320\n",
            "Embedding number : 48321\n",
            "Embedding number : 48322\n",
            "Embedding number : 48323\n",
            "Embedding number : 48324\n",
            "Embedding number : 48325\n",
            "Embedding number : 48326\n",
            "Embedding number : 48327\n",
            "Embedding number : 48328\n",
            "Embedding number : 48329\n",
            "Embedding number : 48330\n",
            "Embedding number : 48331\n",
            "Embedding number : 48332\n",
            "Embedding number : 48333\n",
            "Embedding number : 48334\n",
            "Embedding number : 48335\n",
            "Embedding number : 48336\n",
            "Embedding number : 48337\n",
            "Embedding number : 48338\n",
            "Embedding number : 48339\n",
            "Embedding number : 48340\n",
            "Embedding number : 48341\n",
            "Embedding number : 48342\n",
            "Embedding number : 48343\n",
            "Embedding number : 48344\n",
            "Embedding number : 48345\n",
            "Embedding number : 48346\n",
            "Embedding number : 48347\n",
            "Embedding number : 48348\n",
            "Embedding number : 48349\n",
            "Embedding number : 48350\n",
            "Embedding number : 48351\n",
            "Embedding number : 48352\n",
            "Embedding number : 48353\n",
            "Embedding number : 48354\n",
            "Embedding number : 48355\n",
            "Embedding number : 48356\n",
            "Embedding number : 48357\n",
            "Embedding number : 48358\n",
            "Embedding number : 48359\n",
            "Embedding number : 48360\n",
            "Embedding number : 48361\n",
            "Embedding number : 48362\n",
            "Embedding number : 48363\n",
            "Embedding number : 48364\n",
            "Embedding number : 48365\n",
            "Embedding number : 48366\n",
            "Embedding number : 48367\n",
            "Embedding number : 48368\n",
            "Embedding number : 48369\n",
            "Embedding number : 48370\n",
            "Embedding number : 48371\n",
            "Embedding number : 48372\n",
            "Embedding number : 48373\n",
            "Embedding number : 48374\n",
            "Embedding number : 48375\n",
            "Embedding number : 48376\n",
            "Embedding number : 48377\n",
            "Embedding number : 48378\n",
            "Embedding number : 48379\n",
            "Embedding number : 48380\n",
            "Embedding number : 48381\n",
            "Embedding number : 48382\n",
            "Embedding number : 48383\n",
            "Embedding number : 48384\n",
            "Embedding number : 48385\n",
            "Embedding number : 48386\n",
            "Embedding number : 48387\n",
            "Embedding number : 48388\n",
            "Embedding number : 48389\n",
            "Embedding number : 48390\n",
            "Embedding number : 48391\n",
            "Embedding number : 48392\n",
            "Embedding number : 48393\n",
            "Embedding number : 48394\n",
            "Embedding number : 48395\n",
            "Embedding number : 48396\n",
            "Embedding number : 48397\n",
            "Embedding number : 48398\n",
            "Embedding number : 48399\n",
            "Embedding number : 48400\n",
            "Embedding number : 48401\n",
            "Embedding number : 48402\n",
            "Embedding number : 48403\n",
            "Embedding number : 48404\n",
            "Embedding number : 48405\n",
            "Embedding number : 48406\n",
            "Embedding number : 48407\n",
            "Embedding number : 48408\n",
            "Embedding number : 48409\n",
            "Embedding number : 48410\n",
            "Embedding number : 48411\n",
            "Embedding number : 48412\n",
            "Embedding number : 48413\n",
            "Embedding number : 48414\n",
            "Embedding number : 48415\n",
            "Embedding number : 48416\n",
            "Embedding number : 48417\n",
            "Embedding number : 48418\n",
            "Embedding number : 48419\n",
            "Embedding number : 48420\n",
            "Embedding number : 48421\n",
            "Embedding number : 48422\n",
            "Embedding number : 48423\n",
            "Embedding number : 48424\n",
            "Embedding number : 48425\n",
            "Embedding number : 48426\n",
            "Embedding number : 48427\n",
            "Embedding number : 48428\n",
            "Embedding number : 48429\n",
            "Embedding number : 48430\n",
            "Embedding number : 48431\n",
            "Embedding number : 48432\n",
            "Embedding number : 48433\n",
            "Embedding number : 48434\n",
            "Embedding number : 48435\n",
            "Embedding number : 48436\n",
            "Embedding number : 48437\n",
            "Embedding number : 48438\n",
            "Embedding number : 48439\n",
            "Embedding number : 48440\n",
            "Embedding number : 48441\n",
            "Embedding number : 48442\n",
            "Embedding number : 48443\n",
            "Embedding number : 48444\n",
            "Embedding number : 48445\n",
            "Embedding number : 48446\n",
            "Embedding number : 48447\n",
            "Embedding number : 48448\n",
            "Embedding number : 48449\n",
            "Embedding number : 48450\n",
            "Embedding number : 48451\n",
            "Embedding number : 48452\n",
            "Embedding number : 48453\n",
            "Embedding number : 48454\n",
            "Embedding number : 48455\n",
            "Embedding number : 48456\n",
            "Embedding number : 48457\n",
            "Embedding number : 48458\n",
            "Embedding number : 48459\n",
            "Embedding number : 48460\n",
            "Embedding number : 48461\n",
            "Embedding number : 48462\n",
            "Embedding number : 48463\n",
            "Embedding number : 48464\n",
            "Embedding number : 48465\n",
            "Embedding number : 48466\n",
            "Embedding number : 48467\n",
            "Embedding number : 48468\n",
            "Embedding number : 48469\n",
            "Embedding number : 48470\n",
            "Embedding number : 48471\n",
            "Embedding number : 48472\n",
            "Embedding number : 48473\n",
            "Embedding number : 48474\n",
            "Embedding number : 48475\n",
            "Embedding number : 48476\n",
            "Embedding number : 48477\n",
            "Embedding number : 48478\n",
            "Embedding number : 48479\n",
            "Embedding number : 48480\n",
            "Embedding number : 48481\n",
            "Embedding number : 48482\n",
            "Embedding number : 48483\n",
            "Embedding number : 48484\n",
            "Embedding number : 48485\n",
            "Embedding number : 48486\n",
            "Embedding number : 48487\n",
            "Embedding number : 48488\n",
            "Embedding number : 48489\n",
            "Embedding number : 48490\n",
            "Embedding number : 48491\n",
            "Embedding number : 48492\n",
            "Embedding number : 48493\n",
            "Embedding number : 48494\n",
            "Embedding number : 48495\n",
            "Embedding number : 48496\n",
            "Embedding number : 48497\n",
            "Embedding number : 48498\n",
            "Embedding number : 48499\n",
            "Embedding number : 48500\n",
            "Embedding number : 48501\n",
            "Embedding number : 48502\n",
            "Embedding number : 48503\n",
            "Embedding number : 48504\n",
            "Embedding number : 48505\n",
            "Embedding number : 48506\n",
            "Embedding number : 48507\n",
            "Embedding number : 48508\n",
            "Embedding number : 48509\n",
            "Embedding number : 48510\n",
            "Embedding number : 48511\n",
            "Embedding number : 48512\n",
            "Embedding number : 48513\n",
            "Embedding number : 48514\n",
            "Embedding number : 48515\n",
            "Embedding number : 48516\n",
            "Embedding number : 48517\n",
            "Embedding number : 48518\n",
            "Embedding number : 48519\n",
            "Embedding number : 48520\n",
            "Embedding number : 48521\n",
            "Embedding number : 48522\n",
            "Embedding number : 48523\n",
            "Embedding number : 48524\n",
            "Embedding number : 48525\n",
            "Embedding number : 48526\n",
            "Embedding number : 48527\n",
            "Embedding number : 48528\n",
            "Embedding number : 48529\n",
            "Embedding number : 48530\n",
            "Embedding number : 48531\n",
            "Embedding number : 48532\n",
            "Embedding number : 48533\n",
            "Embedding number : 48534\n",
            "Embedding number : 48535\n",
            "Embedding number : 48536\n",
            "Embedding number : 48537\n",
            "Embedding number : 48538\n",
            "Embedding number : 48539\n",
            "Embedding number : 48540\n",
            "Embedding number : 48541\n",
            "Embedding number : 48542\n",
            "Embedding number : 48543\n",
            "Embedding number : 48544\n",
            "Embedding number : 48545\n",
            "Embedding number : 48546\n",
            "Embedding number : 48547\n",
            "Embedding number : 48548\n",
            "Embedding number : 48549\n",
            "Embedding number : 48550\n",
            "Embedding number : 48551\n",
            "Embedding number : 48552\n",
            "Embedding number : 48553\n",
            "Embedding number : 48554\n",
            "Embedding number : 48555\n",
            "Embedding number : 48556\n",
            "Embedding number : 48557\n",
            "Embedding number : 48558\n",
            "Embedding number : 48559\n",
            "Embedding number : 48560\n",
            "Embedding number : 48561\n",
            "Embedding number : 48562\n",
            "Embedding number : 48563\n",
            "Embedding number : 48564\n",
            "Embedding number : 48565\n",
            "Embedding number : 48566\n",
            "Embedding number : 48567\n",
            "Embedding number : 48568\n",
            "Embedding number : 48569\n",
            "Embedding number : 48570\n",
            "Embedding number : 48571\n",
            "Embedding number : 48572\n",
            "Embedding number : 48573\n",
            "Embedding number : 48574\n",
            "Embedding number : 48575\n",
            "Embedding number : 48576\n",
            "Embedding number : 48577\n",
            "Embedding number : 48578\n",
            "Embedding number : 48579\n",
            "Embedding number : 48580\n",
            "Embedding number : 48581\n",
            "Embedding number : 48582\n",
            "Embedding number : 48583\n",
            "Embedding number : 48584\n",
            "Embedding number : 48585\n",
            "Embedding number : 48586\n",
            "Embedding number : 48587\n",
            "Embedding number : 48588\n",
            "Embedding number : 48589\n",
            "Embedding number : 48590\n",
            "Embedding number : 48591\n",
            "Embedding number : 48592\n",
            "Embedding number : 48593\n",
            "Embedding number : 48594\n",
            "Embedding number : 48595\n",
            "Embedding number : 48596\n",
            "Embedding number : 48597\n",
            "Embedding number : 48598\n",
            "Embedding number : 48599\n",
            "Embedding number : 48600\n",
            "Embedding number : 48601\n",
            "Embedding number : 48602\n",
            "Embedding number : 48603\n",
            "Embedding number : 48604\n",
            "Embedding number : 48605\n",
            "Embedding number : 48606\n",
            "Embedding number : 48607\n",
            "Embedding number : 48608\n",
            "Embedding number : 48609\n",
            "Embedding number : 48610\n",
            "Embedding number : 48611\n",
            "Embedding number : 48612\n",
            "Embedding number : 48613\n",
            "Embedding number : 48614\n",
            "Embedding number : 48615\n",
            "Embedding number : 48616\n",
            "Embedding number : 48617\n",
            "Embedding number : 48618\n",
            "Embedding number : 48619\n",
            "Embedding number : 48620\n",
            "Embedding number : 48621\n",
            "Embedding number : 48622\n",
            "Embedding number : 48623\n",
            "Embedding number : 48624\n",
            "Embedding number : 48625\n",
            "Embedding number : 48626\n",
            "Embedding number : 48627\n",
            "Embedding number : 48628\n",
            "Embedding number : 48629\n",
            "Embedding number : 48630\n",
            "Embedding number : 48631\n",
            "Embedding number : 48632\n",
            "Embedding number : 48633\n",
            "Embedding number : 48634\n",
            "Embedding number : 48635\n",
            "Embedding number : 48636\n",
            "Embedding number : 48637\n",
            "Embedding number : 48638\n",
            "Embedding number : 48639\n",
            "Embedding number : 48640\n",
            "Embedding number : 48641\n",
            "Embedding number : 48642\n",
            "Embedding number : 48643\n",
            "Embedding number : 48644\n",
            "Embedding number : 48645\n",
            "Embedding number : 48646\n",
            "Embedding number : 48647\n",
            "Embedding number : 48648\n",
            "Embedding number : 48649\n",
            "Embedding number : 48650\n",
            "Embedding number : 48651\n",
            "Embedding number : 48652\n",
            "Embedding number : 48653\n",
            "Embedding number : 48654\n",
            "Embedding number : 48655\n",
            "Embedding number : 48656\n",
            "Embedding number : 48657\n",
            "Embedding number : 48658\n",
            "Embedding number : 48659\n",
            "Embedding number : 48660\n",
            "Embedding number : 48661\n",
            "Embedding number : 48662\n",
            "Embedding number : 48663\n",
            "Embedding number : 48664\n",
            "Embedding number : 48665\n",
            "Embedding number : 48666\n",
            "Embedding number : 48667\n",
            "Embedding number : 48668\n",
            "Embedding number : 48669\n",
            "Embedding number : 48670\n",
            "Embedding number : 48671\n",
            "Embedding number : 48672\n",
            "Embedding number : 48673\n",
            "Embedding number : 48674\n",
            "Embedding number : 48675\n",
            "Embedding number : 48676\n",
            "Embedding number : 48677\n",
            "Embedding number : 48678\n",
            "Embedding number : 48679\n",
            "Embedding number : 48680\n",
            "Embedding number : 48681\n",
            "Embedding number : 48682\n",
            "Embedding number : 48683\n",
            "Embedding number : 48684\n",
            "Embedding number : 48685\n",
            "Embedding number : 48686\n",
            "Embedding number : 48687\n",
            "Embedding number : 48688\n",
            "Embedding number : 48689\n",
            "Embedding number : 48690\n",
            "Embedding number : 48691\n",
            "Embedding number : 48692\n",
            "Embedding number : 48693\n",
            "Embedding number : 48694\n",
            "Embedding number : 48695\n",
            "Embedding number : 48696\n",
            "Embedding number : 48697\n",
            "Embedding number : 48698\n",
            "Embedding number : 48699\n",
            "Embedding number : 48700\n",
            "Embedding number : 48701\n",
            "Embedding number : 48702\n",
            "Embedding number : 48703\n",
            "Embedding number : 48704\n",
            "Embedding number : 48705\n",
            "Embedding number : 48706\n",
            "Embedding number : 48707\n",
            "Embedding number : 48708\n",
            "Embedding number : 48709\n",
            "Embedding number : 48710\n",
            "Embedding number : 48711\n",
            "Embedding number : 48712\n",
            "Embedding number : 48713\n",
            "Embedding number : 48714\n",
            "Embedding number : 48715\n",
            "Embedding number : 48716\n",
            "Embedding number : 48717\n",
            "Embedding number : 48718\n",
            "Embedding number : 48719\n",
            "Embedding number : 48720\n",
            "Embedding number : 48721\n",
            "Embedding number : 48722\n",
            "Embedding number : 48723\n",
            "Embedding number : 48724\n",
            "Embedding number : 48725\n",
            "Embedding number : 48726\n",
            "Embedding number : 48727\n",
            "Embedding number : 48728\n",
            "Embedding number : 48729\n",
            "Embedding number : 48730\n",
            "Embedding number : 48731\n",
            "Embedding number : 48732\n",
            "Embedding number : 48733\n",
            "Embedding number : 48734\n",
            "Embedding number : 48735\n",
            "Embedding number : 48736\n",
            "Embedding number : 48737\n",
            "Embedding number : 48738\n",
            "Embedding number : 48739\n",
            "Embedding number : 48740\n",
            "Embedding number : 48741\n",
            "Embedding number : 48742\n",
            "Embedding number : 48743\n",
            "Embedding number : 48744\n",
            "Embedding number : 48745\n",
            "Embedding number : 48746\n",
            "Embedding number : 48747\n",
            "Embedding number : 48748\n",
            "Embedding number : 48749\n",
            "Embedding number : 48750\n",
            "Embedding number : 48751\n",
            "Embedding number : 48752\n",
            "Embedding number : 48753\n",
            "Embedding number : 48754\n",
            "Embedding number : 48755\n",
            "Embedding number : 48756\n",
            "Embedding number : 48757\n",
            "Embedding number : 48758\n",
            "Embedding number : 48759\n",
            "Embedding number : 48760\n",
            "Embedding number : 48761\n",
            "Embedding number : 48762\n",
            "Embedding number : 48763\n",
            "Embedding number : 48764\n",
            "Embedding number : 48765\n",
            "Embedding number : 48766\n",
            "Embedding number : 48767\n",
            "Embedding number : 48768\n",
            "Embedding number : 48769\n",
            "Embedding number : 48770\n",
            "Embedding number : 48771\n",
            "Embedding number : 48772\n",
            "Embedding number : 48773\n",
            "Embedding number : 48774\n",
            "Embedding number : 48775\n",
            "Embedding number : 48776\n",
            "Embedding number : 48777\n",
            "Embedding number : 48778\n",
            "Embedding number : 48779\n",
            "Embedding number : 48780\n",
            "Embedding number : 48781\n",
            "Embedding number : 48782\n",
            "Embedding number : 48783\n",
            "Embedding number : 48784\n",
            "Embedding number : 48785\n",
            "Embedding number : 48786\n",
            "Embedding number : 48787\n",
            "Embedding number : 48788\n",
            "Embedding number : 48789\n",
            "Embedding number : 48790\n",
            "Embedding number : 48791\n",
            "Embedding number : 48792\n",
            "Embedding number : 48793\n",
            "Embedding number : 48794\n",
            "Embedding number : 48795\n",
            "Embedding number : 48796\n",
            "Embedding number : 48797\n",
            "Embedding number : 48798\n",
            "Embedding number : 48799\n",
            "Embedding number : 48800\n",
            "Embedding number : 48801\n",
            "Embedding number : 48802\n",
            "Embedding number : 48803\n",
            "Embedding number : 48804\n",
            "Embedding number : 48805\n",
            "Embedding number : 48806\n",
            "Embedding number : 48807\n",
            "Embedding number : 48808\n",
            "Embedding number : 48809\n",
            "Embedding number : 48810\n",
            "Embedding number : 48811\n",
            "Embedding number : 48812\n",
            "Embedding number : 48813\n",
            "Embedding number : 48814\n",
            "Embedding number : 48815\n",
            "Embedding number : 48816\n",
            "Embedding number : 48817\n",
            "Embedding number : 48818\n",
            "Embedding number : 48819\n",
            "Embedding number : 48820\n",
            "Embedding number : 48821\n",
            "Embedding number : 48822\n",
            "Embedding number : 48823\n",
            "Embedding number : 48824\n",
            "Embedding number : 48825\n",
            "Embedding number : 48826\n",
            "Embedding number : 48827\n",
            "Embedding number : 48828\n",
            "Embedding number : 48829\n",
            "Embedding number : 48830\n",
            "Embedding number : 48831\n",
            "Embedding number : 48832\n",
            "Embedding number : 48833\n",
            "Embedding number : 48834\n",
            "Embedding number : 48835\n",
            "Embedding number : 48836\n",
            "Embedding number : 48837\n",
            "Embedding number : 48838\n",
            "Embedding number : 48839\n",
            "Embedding number : 48840\n",
            "Embedding number : 48841\n",
            "Embedding number : 48842\n",
            "Embedding number : 48843\n",
            "Embedding number : 48844\n",
            "Embedding number : 48845\n",
            "Embedding number : 48846\n",
            "Embedding number : 48847\n",
            "Embedding number : 48848\n",
            "Embedding number : 48849\n",
            "Embedding number : 48850\n",
            "Embedding number : 48851\n",
            "Embedding number : 48852\n",
            "Embedding number : 48853\n",
            "Embedding number : 48854\n",
            "Embedding number : 48855\n",
            "Embedding number : 48856\n",
            "Embedding number : 48857\n",
            "Embedding number : 48858\n",
            "Embedding number : 48859\n",
            "Embedding number : 48860\n",
            "Embedding number : 48861\n",
            "Embedding number : 48862\n",
            "Embedding number : 48863\n",
            "Embedding number : 48864\n",
            "Embedding number : 48865\n",
            "Embedding number : 48866\n",
            "Embedding number : 48867\n",
            "Embedding number : 48868\n",
            "Embedding number : 48869\n",
            "Embedding number : 48870\n",
            "Embedding number : 48871\n",
            "Embedding number : 48872\n",
            "Embedding number : 48873\n",
            "Embedding number : 48874\n",
            "Embedding number : 48875\n",
            "Embedding number : 48876\n",
            "Embedding number : 48877\n",
            "Embedding number : 48878\n",
            "Embedding number : 48879\n",
            "Embedding number : 48880\n",
            "Embedding number : 48881\n",
            "Embedding number : 48882\n",
            "Embedding number : 48883\n",
            "Embedding number : 48884\n",
            "Embedding number : 48885\n",
            "Embedding number : 48886\n",
            "Embedding number : 48887\n",
            "Embedding number : 48888\n",
            "Embedding number : 48889\n",
            "Embedding number : 48890\n",
            "Embedding number : 48891\n",
            "Embedding number : 48892\n",
            "Embedding number : 48893\n",
            "Embedding number : 48894\n",
            "Embedding number : 48895\n",
            "Embedding number : 48896\n",
            "Embedding number : 48897\n",
            "Embedding number : 48898\n",
            "Embedding number : 48899\n",
            "Embedding number : 48900\n",
            "Embedding number : 48901\n",
            "Embedding number : 48902\n",
            "Embedding number : 48903\n",
            "Embedding number : 48904\n",
            "Embedding number : 48905\n",
            "Embedding number : 48906\n",
            "Embedding number : 48907\n",
            "Embedding number : 48908\n",
            "Embedding number : 48909\n",
            "Embedding number : 48910\n",
            "Embedding number : 48911\n",
            "Embedding number : 48912\n",
            "Embedding number : 48913\n",
            "Embedding number : 48914\n",
            "Embedding number : 48915\n",
            "Embedding number : 48916\n",
            "Embedding number : 48917\n",
            "Embedding number : 48918\n",
            "Embedding number : 48919\n",
            "Embedding number : 48920\n",
            "Embedding number : 48921\n",
            "Embedding number : 48922\n",
            "Embedding number : 48923\n",
            "Embedding number : 48924\n",
            "Embedding number : 48925\n",
            "Embedding number : 48926\n",
            "Embedding number : 48927\n",
            "Embedding number : 48928\n",
            "Embedding number : 48929\n",
            "Embedding number : 48930\n",
            "Embedding number : 48931\n",
            "Embedding number : 48932\n",
            "Embedding number : 48933\n",
            "Embedding number : 48934\n",
            "Embedding number : 48935\n",
            "Embedding number : 48936\n",
            "Embedding number : 48937\n",
            "Embedding number : 48938\n",
            "Embedding number : 48939\n",
            "Embedding number : 48940\n",
            "Embedding number : 48941\n",
            "Embedding number : 48942\n",
            "Embedding number : 48943\n",
            "Embedding number : 48944\n",
            "Embedding number : 48945\n",
            "Embedding number : 48946\n",
            "Embedding number : 48947\n",
            "Embedding number : 48948\n",
            "Embedding number : 48949\n",
            "Embedding number : 48950\n",
            "Embedding number : 48951\n",
            "Embedding number : 48952\n",
            "Embedding number : 48953\n",
            "Embedding number : 48954\n",
            "Embedding number : 48955\n",
            "Embedding number : 48956\n",
            "Embedding number : 48957\n",
            "Embedding number : 48958\n",
            "Embedding number : 48959\n",
            "Embedding number : 48960\n",
            "Embedding number : 48961\n",
            "Embedding number : 48962\n",
            "Embedding number : 48963\n",
            "Embedding number : 48964\n",
            "Embedding number : 48965\n",
            "Embedding number : 48966\n",
            "Embedding number : 48967\n",
            "Embedding number : 48968\n",
            "Embedding number : 48969\n",
            "Embedding number : 48970\n",
            "Embedding number : 48971\n",
            "Embedding number : 48972\n",
            "Embedding number : 48973\n",
            "Embedding number : 48974\n",
            "Embedding number : 48975\n",
            "Embedding number : 48976\n",
            "Embedding number : 48977\n",
            "Embedding number : 48978\n",
            "Embedding number : 48979\n",
            "Embedding number : 48980\n",
            "Embedding number : 48981\n",
            "Embedding number : 48982\n",
            "Embedding number : 48983\n",
            "Embedding number : 48984\n",
            "Embedding number : 48985\n",
            "Embedding number : 48986\n",
            "Embedding number : 48987\n",
            "Embedding number : 48988\n",
            "Embedding number : 48989\n",
            "Embedding number : 48990\n",
            "Embedding number : 48991\n",
            "Embedding number : 48992\n",
            "Embedding number : 48993\n",
            "Embedding number : 48994\n",
            "Embedding number : 48995\n",
            "Embedding number : 48996\n",
            "Embedding number : 48997\n",
            "Embedding number : 48998\n",
            "Embedding number : 48999\n",
            "Embedding number : 49000\n",
            "Embedding number : 49001\n",
            "Embedding number : 49002\n",
            "Embedding number : 49003\n",
            "Embedding number : 49004\n",
            "Embedding number : 49005\n",
            "Embedding number : 49006\n",
            "Embedding number : 49007\n",
            "Embedding number : 49008\n",
            "Embedding number : 49009\n",
            "Embedding number : 49010\n",
            "Embedding number : 49011\n",
            "Embedding number : 49012\n",
            "Embedding number : 49013\n",
            "Embedding number : 49014\n",
            "Embedding number : 49015\n",
            "Embedding number : 49016\n",
            "Embedding number : 49017\n",
            "Embedding number : 49018\n",
            "Embedding number : 49019\n",
            "Embedding number : 49020\n",
            "Embedding number : 49021\n",
            "Embedding number : 49022\n",
            "Embedding number : 49023\n",
            "Embedding number : 49024\n",
            "Embedding number : 49025\n",
            "Embedding number : 49026\n",
            "Embedding number : 49027\n",
            "Embedding number : 49028\n",
            "Embedding number : 49029\n",
            "Embedding number : 49030\n",
            "Embedding number : 49031\n",
            "Embedding number : 49032\n",
            "Embedding number : 49033\n",
            "Embedding number : 49034\n",
            "Embedding number : 49035\n",
            "Embedding number : 49036\n",
            "Embedding number : 49037\n",
            "Embedding number : 49038\n",
            "Embedding number : 49039\n",
            "Embedding number : 49040\n",
            "Embedding number : 49041\n",
            "Embedding number : 49042\n",
            "Embedding number : 49043\n",
            "Embedding number : 49044\n",
            "Embedding number : 49045\n",
            "Embedding number : 49046\n",
            "Embedding number : 49047\n",
            "Embedding number : 49048\n",
            "Embedding number : 49049\n",
            "Embedding number : 49050\n",
            "Embedding number : 49051\n",
            "Embedding number : 49052\n",
            "Embedding number : 49053\n",
            "Embedding number : 49054\n",
            "Embedding number : 49055\n",
            "Embedding number : 49056\n",
            "Embedding number : 49057\n",
            "Embedding number : 49058\n",
            "Embedding number : 49059\n",
            "Embedding number : 49060\n",
            "Embedding number : 49061\n",
            "Embedding number : 49062\n",
            "Embedding number : 49063\n",
            "Embedding number : 49064\n",
            "Embedding number : 49065\n",
            "Embedding number : 49066\n",
            "Embedding number : 49067\n",
            "Embedding number : 49068\n",
            "Embedding number : 49069\n",
            "Embedding number : 49070\n",
            "Embedding number : 49071\n",
            "Embedding number : 49072\n",
            "Embedding number : 49073\n",
            "Embedding number : 49074\n",
            "Embedding number : 49075\n",
            "Embedding number : 49076\n",
            "Embedding number : 49077\n",
            "Embedding number : 49078\n",
            "Embedding number : 49079\n",
            "Embedding number : 49080\n",
            "Embedding number : 49081\n",
            "Embedding number : 49082\n",
            "Embedding number : 49083\n",
            "Embedding number : 49084\n",
            "Embedding number : 49085\n",
            "Embedding number : 49086\n",
            "Embedding number : 49087\n",
            "Embedding number : 49088\n",
            "Embedding number : 49089\n",
            "Embedding number : 49090\n",
            "Embedding number : 49091\n",
            "Embedding number : 49092\n",
            "Embedding number : 49093\n",
            "Embedding number : 49094\n",
            "Embedding number : 49095\n",
            "Embedding number : 49096\n",
            "Embedding number : 49097\n",
            "Embedding number : 49098\n",
            "Embedding number : 49099\n",
            "Embedding number : 49100\n",
            "Embedding number : 49101\n",
            "Embedding number : 49102\n",
            "Embedding number : 49103\n",
            "Embedding number : 49104\n",
            "Embedding number : 49105\n",
            "Embedding number : 49106\n",
            "Embedding number : 49107\n",
            "Embedding number : 49108\n",
            "Embedding number : 49109\n",
            "Embedding number : 49110\n",
            "Embedding number : 49111\n",
            "Embedding number : 49112\n",
            "Embedding number : 49113\n",
            "Embedding number : 49114\n",
            "Embedding number : 49115\n",
            "Embedding number : 49116\n",
            "Embedding number : 49117\n",
            "Embedding number : 49118\n",
            "Embedding number : 49119\n",
            "Embedding number : 49120\n",
            "Embedding number : 49121\n",
            "Embedding number : 49122\n",
            "Embedding number : 49123\n",
            "Embedding number : 49124\n",
            "Embedding number : 49125\n",
            "Embedding number : 49126\n",
            "Embedding number : 49127\n",
            "Embedding number : 49128\n",
            "Embedding number : 49129\n",
            "Embedding number : 49130\n",
            "Embedding number : 49131\n",
            "Embedding number : 49132\n",
            "Embedding number : 49133\n",
            "Embedding number : 49134\n",
            "Embedding number : 49135\n",
            "Embedding number : 49136\n",
            "Embedding number : 49137\n",
            "Embedding number : 49138\n",
            "Embedding number : 49139\n",
            "Embedding number : 49140\n",
            "Embedding number : 49141\n",
            "Embedding number : 49142\n",
            "Embedding number : 49143\n",
            "Embedding number : 49144\n",
            "Embedding number : 49145\n",
            "Embedding number : 49146\n",
            "Embedding number : 49147\n",
            "Embedding number : 49148\n",
            "Embedding number : 49149\n",
            "Embedding number : 49150\n",
            "Embedding number : 49151\n",
            "Embedding number : 49152\n",
            "Embedding number : 49153\n",
            "Embedding number : 49154\n",
            "Embedding number : 49155\n",
            "Embedding number : 49156\n",
            "Embedding number : 49157\n",
            "Embedding number : 49158\n",
            "Embedding number : 49159\n",
            "Embedding number : 49160\n",
            "Embedding number : 49161\n",
            "Embedding number : 49162\n",
            "Embedding number : 49163\n",
            "Embedding number : 49164\n",
            "Embedding number : 49165\n",
            "Embedding number : 49166\n",
            "Embedding number : 49167\n",
            "Embedding number : 49168\n",
            "Embedding number : 49169\n",
            "Embedding number : 49170\n",
            "Embedding number : 49171\n",
            "Embedding number : 49172\n",
            "Embedding number : 49173\n",
            "Embedding number : 49174\n",
            "Embedding number : 49175\n",
            "Embedding number : 49176\n",
            "Embedding number : 49177\n",
            "Embedding number : 49178\n",
            "Embedding number : 49179\n",
            "Embedding number : 49180\n",
            "Embedding number : 49181\n",
            "Embedding number : 49182\n",
            "Embedding number : 49183\n",
            "Embedding number : 49184\n",
            "Embedding number : 49185\n",
            "Embedding number : 49186\n",
            "Embedding number : 49187\n",
            "Embedding number : 49188\n",
            "Embedding number : 49189\n",
            "Embedding number : 49190\n",
            "Embedding number : 49191\n",
            "Embedding number : 49192\n",
            "Embedding number : 49193\n",
            "Embedding number : 49194\n",
            "Embedding number : 49195\n",
            "Embedding number : 49196\n",
            "Embedding number : 49197\n",
            "Embedding number : 49198\n",
            "Embedding number : 49199\n",
            "Embedding number : 49200\n",
            "Embedding number : 49201\n",
            "Embedding number : 49202\n",
            "Embedding number : 49203\n",
            "Embedding number : 49204\n",
            "Embedding number : 49205\n",
            "Embedding number : 49206\n",
            "Embedding number : 49207\n",
            "Embedding number : 49208\n",
            "Embedding number : 49209\n",
            "Embedding number : 49210\n",
            "Embedding number : 49211\n",
            "Embedding number : 49212\n",
            "Embedding number : 49213\n",
            "Embedding number : 49214\n",
            "Embedding number : 49215\n",
            "Embedding number : 49216\n",
            "Embedding number : 49217\n",
            "Embedding number : 49218\n",
            "Embedding number : 49219\n",
            "Embedding number : 49220\n",
            "Embedding number : 49221\n",
            "Embedding number : 49222\n",
            "Embedding number : 49223\n",
            "Embedding number : 49224\n",
            "Embedding number : 49225\n",
            "Embedding number : 49226\n",
            "Embedding number : 49227\n",
            "Embedding number : 49228\n",
            "Embedding number : 49229\n",
            "Embedding number : 49230\n",
            "Embedding number : 49231\n",
            "Embedding number : 49232\n",
            "Embedding number : 49233\n",
            "Embedding number : 49234\n",
            "Embedding number : 49235\n",
            "Embedding number : 49236\n",
            "Embedding number : 49237\n",
            "Embedding number : 49238\n",
            "Embedding number : 49239\n",
            "Embedding number : 49240\n",
            "Embedding number : 49241\n",
            "Embedding number : 49242\n",
            "Embedding number : 49243\n",
            "Embedding number : 49244\n",
            "Embedding number : 49245\n",
            "Embedding number : 49246\n",
            "Embedding number : 49247\n",
            "Embedding number : 49248\n",
            "Embedding number : 49249\n",
            "Embedding number : 49250\n",
            "Embedding number : 49251\n",
            "Embedding number : 49252\n",
            "Embedding number : 49253\n",
            "Embedding number : 49254\n",
            "Embedding number : 49255\n",
            "Embedding number : 49256\n",
            "Embedding number : 49257\n",
            "Embedding number : 49258\n",
            "Embedding number : 49259\n",
            "Embedding number : 49260\n",
            "Embedding number : 49261\n",
            "Embedding number : 49262\n",
            "Embedding number : 49263\n",
            "Embedding number : 49264\n",
            "Embedding number : 49265\n",
            "Embedding number : 49266\n",
            "Embedding number : 49267\n",
            "Embedding number : 49268\n",
            "Embedding number : 49269\n",
            "Embedding number : 49270\n",
            "Embedding number : 49271\n",
            "Embedding number : 49272\n",
            "Embedding number : 49273\n",
            "Embedding number : 49274\n",
            "Embedding number : 49275\n",
            "Embedding number : 49276\n",
            "Embedding number : 49277\n",
            "Embedding number : 49278\n",
            "Embedding number : 49279\n",
            "Embedding number : 49280\n",
            "Embedding number : 49281\n",
            "Embedding number : 49282\n",
            "Embedding number : 49283\n",
            "Embedding number : 49284\n",
            "Embedding number : 49285\n",
            "Embedding number : 49286\n",
            "Embedding number : 49287\n",
            "Embedding number : 49288\n",
            "Embedding number : 49289\n",
            "Embedding number : 49290\n",
            "Embedding number : 49291\n",
            "Embedding number : 49292\n",
            "Embedding number : 49293\n",
            "Embedding number : 49294\n",
            "Embedding number : 49295\n",
            "Embedding number : 49296\n",
            "Embedding number : 49297\n",
            "Embedding number : 49298\n",
            "Embedding number : 49299\n",
            "Embedding number : 49300\n",
            "Embedding number : 49301\n",
            "Embedding number : 49302\n",
            "Embedding number : 49303\n",
            "Embedding number : 49304\n",
            "Embedding number : 49305\n",
            "Embedding number : 49306\n",
            "Embedding number : 49307\n",
            "Embedding number : 49308\n",
            "Embedding number : 49309\n",
            "Embedding number : 49310\n",
            "Embedding number : 49311\n",
            "Embedding number : 49312\n",
            "Embedding number : 49313\n",
            "Embedding number : 49314\n",
            "Embedding number : 49315\n",
            "Embedding number : 49316\n",
            "Embedding number : 49317\n",
            "Embedding number : 49318\n",
            "Embedding number : 49319\n",
            "Embedding number : 49320\n",
            "Embedding number : 49321\n",
            "Embedding number : 49322\n",
            "Embedding number : 49323\n",
            "Embedding number : 49324\n",
            "Embedding number : 49325\n",
            "Embedding number : 49326\n",
            "Embedding number : 49327\n",
            "Embedding number : 49328\n",
            "Embedding number : 49329\n",
            "Embedding number : 49330\n",
            "Embedding number : 49331\n",
            "Embedding number : 49332\n",
            "Embedding number : 49333\n",
            "Embedding number : 49334\n",
            "Embedding number : 49335\n",
            "Embedding number : 49336\n",
            "Embedding number : 49337\n",
            "Embedding number : 49338\n",
            "Embedding number : 49339\n",
            "Embedding number : 49340\n",
            "Embedding number : 49341\n",
            "Embedding number : 49342\n",
            "Embedding number : 49343\n",
            "Embedding number : 49344\n",
            "Embedding number : 49345\n",
            "Embedding number : 49346\n",
            "Embedding number : 49347\n",
            "Embedding number : 49348\n",
            "Embedding number : 49349\n",
            "Embedding number : 49350\n",
            "Embedding number : 49351\n",
            "Embedding number : 49352\n",
            "Embedding number : 49353\n",
            "Embedding number : 49354\n",
            "Embedding number : 49355\n",
            "Embedding number : 49356\n",
            "Embedding number : 49357\n",
            "Embedding number : 49358\n",
            "Embedding number : 49359\n",
            "Embedding number : 49360\n",
            "Embedding number : 49361\n",
            "Embedding number : 49362\n",
            "Embedding number : 49363\n",
            "Embedding number : 49364\n",
            "Embedding number : 49365\n",
            "Embedding number : 49366\n",
            "Embedding number : 49367\n",
            "Embedding number : 49368\n",
            "Embedding number : 49369\n",
            "Embedding number : 49370\n",
            "Embedding number : 49371\n",
            "Embedding number : 49372\n",
            "Embedding number : 49373\n",
            "Embedding number : 49374\n",
            "Embedding number : 49375\n",
            "Embedding number : 49376\n",
            "Embedding number : 49377\n",
            "Embedding number : 49378\n",
            "Embedding number : 49379\n",
            "Embedding number : 49380\n",
            "Embedding number : 49381\n",
            "Embedding number : 49382\n",
            "Embedding number : 49383\n",
            "Embedding number : 49384\n",
            "Embedding number : 49385\n",
            "Embedding number : 49386\n",
            "Embedding number : 49387\n",
            "Embedding number : 49388\n",
            "Embedding number : 49389\n",
            "Embedding number : 49390\n",
            "Embedding number : 49391\n",
            "Embedding number : 49392\n",
            "Embedding number : 49393\n",
            "Embedding number : 49394\n",
            "Embedding number : 49395\n",
            "Embedding number : 49396\n",
            "Embedding number : 49397\n",
            "Embedding number : 49398\n",
            "Embedding number : 49399\n",
            "Embedding number : 49400\n",
            "Embedding number : 49401\n",
            "Embedding number : 49402\n",
            "Embedding number : 49403\n",
            "Embedding number : 49404\n",
            "Embedding number : 49405\n",
            "Embedding number : 49406\n",
            "Embedding number : 49407\n",
            "Embedding number : 49408\n",
            "Embedding number : 49409\n",
            "Embedding number : 49410\n",
            "Embedding number : 49411\n",
            "Embedding number : 49412\n",
            "Embedding number : 49413\n",
            "Embedding number : 49414\n",
            "Embedding number : 49415\n",
            "Embedding number : 49416\n",
            "Embedding number : 49417\n",
            "Embedding number : 49418\n",
            "Embedding number : 49419\n",
            "Embedding number : 49420\n",
            "Embedding number : 49421\n",
            "Embedding number : 49422\n",
            "Embedding number : 49423\n",
            "Embedding number : 49424\n",
            "Embedding number : 49425\n",
            "Embedding number : 49426\n",
            "Embedding number : 49427\n",
            "Embedding number : 49428\n",
            "Embedding number : 49429\n",
            "Embedding number : 49430\n",
            "Embedding number : 49431\n",
            "Embedding number : 49432\n",
            "Embedding number : 49433\n",
            "Embedding number : 49434\n",
            "Embedding number : 49435\n",
            "Embedding number : 49436\n",
            "Embedding number : 49437\n",
            "Embedding number : 49438\n",
            "Embedding number : 49439\n",
            "Embedding number : 49440\n",
            "Embedding number : 49441\n",
            "Embedding number : 49442\n",
            "Embedding number : 49443\n",
            "Embedding number : 49444\n",
            "Embedding number : 49445\n",
            "Embedding number : 49446\n",
            "Embedding number : 49447\n",
            "Embedding number : 49448\n",
            "Embedding number : 49449\n",
            "Embedding number : 49450\n",
            "Embedding number : 49451\n",
            "Embedding number : 49452\n",
            "Embedding number : 49453\n",
            "Embedding number : 49454\n",
            "Embedding number : 49455\n",
            "Embedding number : 49456\n",
            "Embedding number : 49457\n",
            "Embedding number : 49458\n",
            "Embedding number : 49459\n",
            "Embedding number : 49460\n",
            "Embedding number : 49461\n",
            "Embedding number : 49462\n",
            "Embedding number : 49463\n",
            "Embedding number : 49464\n",
            "Embedding number : 49465\n",
            "Embedding number : 49466\n",
            "Embedding number : 49467\n",
            "Embedding number : 49468\n",
            "Embedding number : 49469\n",
            "Embedding number : 49470\n",
            "Embedding number : 49471\n",
            "Embedding number : 49472\n",
            "Embedding number : 49473\n",
            "Embedding number : 49474\n",
            "Embedding number : 49475\n",
            "Embedding number : 49476\n",
            "Embedding number : 49477\n",
            "Embedding number : 49478\n",
            "Embedding number : 49479\n",
            "Embedding number : 49480\n",
            "Embedding number : 49481\n",
            "Embedding number : 49482\n",
            "Embedding number : 49483\n",
            "Embedding number : 49484\n",
            "Embedding number : 49485\n",
            "Embedding number : 49486\n",
            "Embedding number : 49487\n",
            "Embedding number : 49488\n",
            "Embedding number : 49489\n",
            "Embedding number : 49490\n",
            "Embedding number : 49491\n",
            "Embedding number : 49492\n",
            "Embedding number : 49493\n",
            "Embedding number : 49494\n",
            "Embedding number : 49495\n",
            "Embedding number : 49496\n",
            "Embedding number : 49497\n",
            "Embedding number : 49498\n",
            "Embedding number : 49499\n",
            "Embedding number : 49500\n",
            "Embedding number : 49501\n",
            "Embedding number : 49502\n",
            "Embedding number : 49503\n",
            "Embedding number : 49504\n",
            "Embedding number : 49505\n",
            "Embedding number : 49506\n",
            "Embedding number : 49507\n",
            "Embedding number : 49508\n",
            "Embedding number : 49509\n",
            "Embedding number : 49510\n",
            "Embedding number : 49511\n",
            "Embedding number : 49512\n",
            "Embedding number : 49513\n",
            "Embedding number : 49514\n",
            "Embedding number : 49515\n",
            "Embedding number : 49516\n",
            "Embedding number : 49517\n",
            "Embedding number : 49518\n",
            "Embedding number : 49519\n",
            "Embedding number : 49520\n",
            "Embedding number : 49521\n",
            "Embedding number : 49522\n",
            "Embedding number : 49523\n",
            "Embedding number : 49524\n",
            "Embedding number : 49525\n",
            "Embedding number : 49526\n",
            "Embedding number : 49527\n",
            "Embedding number : 49528\n",
            "Embedding number : 49529\n",
            "Embedding number : 49530\n",
            "Embedding number : 49531\n",
            "Embedding number : 49532\n",
            "Embedding number : 49533\n",
            "Embedding number : 49534\n",
            "Embedding number : 49535\n",
            "Embedding number : 49536\n",
            "Embedding number : 49537\n",
            "Embedding number : 49538\n",
            "Embedding number : 49539\n",
            "Embedding number : 49540\n",
            "Embedding number : 49541\n",
            "Embedding number : 49542\n",
            "Embedding number : 49543\n",
            "Embedding number : 49544\n",
            "Embedding number : 49545\n",
            "Embedding number : 49546\n",
            "Embedding number : 49547\n",
            "Embedding number : 49548\n",
            "Embedding number : 49549\n",
            "Embedding number : 49550\n",
            "Embedding number : 49551\n",
            "Embedding number : 49552\n",
            "Embedding number : 49553\n",
            "Embedding number : 49554\n",
            "Embedding number : 49555\n",
            "Embedding number : 49556\n",
            "Embedding number : 49557\n",
            "Embedding number : 49558\n",
            "Embedding number : 49559\n",
            "Embedding number : 49560\n",
            "Embedding number : 49561\n",
            "Embedding number : 49562\n",
            "Embedding number : 49563\n",
            "Embedding number : 49564\n",
            "Embedding number : 49565\n",
            "Embedding number : 49566\n",
            "Embedding number : 49567\n",
            "Embedding number : 49568\n",
            "Embedding number : 49569\n",
            "Embedding number : 49570\n",
            "Embedding number : 49571\n",
            "Embedding number : 49572\n",
            "Embedding number : 49573\n",
            "Embedding number : 49574\n",
            "Embedding number : 49575\n",
            "Embedding number : 49576\n",
            "Embedding number : 49577\n",
            "Embedding number : 49578\n",
            "Embedding number : 49579\n",
            "Embedding number : 49580\n",
            "Embedding number : 49581\n",
            "Embedding number : 49582\n",
            "Embedding number : 49583\n",
            "Embedding number : 49584\n",
            "Embedding number : 49585\n",
            "Embedding number : 49586\n",
            "Embedding number : 49587\n",
            "Embedding number : 49588\n",
            "Embedding number : 49589\n",
            "Embedding number : 49590\n",
            "Embedding number : 49591\n",
            "Embedding number : 49592\n",
            "Embedding number : 49593\n",
            "Embedding number : 49594\n",
            "Embedding number : 49595\n",
            "Embedding number : 49596\n",
            "Embedding number : 49597\n",
            "Embedding number : 49598\n",
            "Embedding number : 49599\n",
            "Embedding number : 49600\n",
            "Embedding number : 49601\n",
            "Embedding number : 49602\n",
            "Embedding number : 49603\n",
            "Embedding number : 49604\n",
            "Embedding number : 49605\n",
            "Embedding number : 49606\n",
            "Embedding number : 49607\n",
            "Embedding number : 49608\n",
            "Embedding number : 49609\n",
            "Embedding number : 49610\n",
            "Embedding number : 49611\n",
            "Embedding number : 49612\n",
            "Embedding number : 49613\n",
            "Embedding number : 49614\n",
            "Embedding number : 49615\n",
            "Embedding number : 49616\n",
            "Embedding number : 49617\n",
            "Embedding number : 49618\n",
            "Embedding number : 49619\n",
            "Embedding number : 49620\n",
            "Embedding number : 49621\n",
            "Embedding number : 49622\n",
            "Embedding number : 49623\n",
            "Embedding number : 49624\n",
            "Embedding number : 49625\n",
            "Embedding number : 49626\n",
            "Embedding number : 49627\n",
            "Embedding number : 49628\n",
            "Embedding number : 49629\n",
            "Embedding number : 49630\n",
            "Embedding number : 49631\n",
            "Embedding number : 49632\n",
            "Embedding number : 49633\n",
            "Embedding number : 49634\n",
            "Embedding number : 49635\n",
            "Embedding number : 49636\n",
            "Embedding number : 49637\n",
            "Embedding number : 49638\n",
            "Embedding number : 49639\n",
            "Embedding number : 49640\n",
            "Embedding number : 49641\n",
            "Embedding number : 49642\n",
            "Embedding number : 49643\n",
            "Embedding number : 49644\n",
            "Embedding number : 49645\n",
            "Embedding number : 49646\n",
            "Embedding number : 49647\n",
            "Embedding number : 49648\n",
            "Embedding number : 49649\n",
            "Embedding number : 49650\n",
            "Embedding number : 49651\n",
            "Embedding number : 49652\n",
            "Embedding number : 49653\n",
            "Embedding number : 49654\n",
            "Embedding number : 49655\n",
            "Embedding number : 49656\n",
            "Embedding number : 49657\n",
            "Embedding number : 49658\n",
            "Embedding number : 49659\n",
            "Embedding number : 49660\n",
            "Embedding number : 49661\n",
            "Embedding number : 49662\n",
            "Embedding number : 49663\n",
            "Embedding number : 49664\n",
            "Embedding number : 49665\n",
            "Embedding number : 49666\n",
            "Embedding number : 49667\n",
            "Embedding number : 49668\n",
            "Embedding number : 49669\n",
            "Embedding number : 49670\n",
            "Embedding number : 49671\n",
            "Embedding number : 49672\n",
            "Embedding number : 49673\n",
            "Embedding number : 49674\n",
            "Embedding number : 49675\n",
            "Embedding number : 49676\n",
            "Embedding number : 49677\n",
            "Embedding number : 49678\n",
            "Embedding number : 49679\n",
            "Embedding number : 49680\n",
            "Embedding number : 49681\n",
            "Embedding number : 49682\n",
            "Embedding number : 49683\n",
            "Embedding number : 49684\n",
            "Embedding number : 49685\n",
            "Embedding number : 49686\n",
            "Embedding number : 49687\n",
            "Embedding number : 49688\n",
            "Embedding number : 49689\n",
            "Embedding number : 49690\n",
            "Embedding number : 49691\n",
            "Embedding number : 49692\n",
            "Embedding number : 49693\n",
            "Embedding number : 49694\n",
            "Embedding number : 49695\n",
            "Embedding number : 49696\n",
            "Embedding number : 49697\n",
            "Embedding number : 49698\n",
            "Embedding number : 49699\n",
            "Embedding number : 49700\n",
            "Embedding number : 49701\n",
            "Embedding number : 49702\n",
            "Embedding number : 49703\n",
            "Embedding number : 49704\n",
            "Embedding number : 49705\n",
            "Embedding number : 49706\n",
            "Embedding number : 49707\n",
            "Embedding number : 49708\n",
            "Embedding number : 49709\n",
            "Embedding number : 49710\n",
            "Embedding number : 49711\n",
            "Embedding number : 49712\n",
            "Embedding number : 49713\n",
            "Embedding number : 49714\n",
            "Embedding number : 49715\n",
            "Embedding number : 49716\n",
            "Embedding number : 49717\n",
            "Embedding number : 49718\n",
            "Embedding number : 49719\n",
            "Embedding number : 49720\n",
            "Embedding number : 49721\n",
            "Embedding number : 49722\n",
            "Embedding number : 49723\n",
            "Embedding number : 49724\n",
            "Embedding number : 49725\n",
            "Embedding number : 49726\n",
            "Embedding number : 49727\n",
            "Embedding number : 49728\n",
            "Embedding number : 49729\n",
            "Embedding number : 49730\n",
            "Embedding number : 49731\n",
            "Embedding number : 49732\n",
            "Embedding number : 49733\n",
            "Embedding number : 49734\n",
            "Embedding number : 49735\n",
            "Embedding number : 49736\n",
            "Embedding number : 49737\n",
            "Embedding number : 49738\n",
            "Embedding number : 49739\n",
            "Embedding number : 49740\n",
            "Embedding number : 49741\n",
            "Embedding number : 49742\n",
            "Embedding number : 49743\n",
            "Embedding number : 49744\n",
            "Embedding number : 49745\n",
            "Embedding number : 49746\n",
            "Embedding number : 49747\n",
            "Embedding number : 49748\n",
            "Embedding number : 49749\n",
            "Embedding number : 49750\n",
            "Embedding number : 49751\n",
            "Embedding number : 49752\n",
            "Embedding number : 49753\n",
            "Embedding number : 49754\n",
            "Embedding number : 49755\n",
            "Embedding number : 49756\n",
            "Embedding number : 49757\n",
            "Embedding number : 49758\n",
            "Embedding number : 49759\n",
            "Embedding number : 49760\n",
            "Embedding number : 49761\n",
            "Embedding number : 49762\n",
            "Embedding number : 49763\n",
            "Embedding number : 49764\n",
            "Embedding number : 49765\n",
            "Embedding number : 49766\n",
            "Embedding number : 49767\n",
            "Embedding number : 49768\n",
            "Embedding number : 49769\n",
            "Embedding number : 49770\n",
            "Embedding number : 49771\n",
            "Embedding number : 49772\n",
            "Embedding number : 49773\n",
            "Embedding number : 49774\n",
            "Embedding number : 49775\n",
            "Embedding number : 49776\n",
            "Embedding number : 49777\n",
            "Embedding number : 49778\n",
            "Embedding number : 49779\n",
            "Embedding number : 49780\n",
            "Embedding number : 49781\n",
            "Embedding number : 49782\n",
            "Embedding number : 49783\n",
            "Embedding number : 49784\n",
            "Embedding number : 49785\n",
            "Embedding number : 49786\n",
            "Embedding number : 49787\n",
            "Embedding number : 49788\n",
            "Embedding number : 49789\n",
            "Embedding number : 49790\n",
            "Embedding number : 49791\n",
            "Embedding number : 49792\n",
            "Embedding number : 49793\n",
            "Embedding number : 49794\n",
            "Embedding number : 49795\n",
            "Embedding number : 49796\n",
            "Embedding number : 49797\n",
            "Embedding number : 49798\n",
            "Embedding number : 49799\n",
            "Embedding number : 49800\n",
            "Embedding number : 49801\n",
            "Embedding number : 49802\n",
            "Embedding number : 49803\n",
            "Embedding number : 49804\n",
            "Embedding number : 49805\n",
            "Embedding number : 49806\n",
            "Embedding number : 49807\n",
            "Embedding number : 49808\n",
            "Embedding number : 49809\n",
            "Embedding number : 49810\n",
            "Embedding number : 49811\n",
            "Embedding number : 49812\n",
            "Embedding number : 49813\n",
            "Embedding number : 49814\n",
            "Embedding number : 49815\n",
            "Embedding number : 49816\n",
            "Embedding number : 49817\n",
            "Embedding number : 49818\n",
            "Embedding number : 49819\n",
            "Embedding number : 49820\n",
            "Embedding number : 49821\n",
            "Embedding number : 49822\n",
            "Embedding number : 49823\n",
            "Embedding number : 49824\n",
            "Embedding number : 49825\n",
            "Embedding number : 49826\n",
            "Embedding number : 49827\n",
            "Embedding number : 49828\n",
            "Embedding number : 49829\n",
            "Embedding number : 49830\n",
            "Embedding number : 49831\n",
            "Embedding number : 49832\n",
            "Embedding number : 49833\n",
            "Embedding number : 49834\n",
            "Embedding number : 49835\n",
            "Embedding number : 49836\n",
            "Embedding number : 49837\n",
            "Embedding number : 49838\n",
            "Embedding number : 49839\n",
            "Embedding number : 49840\n",
            "Embedding number : 49841\n",
            "Embedding number : 49842\n",
            "Embedding number : 49843\n",
            "Embedding number : 49844\n",
            "Embedding number : 49845\n",
            "Embedding number : 49846\n",
            "Embedding number : 49847\n",
            "Embedding number : 49848\n",
            "Embedding number : 49849\n",
            "Embedding number : 49850\n",
            "Embedding number : 49851\n",
            "Embedding number : 49852\n",
            "Embedding number : 49853\n",
            "Embedding number : 49854\n",
            "Embedding number : 49855\n",
            "Embedding number : 49856\n",
            "Embedding number : 49857\n",
            "Embedding number : 49858\n",
            "Embedding number : 49859\n",
            "Embedding number : 49860\n",
            "Embedding number : 49861\n",
            "Embedding number : 49862\n",
            "Embedding number : 49863\n",
            "Embedding number : 49864\n",
            "Embedding number : 49865\n",
            "Embedding number : 49866\n",
            "Embedding number : 49867\n",
            "Embedding number : 49868\n",
            "Embedding number : 49869\n",
            "Embedding number : 49870\n",
            "Embedding number : 49871\n",
            "Embedding number : 49872\n",
            "Embedding number : 49873\n",
            "Embedding number : 49874\n",
            "Embedding number : 49875\n",
            "Embedding number : 49876\n",
            "Embedding number : 49877\n",
            "Embedding number : 49878\n",
            "Embedding number : 49879\n",
            "Embedding number : 49880\n",
            "Embedding number : 49881\n",
            "Embedding number : 49882\n",
            "Embedding number : 49883\n",
            "Embedding number : 49884\n",
            "Embedding number : 49885\n",
            "Embedding number : 49886\n",
            "Embedding number : 49887\n",
            "Embedding number : 49888\n",
            "Embedding number : 49889\n",
            "Embedding number : 49890\n",
            "Embedding number : 49891\n",
            "Embedding number : 49892\n",
            "Embedding number : 49893\n",
            "Embedding number : 49894\n",
            "Embedding number : 49895\n",
            "Embedding number : 49896\n",
            "Embedding number : 49897\n",
            "Embedding number : 49898\n",
            "Embedding number : 49899\n",
            "Embedding number : 49900\n",
            "Embedding number : 49901\n",
            "Embedding number : 49902\n",
            "Embedding number : 49903\n",
            "Embedding number : 49904\n",
            "Embedding number : 49905\n",
            "Embedding number : 49906\n",
            "Embedding number : 49907\n",
            "Embedding number : 49908\n",
            "Embedding number : 49909\n",
            "Embedding number : 49910\n",
            "Embedding number : 49911\n",
            "Embedding number : 49912\n",
            "Embedding number : 49913\n",
            "Embedding number : 49914\n",
            "Embedding number : 49915\n",
            "Embedding number : 49916\n",
            "Embedding number : 49917\n",
            "Embedding number : 49918\n",
            "Embedding number : 49919\n",
            "Embedding number : 49920\n",
            "Embedding number : 49921\n",
            "Embedding number : 49922\n",
            "Embedding number : 49923\n",
            "Embedding number : 49924\n",
            "Embedding number : 49925\n",
            "Embedding number : 49926\n",
            "Embedding number : 49927\n",
            "Embedding number : 49928\n",
            "Embedding number : 49929\n",
            "Embedding number : 49930\n",
            "Embedding number : 49931\n",
            "Embedding number : 49932\n",
            "Embedding number : 49933\n",
            "Embedding number : 49934\n",
            "Embedding number : 49935\n",
            "Embedding number : 49936\n",
            "Embedding number : 49937\n",
            "Embedding number : 49938\n",
            "Embedding number : 49939\n",
            "Embedding number : 49940\n",
            "Embedding number : 49941\n",
            "Embedding number : 49942\n",
            "Embedding number : 49943\n",
            "Embedding number : 49944\n",
            "Embedding number : 49945\n",
            "Embedding number : 49946\n",
            "Embedding number : 49947\n",
            "Embedding number : 49948\n",
            "Embedding number : 49949\n",
            "Embedding number : 49950\n",
            "Embedding number : 49951\n",
            "Embedding number : 49952\n",
            "Embedding number : 49953\n",
            "Embedding number : 49954\n",
            "Embedding number : 49955\n",
            "Embedding number : 49956\n",
            "Embedding number : 49957\n",
            "Embedding number : 49958\n",
            "Embedding number : 49959\n",
            "Embedding number : 49960\n",
            "Embedding number : 49961\n",
            "Embedding number : 49962\n",
            "Embedding number : 49963\n",
            "Embedding number : 49964\n",
            "Embedding number : 49965\n",
            "Embedding number : 49966\n",
            "Embedding number : 49967\n",
            "Embedding number : 49968\n",
            "Embedding number : 49969\n",
            "Embedding number : 49970\n",
            "Embedding number : 49971\n",
            "Embedding number : 49972\n",
            "Embedding number : 49973\n",
            "Embedding number : 49974\n",
            "Embedding number : 49975\n",
            "Embedding number : 49976\n",
            "Embedding number : 49977\n",
            "Embedding number : 49978\n",
            "Embedding number : 49979\n",
            "Embedding number : 49980\n",
            "Embedding number : 49981\n",
            "Embedding number : 49982\n",
            "Embedding number : 49983\n",
            "Embedding number : 49984\n",
            "Embedding number : 49985\n",
            "Embedding number : 49986\n",
            "Embedding number : 49987\n",
            "Embedding number : 49988\n",
            "Embedding number : 49989\n",
            "Embedding number : 49990\n",
            "Embedding number : 49991\n",
            "Embedding number : 49992\n",
            "Embedding number : 49993\n",
            "Embedding number : 49994\n",
            "Embedding number : 49995\n",
            "Embedding number : 49996\n",
            "Embedding number : 49997\n",
            "Embedding number : 49998\n",
            "Embedding number : 49999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEbw_JYJHEQv"
      },
      "outputs": [],
      "source": [
        "# Save Embeddings\n",
        "torch.save(torch.stack(data_list),\"/content/drive/MyDrive/IMDB/bert-embed/IMDB_cls_last6layers.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Embeddings to Image"
      ],
      "metadata": {
        "id": "3ppqgo61NfPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Our embeddings are ready! In the next step, we should generate images for BERT-representations\n",
        "of the IMDB Dataset using pyDeepInsight from the following paper:\n",
        "\n",
        "**DeepInsight: A methodology to transform a non-image data to an image\n",
        "     for convolution neural network architecture**"
      ],
      "metadata": {
        "id": "3vSW-iCwNowl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip -q install git+https://github.com/alok-ai-lab/pyDeepInsight.git\n",
        "!pip install umap-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bSkMk19TBJO",
        "outputId": "376af85c-4811-4216-918e-9080855e8d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.58.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from pyDeepInsight import ImageTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "fWRRIVpTPNUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "data_path = Path('/content/drive/MyDrive/IMDB/bert-embed')\n",
        "data = torch.load(data_path / \"IMDB_cls_last6layers.pt\")\n",
        "data = data[:,:-1,:]\n",
        "data = np.array(data).reshape(50000,-1)"
      ],
      "metadata": {
        "id": "3RI7z-hoQr_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use t-SNE and DeepInsight to generate 50 * 50 pixel images from BERT Embeddings\n",
        "tsne = TSNE(\n",
        "    n_components=2,\n",
        "    random_state=1701,\n",
        "    n_jobs=-1)\n",
        "\n",
        "it = ImageTransformer(\n",
        "    feature_extractor=tsne,\n",
        "    pixels=50)\n",
        "\n",
        "X_train_img = it.fit_transform(data)\n",
        "dInsightImages = torch.from_numpy(X_train_img)"
      ],
      "metadata": {
        "id": "I-kKyWjEQ4oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del data"
      ],
      "metadata": {
        "id": "zu7Zmj2SH4WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train_img"
      ],
      "metadata": {
        "id": "SpFaE42hH6rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dInsightImages = dInsightImages.cuda()"
      ],
      "metadata": {
        "id": "zQmBhoqOIFiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save obtained images\n",
        "torch.save(dInsightImages, \"/content/drive/MyDrive/IMDB/imdb-image/Ready_images-six2elev.pt\")"
      ],
      "metadata": {
        "id": "2ZB1YDdvHsXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "zqera7fg_w76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our images are ready for training! Firstly we will change some parts of pretrained models based on the paper. Secondly, we will fine-tune them on the IMDB-Image Dataset:"
      ],
      "metadata": {
        "id": "US3kyAfKRqsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "from torchvision import models\n",
        "from torch import LongTensor\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional\n",
        "from torch.nn.functional import interpolate\n",
        "import json\n",
        "\n",
        "dtype = torch.cuda.FloatTensor\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "ctkWSJ3PV9rI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet"
      ],
      "metadata": {
        "id": "Kaa8sWUQ_3Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For AlexNet, we will use the first two pretrained convolutional layers which outputs 192 feature maps for each input image:"
      ],
      "metadata": {
        "id": "Jo2F9sb9TvR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine feature extractor\n",
        "def set_parameter_requires_grad(model, train_early=False):\n",
        "\n",
        "    feature_extractor_early = model.features[0:5]\n",
        "    if train_early == True:\n",
        "        for param in feature_extractor_early.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        for param in feature_extractor_early.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    return feature_extractor_early\n",
        "\n",
        "def create_feature_extractor(CNNmodel):\n",
        "    model = CNNmodel\n",
        "    model_features = set_parameter_requires_grad(model, train_early=False)\n",
        "    return model_features\n",
        "\n",
        "pretrained_early = create_feature_extractor(models.alexnet(pretrained=True))"
      ],
      "metadata": {
        "id": "R0146fJQXNVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dde160-b94b-4fa2-da95-635cea84904c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 149MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet\n",
        "class alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        global batch_size\n",
        "        super().__init__()\n",
        "        self.name = \"alexnet\"\n",
        "        self.feature_extractor = pretrained_early  # Early Layers PRetrained\n",
        "\n",
        "        self.conv_auto_encoder = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=2),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(192),\n",
        "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=2),\n",
        "        nn.ReLU(),\n",
        "\tnn.BatchNorm2d(192),\n",
        "        nn.Conv2d(in_channels=192, out_channels=192, kernel_size=2),\n",
        "        nn.ReLU(),\n",
        "\tnn.BatchNorm2d(192),\n",
        "        nn.Conv2d(in_channels=192, out_channels=64, kernel_size=2),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64)\n",
        "\t)\n",
        "        self.Adaptiveavgpool = nn.AdaptiveAvgPool2d(5)\n",
        "        self.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=False),\n",
        "        nn.Linear(1600, 700),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.3, inplace=False),\n",
        "        nn.Linear(700, 50),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(50, 2)\n",
        "        )\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_embedding):\n",
        "        preTrained_features = self.feature_extractor(input_embedding)\n",
        "        found_features = self.conv_auto_encoder(preTrained_features)\n",
        "        found_features = self.Adaptiveavgpool(found_features)\n",
        "        conv_shape = found_features.shape\n",
        "\n",
        "        try:\n",
        "            found_features = found_features.contiguous().view(batch_size, conv_shape[1] * conv_shape[2]*conv_shape[3])\n",
        "        except Exception as e:\n",
        "            found_features = found_features.contiguous().view(16, conv_shape[1] * conv_shape[2]*conv_shape[3])\n",
        "\n",
        "        logits = self.classifier(found_features)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "pCKEh33USsgv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNext"
      ],
      "metadata": {
        "id": "eeHaINy8AJnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ResNext, we will utilize the first convolutional layer as well as the first residual layer:"
      ],
      "metadata": {
        "id": "_6d30t2sgDQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine feature extractor layers\n",
        "def resnext_frozen():\n",
        "    resnext = models.resnext50_32x4d(pretrained=True)\n",
        "    feature_extractor = nn.Sequential(resnext.conv1,\n",
        "                                      resnext.bn1,\n",
        "                                      resnext.relu,\n",
        "\t\t\t\t                              resnext.maxpool,\n",
        "\t\t\t\t                              resnext.layer1)\n",
        "\n",
        "    for param in feature_extractor.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    del resnext\n",
        "    return feature_extractor"
      ],
      "metadata": {
        "id": "l-Cpuo6RgwMA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNext\n",
        "class resnext(nn.Module):\n",
        "    def __init__(self):\n",
        "        global batch_size\n",
        "        super().__init__()\n",
        "        self.name = \"resnext\"\n",
        "        self.feature_extractor = resnext_frozen()\n",
        "        self.conv_auto_encoder = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=256, out_channels=192, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(192),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=192, out_channels=128, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=128, out_channels=64, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=64, out_channels=32, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                                        )\n",
        "        self.adaptavgpool = nn.AdaptiveAvgPool2d(10)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                        nn.Linear(3200,1600),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.3, inplace = False),\n",
        "                        nn.Linear(1600,700),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.3, inplace = False),\n",
        "                        nn.Linear(700,50),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Linear(50,2)\n",
        "                        )\n",
        "\n",
        "    def forward(self, input_embedding):\n",
        "        from_pretrained = self.feature_extractor(input_embedding)\n",
        "        from_init = self.conv_auto_encoder(from_pretrained)\n",
        "        pooled_features = self.adaptavgpool(from_init)\n",
        "\n",
        "        pooled_features = pooled_features.contiguous().view(pooled_features.shape[0],-1)\n",
        "\n",
        "        logits = self.classifier(pooled_features)\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "Cn7aaAaxz5X1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "Ayg5dbysASuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ResNet, we will use the first downsampling convolutional layer and the first residual layer:"
      ],
      "metadata": {
        "id": "pAymSO7DhRoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature extractor layers\n",
        "def resnet_layer1_frozen():\n",
        "    resnet = models.wide_resnet50_2(pretrained=True)\n",
        "    feature_extractor = nn.Sequential(resnet.conv1,\n",
        "                                        resnet.bn1,\n",
        "    \t\t\t                resnet.relu,\n",
        "\t\t\t\t        resnet.maxpool,\n",
        "\t\t\t\t        resnet.layer1)\n",
        "\n",
        "    for param in feature_extractor.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    del resnet\n",
        "    return feature_extractor"
      ],
      "metadata": {
        "id": "0Blpgj_Zh_kV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet\n",
        "class resnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        global batch_size\n",
        "        super().__init__()\n",
        "        self.name = \"resnet\"\n",
        "        self.feature_extractor = resnet_layer1_frozen()\n",
        "        self.conv_auto_encoder = nn.Sequential(\n",
        "\t\t\t    nn.Conv2d(in_channels=256, out_channels=192, kernel_size=4),\n",
        "                            nn.ReLU(),\n",
        "\t\t\t    nn.BatchNorm2d(192),\n",
        "\t\t\t    nn.Dropout(p=0.2),\n",
        "                            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=4),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm2d(128),\n",
        "\t\t\t    nn.Dropout(p=0.2),\n",
        "                            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=4),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm2d(64),\n",
        "\t\t\t    nn.Dropout(p=0.2),\n",
        "                            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=4),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm2d(32),\n",
        "\t\t\t\t\t\t\t\t\t\t    )\n",
        "        self.adaptavgpool = nn.AdaptiveAvgPool2d(10)\n",
        "        self.classifier = nn.Sequential(\n",
        "\t\t\t\t    nn.Linear(3200,1600),\n",
        "\t\t\t\t    nn.ReLU(inplace=True),\n",
        "\t\t\t\t    nn.Dropout(p=0.3, inplace = False),\n",
        "\t\t\t\t    nn.Linear(1600,700),\n",
        "\t\t\t\t    nn.ReLU(inplace=True),\n",
        "\t\t\t\t    nn.Dropout(p=0.3, inplace = False),\n",
        "\t\t        \t    nn.Linear(700,50),\n",
        "\t\t\t\t    nn.ReLU(inplace=True),\n",
        "\t\t\t\t    nn.Linear(50,2)\n",
        "\t\t\t\t\t\t)\n",
        "\n",
        "    def forward(self, input_embedding):\n",
        "      from_pretrained = self.feature_extractor(input_embedding)\n",
        "      from_init = self.conv_auto_encoder(from_pretrained)\n",
        "      pooled_features = self.adaptavgpool(from_init)\n",
        "      pooled_features = pooled_features.contiguous().view(pooled_features.shape[0],-1)\n",
        "      logits = self.classifier(pooled_features)\n",
        "\n",
        "      return logits"
      ],
      "metadata": {
        "id": "WG3JqjNnAV0U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ShuffleNet"
      ],
      "metadata": {
        "id": "FIYqR6g5B-27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ShuffleNet, we used the ﬁrst convolutional layer followed by batch normalization, and stage2 mentioned in the shuffle-net paper:"
      ],
      "metadata": {
        "id": "_lENcHbPjfz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine feature extractor layers\n",
        "def shuffleNet_frozen():\n",
        "    shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
        "    feature_extractor = nn.Sequential(shufflenet.conv1,\n",
        "                                      shufflenet.maxpool,\n",
        "                                      shufflenet.stage2)\n",
        "\n",
        "    for param in feature_extractor.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    del shufflenet\n",
        "    return feature_extractor"
      ],
      "metadata": {
        "id": "6sGiWSRqj22t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffleNet\n",
        "class shufflenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        global batch_size\n",
        "        super().__init__()\n",
        "        self.name = \"shufflenet\"\n",
        "        self.feature_extractor = shuffleNet_frozen()\n",
        "        self.conv_auto_encoder = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=116, out_channels=192, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(192),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=192, out_channels=128, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=128, out_channels=64, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=64, out_channels=32, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                                        )\n",
        "        self.adaptavgpool = nn.AdaptiveAvgPool2d(10)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                        nn.Linear(3200,1600),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.3, inplace = False),\n",
        "                        nn.Linear(1600,700),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.3, inplace = False),\n",
        "                        nn.Linear(700,50),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Linear(50,2)\n",
        "                        )\n",
        "\n",
        "    def forward(self, input_embedding):\n",
        "        from_pretrained = self.feature_extractor(input_embedding)\n",
        "        from_init = self.conv_auto_encoder(from_pretrained)\n",
        "        pooled_features = self.adaptavgpool(from_init)\n",
        "\n",
        "        pooled_features = pooled_features.contiguous().view(pooled_features.shape[0],-1)\n",
        "\n",
        "        logits = self.classifier(pooled_features)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "dWG6Bls9CEXK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16"
      ],
      "metadata": {
        "id": "g08r5XbBCKPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " In case of VGG16, we use the ﬁrst 12 layers, containing 4 Convolutional layers for the feature extractor in this experiment:"
      ],
      "metadata": {
        "id": "i8M8WQC6k1JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine feature extractor layers\n",
        "def vgg16_frozen():\n",
        "    vgg16 = models.vgg16(pretrained=True)\n",
        "    feature_extractor = vgg16.features[:12]\n",
        "\n",
        "    for param in feature_extractor.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    del vgg16\n",
        "    return feature_extractor"
      ],
      "metadata": {
        "id": "Te-rmlwhkq4d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16\n",
        "class vgg16(nn.Module):\n",
        "    def __init__(self):\n",
        "        global batch_size\n",
        "        super().__init__()\n",
        "        self.name = \"vgg16\"\n",
        "        self.feature_extractor = vgg16_frozen()\n",
        "        self.conv_auto_encoder = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=256, out_channels=192, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(192),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=192, out_channels=128, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=128, out_channels=64, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Dropout(p=0.05),\n",
        "                        nn.Conv2d(in_channels=64, out_channels=32, kernel_size=4),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                                        )\n",
        "        self.adaptavgpool = nn.AdaptiveAvgPool2d(10)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                        nn.Linear(3200,1600),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.3, inplace = False),\n",
        "                        nn.Linear(1600,700),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.3, inplace = False),\n",
        "                        nn.Linear(700,50),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Linear(50,2)\n",
        "                        )\n",
        "\n",
        "    def forward(self, input_embedding):\n",
        "        from_pretrained = self.feature_extractor(input_embedding)\n",
        "        from_init = self.conv_auto_encoder(from_pretrained)\n",
        "        pooled_features = self.adaptavgpool(from_init)\n",
        "\n",
        "        pooled_features = pooled_features.contiguous().view(pooled_features.shape[0],-1)\n",
        "\n",
        "        logits = self.classifier(pooled_features)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "WyiBhhARCOCa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time to train"
      ],
      "metadata": {
        "id": "BWc4_rW8CUpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After making our CNN models ready, it's time to train them on IMDB-Image Dataset:"
      ],
      "metadata": {
        "id": "sJi9p9QGnx5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "from torch.nn import functional\n",
        "from torch.nn.functional import interpolate\n",
        "from pathlib import Path\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
        "import sys\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "XGjTQuAboCww"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset to get labels\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/IMDB/IMDB Dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H3BcupVkh_oe",
        "outputId": "0d87e8f2-e228-459a-cd5d-8ec067a08c1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73bc11c2-1fad-4187-ac6c-76f2366b010e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73bc11c2-1fad-4187-ac6c-76f2366b010e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73bc11c2-1fad-4187-ac6c-76f2366b010e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73bc11c2-1fad-4187-ac6c-76f2366b010e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d9a8176-3c15-4e07-8930-7202f0ea1f58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d9a8176-3c15-4e07-8930-7202f0ea1f58')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d9a8176-3c15-4e07-8930-7202f0ea1f58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding labels\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "enc = LabelBinarizer()\n",
        "y = enc.fit_transform(df['sentiment'])"
      ],
      "metadata": {
        "id": "6CYjkiXBhjAM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels ready for training\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "categorical_labels = to_categorical(y, num_classes=2)"
      ],
      "metadata": {
        "id": "9XX68XhnhkJ_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Images\n",
        "data = torch.load(\"/content/drive/MyDrive/IMDB/imdb-image/Ready_images-six2elev.pt\",map_location='cuda:0')\n",
        "labels = torch.tensor(categorical_labels)"
      ],
      "metadata": {
        "id": "CRE9EtT3pIu0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset for training\n",
        "def create_dataset(input_embedding, input_labels):\n",
        "\tglobal batch_size\n",
        "\tdataset = TensorDataset(input_embedding.type(dtype).cuda(),\n",
        "\t\t\t            input_labels.type(dtype).cuda())\n",
        "\t#Splits\n",
        "\ttrain_size = int(0.8 * len(dataset))\n",
        "\tval_size = int(0.2 * len(dataset))\n",
        "\n",
        "\ttrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\ttrain_loader = DataLoader(dataset=train_dataset, batch_size = batch_size,shuffle=True)\n",
        "\tval_loader = DataLoader(dataset = val_dataset, batch_size = batch_size,shuffle=True)\n",
        "\treturn train_loader, val_loader\n",
        "\n",
        "train_loader, val_loader = create_dataset(data, labels)\n",
        "\n",
        "del data, labels"
      ],
      "metadata": {
        "id": "yegyDmOlrTWG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to init layer weights\n",
        "def initialize_parameters(m) -> None:\n",
        "\tif isinstance(m, nn.Linear):\n",
        "\t\tm.weight.data = init.xavier_uniform_(m.weight.data,\n",
        "\t\t\t\t\t\t    gain=nn.init.calculate_gain('relu'))\n",
        "\tif isinstance(m, nn.Conv2d):\n",
        "\t\tm.weight.data = init.xavier_normal_(m.weight.data)"
      ],
      "metadata": {
        "id": "27ucOM4eqN1H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rates for different models\n",
        "learning_rates = {'alexnet': {\"CAE LR\": 0.00001, \"LC LR\":0.0005},\n",
        "                    'resnet': {\"CAE LR\": 0.00005, \"LC LR\":0.0001},\n",
        "                    'resnext': {\"CAE LR\": 0.00005, \"LC LR\":0.001 },\n",
        "                    'shufflenet': {\"CAE LR\": 0.0005, \"LC LR\":0.001},\n",
        "                    'vgg16': {\"CAE LR\": 0.00005, \"LC LR\":0.001}\n",
        "                }"
      ],
      "metadata": {
        "id": "EUp-E4k8DoWl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model dictionary\n",
        "model_dict = {'alexnet': alexnet(),\n",
        "              'resnet': resnet(),\n",
        "              'resnext': resnext(),\n",
        "              'shufflenet': shufflenet(),\n",
        "              'vgg16':vgg16()}"
      ],
      "metadata": {
        "id": "xDjUcPuXFBKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aacc693-fa81-4d10-ff81-9934c5f9de51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
            "100%|██████████| 132M/132M [00:03<00:00, 44.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
            "100%|██████████| 95.8M/95.8M [00:01<00:00, 83.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n",
            "100%|██████████| 8.79M/8.79M [00:00<00:00, 73.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 82.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to create the desired model\n",
        "def create_model(model_name):\n",
        "    model = model_dict[model_name]\n",
        "    model.conv_auto_encoder.apply(initialize_parameters)\n",
        "    model.classifier.apply(initialize_parameters)\n",
        "    model = model.cuda()\n",
        "    return model"
      ],
      "metadata": {
        "id": "YBAmeWr_xRNx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the whole process of training and evaluation of a model\n",
        "def train_and_evaluate():\n",
        "    # Training settings and results\n",
        "    train_total = 0\n",
        "    train_correct = 0\n",
        "    val_total = 0\n",
        "    val_correct = 0\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    model_status_dict = []\n",
        "    Epochs = 15\n",
        "    iteration  = 0\n",
        "    step = 0\n",
        "    val_step = 0\n",
        "\n",
        "    for epoch in range(Epochs):\n",
        "        for i, (input_batch, label) in enumerate(train_loader):\n",
        "            model.train()\n",
        "            input_batch = scale_image_batch(input_batch)\n",
        "            input_batch = z_normalize(input_batch)\n",
        "            label = label.contiguous().view(batch_size, 2)\n",
        "            label = torch.max(label.long().to(device),1)[1]\n",
        "            output = model(input_batch)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            train_total += label.size(0)\n",
        "            train_correct += (predicted == label).sum().item()\n",
        "            train_accuracy = train_correct/train_total\n",
        "            train_accuracies.append(train_accuracy)\n",
        "            loss = criterion(output, label)\n",
        "            train_losses.append(loss.item())\n",
        "            step += 1\n",
        "            opt_model(loss)\n",
        "            iteration += 1\n",
        "\n",
        "            if iteration %50 == 0:\n",
        "                model.eval()\n",
        "                for j,(val_input_batch, val_label) in enumerate(val_loader):\n",
        "                    val_input_batch = scale_image_batch(val_input_batch)\n",
        "                    val_input_batch = z_normalize(val_input_batch)\n",
        "                    try:\n",
        "                        val_label = val_label.contiguous().view(batch_size,2)\n",
        "                    except Exception as e:\n",
        "                        val_label = val_label.contiguous().view(16,2)\n",
        "                    val_label = torch.max(val_label.long().to(device),1)[1]\n",
        "                    val_output = model(val_input_batch)\n",
        "                    _, val_predicted = torch.max(val_output.data, 1)\n",
        "                    val_total += val_label.size(0)\n",
        "                    val_correct += (val_predicted == val_label).sum().item()\n",
        "                    val_accuracy = val_correct/val_total\n",
        "                    val_accuracies.append(val_accuracy)\n",
        "                    val_loss = criterion(val_output, val_label)\n",
        "                    val_step += 1\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                try:\n",
        "                    print(f\"\"\"    epoch: {epoch + 1}\n",
        "                    \\t     Train Loss : {np.mean(train_losses)}\n",
        "                    \\t     Validation Loss : {np.mean(val_losses)}\n",
        "                    \\t     Training Accuracy : {train_accuracy}\n",
        "                    \\t     Validation Accuracy : {val_accuracy}\n",
        "                    \"\"\")\n",
        "\n",
        "                    m_dict = {\n",
        "                        'epoch': epoch + 1,\n",
        "                        'Train Loss' : np.mean(train_losses),\n",
        "                        'Validation Loss' : np.mean(val_losses),\n",
        "                        'Training Accuracy' : train_accuracy,\n",
        "                        'Validation Accuracy' : val_accuracy\n",
        "                            }\n",
        "\n",
        "                    # Save model status\n",
        "                    model_status_dict.append(m_dict)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    continue\n",
        "\n",
        "    #Saving Validation Losses, Accuracies and states\n",
        "    save_path = \"/content/drive/MyDrive/IMDB/results\"\n",
        "    torch.save(val_losses, save_path + \"/\" + str(model.name)+\"_val_losses.pt\")\n",
        "    torch.save(val_accuracies , save_path + \"/\" + str(model.name)+\"_val_accs.pt\")\n",
        "    with open(save_path + \"/\" + str(model.name)+\"_status.txt\" , 'w') as file:\n",
        "      json.dump(model_status_dict, file)\n"
      ],
      "metadata": {
        "id": "5H5FPcFo9-eZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizing model\n",
        "def opt_model(loss)-> None:\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Pxe_LDml0g7C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling and Z-normalizing images\n",
        "upsample = nn.Upsample(scale_factor = 3, mode = \"nearest\")\n",
        "\n",
        "def scale_image_batch(image_batch) -> torch.Tensor:\n",
        "    a = torch.movedim(image_batch, -1,1)\n",
        "    scaled_batch = upsample(a)\n",
        "    return scaled_batch.cuda()\n",
        "\n",
        "\n",
        "\n",
        "def z_normalize(input_tensor) -> torch.Tensor:\n",
        "    mean = input_tensor.mean()\n",
        "    std = input_tensor.std()\n",
        "    up = torch.sub(input_tensor, mean)\n",
        "    down = torch.add(std**2, 0.0001**2)\n",
        "    return torch.div(up,torch.sqrt(down))"
      ],
      "metadata": {
        "id": "mjmcf3YE0r1y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AlexNet"
      ],
      "metadata": {
        "id": "k_4P7-HAD6mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the paper, it was mentioned that AlexNet achieved 0.87 accuracy on validation but here we achieved 0.79 accuracy:"
      ],
      "metadata": {
        "id": "Zhvdl0cvmex8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('alexnet')\n",
        "\n",
        "optimizer = optim.Adam([{'params': model.feature_extractor.parameters()},\n",
        "    {'params': model.conv_auto_encoder.parameters(), 'lr' : learning_rates[str(model.name)]['CAE LR']},\n",
        "    {'params': model.classifier.parameters(), 'lr' : learning_rates[str(model.name)]['LC LR']}],\n",
        "    lr=0.0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JdPXOIMxs6C",
        "outputId": "1f5bf69a-a7f0-4ca5-9a72-cc8e2efd832e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.8706789493560791\n",
            "                    \t     Validation Loss : 0.656785101745837\n",
            "                    \t     Training Accuracy : 0.5325\n",
            "                    \t     Validation Accuracy : 0.626\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7716198515892029\n",
            "                    \t     Validation Loss : 0.6501881605900895\n",
            "                    \t     Training Accuracy : 0.5640625\n",
            "                    \t     Validation Accuracy : 0.6285\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7309416969617207\n",
            "                    \t     Validation Loss : 0.6379981338025663\n",
            "                    \t     Training Accuracy : 0.5802083333333333\n",
            "                    \t     Validation Accuracy : 0.6381\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7049411226809025\n",
            "                    \t     Validation Loss : 0.6228290775332588\n",
            "                    \t     Training Accuracy : 0.5990625\n",
            "                    \t     Validation Accuracy : 0.657175\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6804649209976197\n",
            "                    \t     Validation Loss : 0.6121920511554986\n",
            "                    \t     Training Accuracy : 0.616125\n",
            "                    \t     Validation Accuracy : 0.66698\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.664241510828336\n",
            "                    \t     Validation Loss : 0.5993047447059863\n",
            "                    \t     Training Accuracy : 0.6275\n",
            "                    \t     Validation Accuracy : 0.6772333333333334\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6530135003158024\n",
            "                    \t     Validation Loss : 0.5890631056550103\n",
            "                    \t     Training Accuracy : 0.6367857142857143\n",
            "                    \t     Validation Accuracy : 0.6859285714285714\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6409858448803425\n",
            "                    \t     Validation Loss : 0.5824150927126789\n",
            "                    \t     Training Accuracy : 0.645078125\n",
            "                    \t     Validation Accuracy : 0.6915375\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6330817490153843\n",
            "                    \t     Validation Loss : 0.5758359500775322\n",
            "                    \t     Training Accuracy : 0.6514583333333334\n",
            "                    \t     Validation Accuracy : 0.6968555555555556\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6248162750005722\n",
            "                    \t     Validation Loss : 0.5695243683390724\n",
            "                    \t     Training Accuracy : 0.65825\n",
            "                    \t     Validation Accuracy : 0.70171\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6171751866015521\n",
            "                    \t     Validation Loss : 0.5636844197106923\n",
            "                    \t     Training Accuracy : 0.6644318181818182\n",
            "                    \t     Validation Accuracy : 0.7066454545454546\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6099978777269522\n",
            "                    \t     Validation Loss : 0.5587973604663111\n",
            "                    \t     Training Accuracy : 0.670625\n",
            "                    \t     Validation Accuracy : 0.7103166666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6048239748753034\n",
            "                    \t     Validation Loss : 0.5547428712721215\n",
            "                    \t     Training Accuracy : 0.6750480769230769\n",
            "                    \t     Validation Accuracy : 0.7133615384615385\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5981214607613428\n",
            "                    \t     Validation Loss : 0.553522487989249\n",
            "                    \t     Training Accuracy : 0.6804910714285715\n",
            "                    \t     Validation Accuracy : 0.7143714285714285\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5930948696931203\n",
            "                    \t     Validation Loss : 0.5491877914046327\n",
            "                    \t     Training Accuracy : 0.6832916666666666\n",
            "                    \t     Validation Accuracy : 0.71762\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5875677221268415\n",
            "                    \t     Validation Loss : 0.5448932529876407\n",
            "                    \t     Training Accuracy : 0.6871484375\n",
            "                    \t     Validation Accuracy : 0.72084375\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5840940217060201\n",
            "                    \t     Validation Loss : 0.5413476540739431\n",
            "                    \t     Training Accuracy : 0.6896691176470588\n",
            "                    \t     Validation Accuracy : 0.7234529411764706\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5801422935393121\n",
            "                    \t     Validation Loss : 0.5384001761971106\n",
            "                    \t     Training Accuracy : 0.6928472222222222\n",
            "                    \t     Validation Accuracy : 0.72545\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5766795066469594\n",
            "                    \t     Validation Loss : 0.5352163323388693\n",
            "                    \t     Training Accuracy : 0.6953289473684211\n",
            "                    \t     Validation Accuracy : 0.7278263157894737\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5719110737740993\n",
            "                    \t     Validation Loss : 0.5319825129791761\n",
            "                    \t     Training Accuracy : 0.69896875\n",
            "                    \t     Validation Accuracy : 0.730095\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5677038199560983\n",
            "                    \t     Validation Loss : 0.5288686172119399\n",
            "                    \t     Training Accuracy : 0.7021428571428572\n",
            "                    \t     Validation Accuracy : 0.7322809523809524\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5643622028827667\n",
            "                    \t     Validation Loss : 0.5261693970710601\n",
            "                    \t     Training Accuracy : 0.7047727272727272\n",
            "                    \t     Validation Accuracy : 0.7342681818181818\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5626839611322983\n",
            "                    \t     Validation Loss : 0.5242104350936828\n",
            "                    \t     Training Accuracy : 0.7066847826086956\n",
            "                    \t     Validation Accuracy : 0.7357521739130435\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5601153373221557\n",
            "                    \t     Validation Loss : 0.5224428052842395\n",
            "                    \t     Training Accuracy : 0.70859375\n",
            "                    \t     Validation Accuracy : 0.7369333333333333\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5582617493867874\n",
            "                    \t     Validation Loss : 0.5208266198082854\n",
            "                    \t     Training Accuracy : 0.71065\n",
            "                    \t     Validation Accuracy : 0.738192\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5558917992390119\n",
            "                    \t     Validation Loss : 0.5188855350175019\n",
            "                    \t     Training Accuracy : 0.7126923076923077\n",
            "                    \t     Validation Accuracy : 0.7394923076923077\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5532907919972031\n",
            "                    \t     Validation Loss : 0.5170783677488061\n",
            "                    \t     Training Accuracy : 0.7149074074074074\n",
            "                    \t     Validation Accuracy : 0.7406518518518519\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5503991789051464\n",
            "                    \t     Validation Loss : 0.5150617343096878\n",
            "                    \t     Training Accuracy : 0.7172767857142858\n",
            "                    \t     Validation Accuracy : 0.7420107142857143\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5470642466791745\n",
            "                    \t     Validation Loss : 0.5141327639413166\n",
            "                    \t     Training Accuracy : 0.7197198275862069\n",
            "                    \t     Validation Accuracy : 0.7426793103448276\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5448561095396678\n",
            "                    \t     Validation Loss : 0.5122733783560058\n",
            "                    \t     Training Accuracy : 0.7215\n",
            "                    \t     Validation Accuracy : 0.7439633333333333\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5421510303020477\n",
            "                    \t     Validation Loss : 0.5105906064060316\n",
            "                    \t     Training Accuracy : 0.7233266129032258\n",
            "                    \t     Validation Accuracy : 0.7451322580645161\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5393536954931915\n",
            "                    \t     Validation Loss : 0.509503986821852\n",
            "                    \t     Training Accuracy : 0.7251953125\n",
            "                    \t     Validation Accuracy : 0.74583125\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5368016081506556\n",
            "                    \t     Validation Loss : 0.5077935111512287\n",
            "                    \t     Training Accuracy : 0.7269696969696969\n",
            "                    \t     Validation Accuracy : 0.7470030303030303\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5347413357040461\n",
            "                    \t     Validation Loss : 0.5068730683708478\n",
            "                    \t     Training Accuracy : 0.7285110294117647\n",
            "                    \t     Validation Accuracy : 0.7478\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5333515391009195\n",
            "                    \t     Validation Loss : 0.5056223811841022\n",
            "                    \t     Training Accuracy : 0.7296607142857143\n",
            "                    \t     Validation Accuracy : 0.7486457142857142\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5318200360900825\n",
            "                    \t     Validation Loss : 0.5043567988266431\n",
            "                    \t     Training Accuracy : 0.7309201388888888\n",
            "                    \t     Validation Accuracy : 0.7496666666666667\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5298680320301571\n",
            "                    \t     Validation Loss : 0.5029136678883473\n",
            "                    \t     Training Accuracy : 0.7325\n",
            "                    \t     Validation Accuracy : 0.7506864864864865\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5281571982722534\n",
            "                    \t     Validation Loss : 0.5015214299224036\n",
            "                    \t     Training Accuracy : 0.7339309210526316\n",
            "                    \t     Validation Accuracy : 0.7516157894736842\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.527560941790923\n",
            "                    \t     Validation Loss : 0.5003634131581209\n",
            "                    \t     Training Accuracy : 0.7341185897435898\n",
            "                    \t     Validation Accuracy : 0.752523076923077\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5254918899312615\n",
            "                    \t     Validation Loss : 0.4993625956828507\n",
            "                    \t     Training Accuracy : 0.7355\n",
            "                    \t     Validation Accuracy : 0.75335\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5236504946176599\n",
            "                    \t     Validation Loss : 0.49810642296509167\n",
            "                    \t     Training Accuracy : 0.7367987804878049\n",
            "                    \t     Validation Accuracy : 0.7541853658536586\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5227090260457425\n",
            "                    \t     Validation Loss : 0.4971474564587364\n",
            "                    \t     Training Accuracy : 0.7375148809523809\n",
            "                    \t     Validation Accuracy : 0.7547928571428572\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5210515443460886\n",
            "                    \t     Validation Loss : 0.4959614458846447\n",
            "                    \t     Training Accuracy : 0.7388226744186046\n",
            "                    \t     Validation Accuracy : 0.7555930232558139\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5196766754375263\n",
            "                    \t     Validation Loss : 0.4949669861647233\n",
            "                    \t     Training Accuracy : 0.7400142045454545\n",
            "                    \t     Validation Accuracy : 0.7562068181818182\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5182409334381421\n",
            "                    \t     Validation Loss : 0.49408065384696215\n",
            "                    \t     Training Accuracy : 0.7409583333333334\n",
            "                    \t     Validation Accuracy : 0.7567177777777778\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5164363109547159\n",
            "                    \t     Validation Loss : 0.49298209095911144\n",
            "                    \t     Training Accuracy : 0.7420652173913044\n",
            "                    \t     Validation Accuracy : 0.7575347826086957\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5154583972565672\n",
            "                    \t     Validation Loss : 0.49217270253208817\n",
            "                    \t     Training Accuracy : 0.7428058510638298\n",
            "                    \t     Validation Accuracy : 0.7580106382978723\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5144319278125962\n",
            "                    \t     Validation Loss : 0.49113944348213645\n",
            "                    \t     Training Accuracy : 0.7434635416666666\n",
            "                    \t     Validation Accuracy : 0.758675\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5126384160956557\n",
            "                    \t     Validation Loss : 0.49006865651159653\n",
            "                    \t     Training Accuracy : 0.7446938775510205\n",
            "                    \t     Validation Accuracy : 0.7593673469387755\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5112704938173294\n",
            "                    \t     Validation Loss : 0.4890530313022982\n",
            "                    \t     Training Accuracy : 0.7456625\n",
            "                    \t     Validation Accuracy : 0.760028\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5096997822441307\n",
            "                    \t     Validation Loss : 0.4881682408947787\n",
            "                    \t     Training Accuracy : 0.7468504901960784\n",
            "                    \t     Validation Accuracy : 0.7605705882352941\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5083179606439976\n",
            "                    \t     Validation Loss : 0.48722563777553796\n",
            "                    \t     Training Accuracy : 0.7479086538461538\n",
            "                    \t     Validation Accuracy : 0.7611826923076923\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5068408037581533\n",
            "                    \t     Validation Loss : 0.48631910344681106\n",
            "                    \t     Training Accuracy : 0.7488561320754717\n",
            "                    \t     Validation Accuracy : 0.7618245283018867\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5057865793285546\n",
            "                    \t     Validation Loss : 0.4854903471836986\n",
            "                    \t     Training Accuracy : 0.7496296296296296\n",
            "                    \t     Validation Accuracy : 0.7623462962962962\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5045981512611563\n",
            "                    \t     Validation Loss : 0.4847408891148322\n",
            "                    \t     Training Accuracy : 0.7504431818181818\n",
            "                    \t     Validation Accuracy : 0.7629254545454546\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5036063283043248\n",
            "                    \t     Validation Loss : 0.48396523745024056\n",
            "                    \t     Training Accuracy : 0.7512388392857143\n",
            "                    \t     Validation Accuracy : 0.7634017857142857\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5025113330441608\n",
            "                    \t     Validation Loss : 0.4835405884790124\n",
            "                    \t     Training Accuracy : 0.751907894736842\n",
            "                    \t     Validation Accuracy : 0.7637122807017543\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5013220059614757\n",
            "                    \t     Validation Loss : 0.48286143026550765\n",
            "                    \t     Training Accuracy : 0.7527478448275862\n",
            "                    \t     Validation Accuracy : 0.7641706896551724\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.5003802185897099\n",
            "                    \t     Validation Loss : 0.4820563580029682\n",
            "                    \t     Training Accuracy : 0.7534745762711864\n",
            "                    \t     Validation Accuracy : 0.7647118644067796\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4991663546363513\n",
            "                    \t     Validation Loss : 0.48140151766193306\n",
            "                    \t     Training Accuracy : 0.7541979166666667\n",
            "                    \t     Validation Accuracy : 0.7651833333333333\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4983489059278222\n",
            "                    \t     Validation Loss : 0.48065886720535\n",
            "                    \t     Training Accuracy : 0.7546823770491803\n",
            "                    \t     Validation Accuracy : 0.7657262295081967\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4970349454543283\n",
            "                    \t     Validation Loss : 0.47996866693358364\n",
            "                    \t     Training Accuracy : 0.7554133064516129\n",
            "                    \t     Validation Accuracy : 0.7662064516129032\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4963830838837321\n",
            "                    \t     Validation Loss : 0.4793063168929166\n",
            "                    \t     Training Accuracy : 0.7558730158730159\n",
            "                    \t     Validation Accuracy : 0.7666666666666667\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.49495864151511343\n",
            "                    \t     Validation Loss : 0.4789793262490259\n",
            "                    \t     Training Accuracy : 0.756845703125\n",
            "                    \t     Validation Accuracy : 0.7669640625\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.49365167264754956\n",
            "                    \t     Validation Loss : 0.4782362333099038\n",
            "                    \t     Training Accuracy : 0.757576923076923\n",
            "                    \t     Validation Accuracy : 0.7674430769230769\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4924542792909073\n",
            "                    \t     Validation Loss : 0.477657599151221\n",
            "                    \t     Training Accuracy : 0.7584469696969697\n",
            "                    \t     Validation Accuracy : 0.7678090909090909\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.491236520200523\n",
            "                    \t     Validation Loss : 0.47737166810263654\n",
            "                    \t     Training Accuracy : 0.7594029850746269\n",
            "                    \t     Validation Accuracy : 0.7681134328358209\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4906453288609491\n",
            "                    \t     Validation Loss : 0.47670673789150886\n",
            "                    \t     Training Accuracy : 0.7598161764705882\n",
            "                    \t     Validation Accuracy : 0.7685264705882353\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4896645315531371\n",
            "                    \t     Validation Loss : 0.4760654187777332\n",
            "                    \t     Training Accuracy : 0.7603804347826087\n",
            "                    \t     Validation Accuracy : 0.7689507246376811\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.48863769525715284\n",
            "                    \t     Validation Loss : 0.47538960642503963\n",
            "                    \t     Training Accuracy : 0.7610803571428572\n",
            "                    \t     Validation Accuracy : 0.7693842857142857\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4877443711060873\n",
            "                    \t     Validation Loss : 0.47481033192240185\n",
            "                    \t     Training Accuracy : 0.761725352112676\n",
            "                    \t     Validation Accuracy : 0.7697788732394366\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4868750650684039\n",
            "                    \t     Validation Loss : 0.4742311420349585\n",
            "                    \t     Training Accuracy : 0.7624479166666667\n",
            "                    \t     Validation Accuracy : 0.7701680555555556\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4859520605492265\n",
            "                    \t     Validation Loss : 0.4737660966376944\n",
            "                    \t     Training Accuracy : 0.7630650684931507\n",
            "                    \t     Validation Accuracy : 0.7705246575342466\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.48513617651688085\n",
            "                    \t     Validation Loss : 0.4734766610110221\n",
            "                    \t     Training Accuracy : 0.7636993243243243\n",
            "                    \t     Validation Accuracy : 0.7707513513513513\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4841663410147031\n",
            "                    \t     Validation Loss : 0.4729809885099927\n",
            "                    \t     Training Accuracy : 0.76435\n",
            "                    \t     Validation Accuracy : 0.7710626666666667\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.483210399990019\n",
            "                    \t     Validation Loss : 0.47235622433768576\n",
            "                    \t     Training Accuracy : 0.7650986842105263\n",
            "                    \t     Validation Accuracy : 0.7715\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4817055625342703\n",
            "                    \t     Validation Loss : 0.4717718188947951\n",
            "                    \t     Training Accuracy : 0.7660795454545455\n",
            "                    \t     Validation Accuracy : 0.7718753246753247\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4804946017303528\n",
            "                    \t     Validation Loss : 0.4713595442170543\n",
            "                    \t     Training Accuracy : 0.7668990384615385\n",
            "                    \t     Validation Accuracy : 0.7721769230769231\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47965569959411136\n",
            "                    \t     Validation Loss : 0.4708041861522558\n",
            "                    \t     Training Accuracy : 0.7675395569620254\n",
            "                    \t     Validation Accuracy : 0.7725329113924051\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4786462313085794\n",
            "                    \t     Validation Loss : 0.4703710889872223\n",
            "                    \t     Training Accuracy : 0.7683828125\n",
            "                    \t     Validation Accuracy : 0.7727675\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47768936187396815\n",
            "                    \t     Validation Loss : 0.46983705544073956\n",
            "                    \t     Training Accuracy : 0.7690123456790123\n",
            "                    \t     Validation Accuracy : 0.7731185185185185\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4768647966515727\n",
            "                    \t     Validation Loss : 0.4693180621970817\n",
            "                    \t     Training Accuracy : 0.7695350609756098\n",
            "                    \t     Validation Accuracy : 0.7734585365853659\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47588120604135903\n",
            "                    \t     Validation Loss : 0.46888370460102285\n",
            "                    \t     Training Accuracy : 0.7701581325301204\n",
            "                    \t     Validation Accuracy : 0.7737518072289157\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47517240702396346\n",
            "                    \t     Validation Loss : 0.4685739402436927\n",
            "                    \t     Training Accuracy : 0.770639880952381\n",
            "                    \t     Validation Accuracy : 0.7740095238095238\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4744432115204194\n",
            "                    \t     Validation Loss : 0.46807081336209794\n",
            "                    \t     Training Accuracy : 0.7711029411764706\n",
            "                    \t     Validation Accuracy : 0.7743458823529412\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4735803916911746\n",
            "                    \t     Validation Loss : 0.4677126840851939\n",
            "                    \t     Training Accuracy : 0.7716279069767442\n",
            "                    \t     Validation Accuracy : 0.7745848837209303\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47293298581893417\n",
            "                    \t     Validation Loss : 0.46719628002103725\n",
            "                    \t     Training Accuracy : 0.771875\n",
            "                    \t     Validation Accuracy : 0.7749195402298851\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47235041712834075\n",
            "                    \t     Validation Loss : 0.4667559351637903\n",
            "                    \t     Training Accuracy : 0.7722017045454546\n",
            "                    \t     Validation Accuracy : 0.7752147727272727\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47141731707902435\n",
            "                    \t     Validation Loss : 0.4662981074278381\n",
            "                    \t     Training Accuracy : 0.7727668539325843\n",
            "                    \t     Validation Accuracy : 0.7755022471910112\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47061697869499525\n",
            "                    \t     Validation Loss : 0.46584232045396406\n",
            "                    \t     Training Accuracy : 0.7732152777777778\n",
            "                    \t     Validation Accuracy : 0.7758055555555555\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.47001321588243755\n",
            "                    \t     Validation Loss : 0.4654442443745284\n",
            "                    \t     Training Accuracy : 0.7737774725274725\n",
            "                    \t     Validation Accuracy : 0.7760956043956044\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4696426602874113\n",
            "                    \t     Validation Loss : 0.46498085930995237\n",
            "                    \t     Training Accuracy : 0.7740421195652174\n",
            "                    \t     Validation Accuracy : 0.7763880434782608\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4690610277236149\n",
            "                    \t     Validation Loss : 0.46461058220484036\n",
            "                    \t     Training Accuracy : 0.7743884408602151\n",
            "                    \t     Validation Accuracy : 0.7766645161290323\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.46825354404588965\n",
            "                    \t     Validation Loss : 0.46426829251685287\n",
            "                    \t     Training Accuracy : 0.7749069148936171\n",
            "                    \t     Validation Accuracy : 0.7768627659574469\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.46771986034041957\n",
            "                    \t     Validation Loss : 0.4638271500017135\n",
            "                    \t     Training Accuracy : 0.7752631578947369\n",
            "                    \t     Validation Accuracy : 0.77716\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.46749715811262527\n",
            "                    \t     Validation Loss : 0.46338019826815435\n",
            "                    \t     Training Accuracy : 0.7753971354166667\n",
            "                    \t     Validation Accuracy : 0.7774479166666667\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4670077847635623\n",
            "                    \t     Validation Loss : 0.46299514624867993\n",
            "                    \t     Training Accuracy : 0.7756958762886598\n",
            "                    \t     Validation Accuracy : 0.777680412371134\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4662096737933402\n",
            "                    \t     Validation Loss : 0.46272042304736005\n",
            "                    \t     Training Accuracy : 0.7762372448979592\n",
            "                    \t     Validation Accuracy : 0.7779061224489796\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.46535733135661694\n",
            "                    \t     Validation Loss : 0.46257189182135366\n",
            "                    \t     Training Accuracy : 0.7767424242424242\n",
            "                    \t     Validation Accuracy : 0.7780686868686869\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4647713685363531\n",
            "                    \t     Validation Loss : 0.4622275719370324\n",
            "                    \t     Training Accuracy : 0.77718125\n",
            "                    \t     Validation Accuracy : 0.778259\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4636753748401557\n",
            "                    \t     Validation Loss : 0.461839574303637\n",
            "                    \t     Training Accuracy : 0.7778217821782178\n",
            "                    \t     Validation Accuracy : 0.7785346534653466\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4629703507908419\n",
            "                    \t     Validation Loss : 0.46174451529985305\n",
            "                    \t     Training Accuracy : 0.7783088235294118\n",
            "                    \t     Validation Accuracy : 0.7786245098039216\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.46232763071083327\n",
            "                    \t     Validation Loss : 0.4613467439620399\n",
            "                    \t     Training Accuracy : 0.778743932038835\n",
            "                    \t     Validation Accuracy : 0.778864077669903\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.461489375878412\n",
            "                    \t     Validation Loss : 0.46096377540860417\n",
            "                    \t     Training Accuracy : 0.77921875\n",
            "                    \t     Validation Accuracy : 0.7791403846153846\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4605591711543855\n",
            "                    \t     Validation Loss : 0.4606185983789941\n",
            "                    \t     Training Accuracy : 0.7797440476190476\n",
            "                    \t     Validation Accuracy : 0.7793847619047619\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4599682561856396\n",
            "                    \t     Validation Loss : 0.46021935266806785\n",
            "                    \t     Training Accuracy : 0.7800707547169812\n",
            "                    \t     Validation Accuracy : 0.77965\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45953324476692164\n",
            "                    \t     Validation Loss : 0.4598325606731305\n",
            "                    \t     Training Accuracy : 0.7802978971962616\n",
            "                    \t     Validation Accuracy : 0.7799158878504673\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45876508789205994\n",
            "                    \t     Validation Loss : 0.45954147941016216\n",
            "                    \t     Training Accuracy : 0.7808043981481482\n",
            "                    \t     Validation Accuracy : 0.7801435185185185\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4581873475548324\n",
            "                    \t     Validation Loss : 0.4593009339441262\n",
            "                    \t     Training Accuracy : 0.7812155963302753\n",
            "                    \t     Validation Accuracy : 0.7803091743119266\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45739780629764903\n",
            "                    \t     Validation Loss : 0.45895827935898753\n",
            "                    \t     Training Accuracy : 0.7817443181818182\n",
            "                    \t     Validation Accuracy : 0.7805372727272727\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45692637151157534\n",
            "                    \t     Validation Loss : 0.4586101187881958\n",
            "                    \t     Training Accuracy : 0.7820157657657658\n",
            "                    \t     Validation Accuracy : 0.7807702702702702\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4563327620657427\n",
            "                    \t     Validation Loss : 0.4582509226822441\n",
            "                    \t     Training Accuracy : 0.7823325892857143\n",
            "                    \t     Validation Accuracy : 0.7810071428571429\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45577826461169574\n",
            "                    \t     Validation Loss : 0.45797112682320434\n",
            "                    \t     Training Accuracy : 0.7828097345132743\n",
            "                    \t     Validation Accuracy : 0.7811849557522124\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45518295047314544\n",
            "                    \t     Validation Loss : 0.45765852787969935\n",
            "                    \t     Training Accuracy : 0.7831140350877193\n",
            "                    \t     Validation Accuracy : 0.781388596491228\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4545773882321689\n",
            "                    \t     Validation Loss : 0.4574772786690073\n",
            "                    \t     Training Accuracy : 0.783375\n",
            "                    \t     Validation Accuracy : 0.7815669565217391\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4538586660063472\n",
            "                    \t     Validation Loss : 0.45730495888079475\n",
            "                    \t     Training Accuracy : 0.783895474137931\n",
            "                    \t     Validation Accuracy : 0.7816939655172414\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4533084930772455\n",
            "                    \t     Validation Loss : 0.45697106618504074\n",
            "                    \t     Training Accuracy : 0.7843002136752136\n",
            "                    \t     Validation Accuracy : 0.7819017094017094\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45273057617373386\n",
            "                    \t     Validation Loss : 0.4566331536373385\n",
            "                    \t     Training Accuracy : 0.7847033898305085\n",
            "                    \t     Validation Accuracy : 0.7821076271186441\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4520212826333126\n",
            "                    \t     Validation Loss : 0.45633685428251225\n",
            "                    \t     Training Accuracy : 0.7851838235294117\n",
            "                    \t     Validation Accuracy : 0.7822848739495798\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.45156533900648355\n",
            "                    \t     Validation Loss : 0.4560594556077569\n",
            "                    \t     Training Accuracy : 0.7854895833333333\n",
            "                    \t     Validation Accuracy : 0.7824633333333333\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4510316107933186\n",
            "                    \t     Validation Loss : 0.45574692080211837\n",
            "                    \t     Training Accuracy : 0.7858367768595041\n",
            "                    \t     Validation Accuracy : 0.7826603305785124\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4504831470207113\n",
            "                    \t     Validation Loss : 0.45548035052183483\n",
            "                    \t     Training Accuracy : 0.786173155737705\n",
            "                    \t     Validation Accuracy : 0.7828040983606558\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.449976959260014\n",
            "                    \t     Validation Loss : 0.4551436812972127\n",
            "                    \t     Training Accuracy : 0.7864939024390244\n",
            "                    \t     Validation Accuracy : 0.7830170731707317\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4493060049871283\n",
            "                    \t     Validation Loss : 0.45492473539142747\n",
            "                    \t     Training Accuracy : 0.7868649193548387\n",
            "                    \t     Validation Accuracy : 0.7831943548387097\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4487465163207054\n",
            "                    \t     Validation Loss : 0.4546974938715609\n",
            "                    \t     Training Accuracy : 0.78721\n",
            "                    \t     Validation Accuracy : 0.7833616\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44797868149621145\n",
            "                    \t     Validation Loss : 0.4544158571284177\n",
            "                    \t     Training Accuracy : 0.7875545634920635\n",
            "                    \t     Validation Accuracy : 0.7835380952380953\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.447309336216431\n",
            "                    \t     Validation Loss : 0.4541295898909515\n",
            "                    \t     Training Accuracy : 0.7879429133858268\n",
            "                    \t     Validation Accuracy : 0.7837464566929134\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4464778690435924\n",
            "                    \t     Validation Loss : 0.45400585917035896\n",
            "                    \t     Training Accuracy : 0.7884228515625\n",
            "                    \t     Validation Accuracy : 0.7838859375\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4458878918904667\n",
            "                    \t     Validation Loss : 0.4538701011009715\n",
            "                    \t     Training Accuracy : 0.7888372093023256\n",
            "                    \t     Validation Accuracy : 0.784029457364341\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44538553620301763\n",
            "                    \t     Validation Loss : 0.45369792592726166\n",
            "                    \t     Training Accuracy : 0.7891442307692308\n",
            "                    \t     Validation Accuracy : 0.7841492307692308\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4447113701610165\n",
            "                    \t     Validation Loss : 0.4534837257160552\n",
            "                    \t     Training Accuracy : 0.7895801526717557\n",
            "                    \t     Validation Accuracy : 0.7843221374045801\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44412238644605334\n",
            "                    \t     Validation Loss : 0.4532206567975048\n",
            "                    \t     Training Accuracy : 0.7899431818181818\n",
            "                    \t     Validation Accuracy : 0.7845106060606061\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44348023106056944\n",
            "                    \t     Validation Loss : 0.45295923787818326\n",
            "                    \t     Training Accuracy : 0.7903665413533835\n",
            "                    \t     Validation Accuracy : 0.7846977443609022\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4429011275541426\n",
            "                    \t     Validation Loss : 0.45268148082638837\n",
            "                    \t     Training Accuracy : 0.7907042910447761\n",
            "                    \t     Validation Accuracy : 0.784865671641791\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44232954146464665\n",
            "                    \t     Validation Loss : 0.4524001149909198\n",
            "                    \t     Training Accuracy : 0.791125\n",
            "                    \t     Validation Accuracy : 0.78504\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44167395606198734\n",
            "                    \t     Validation Loss : 0.45214042343021427\n",
            "                    \t     Training Accuracy : 0.7915211397058823\n",
            "                    \t     Validation Accuracy : 0.7852323529411764\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44112166572226225\n",
            "                    \t     Validation Loss : 0.4518769951722078\n",
            "                    \t     Training Accuracy : 0.791875\n",
            "                    \t     Validation Accuracy : 0.7854277372262773\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.44040651823515475\n",
            "                    \t     Validation Loss : 0.4517193051122259\n",
            "                    \t     Training Accuracy : 0.7922735507246377\n",
            "                    \t     Validation Accuracy : 0.7855942028985508\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.43995934509973733\n",
            "                    \t     Validation Loss : 0.45149507105547776\n",
            "                    \t     Training Accuracy : 0.7925539568345323\n",
            "                    \t     Validation Accuracy : 0.7857510791366906\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.43950890159819805\n",
            "                    \t     Validation Loss : 0.4512485963689008\n",
            "                    \t     Training Accuracy : 0.79284375\n",
            "                    \t     Validation Accuracy : 0.7859014285714285\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.43898843541847055\n",
            "                    \t     Validation Loss : 0.4509789256934303\n",
            "                    \t     Training Accuracy : 0.7931737588652482\n",
            "                    \t     Validation Accuracy : 0.7860631205673759\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.43847796404865425\n",
            "                    \t     Validation Loss : 0.4507498006783424\n",
            "                    \t     Training Accuracy : 0.7934947183098592\n",
            "                    \t     Validation Accuracy : 0.786218309859155\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.43787954182266353\n",
            "                    \t     Validation Loss : 0.4505677459335654\n",
            "                    \t     Training Accuracy : 0.7938243006993007\n",
            "                    \t     Validation Accuracy : 0.7863657342657343\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.43751582616940143\n",
            "                    \t     Validation Loss : 0.45033985724058406\n",
            "                    \t     Training Accuracy : 0.7939800347222222\n",
            "                    \t     Validation Accuracy : 0.7865270833333333\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4369951973310832\n",
            "                    \t     Validation Loss : 0.4501808359527872\n",
            "                    \t     Training Accuracy : 0.7942844827586207\n",
            "                    \t     Validation Accuracy : 0.7866496551724138\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4366045735470236\n",
            "                    \t     Validation Loss : 0.4499691217659057\n",
            "                    \t     Training Accuracy : 0.794576198630137\n",
            "                    \t     Validation Accuracy : 0.786786301369863\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4361006111555359\n",
            "                    \t     Validation Loss : 0.4497694670713571\n",
            "                    \t     Training Accuracy : 0.7949234693877552\n",
            "                    \t     Validation Accuracy : 0.786921768707483\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4355843603107575\n",
            "                    \t     Validation Loss : 0.4495765626634452\n",
            "                    \t     Training Accuracy : 0.7952195945945946\n",
            "                    \t     Validation Accuracy : 0.7870662162162162\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4350300574482687\n",
            "                    \t     Validation Loss : 0.4493610972430874\n",
            "                    \t     Training Accuracy : 0.7954865771812081\n",
            "                    \t     Validation Accuracy : 0.7872100671140939\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4346959720989068\n",
            "                    \t     Validation Loss : 0.4491542789419365\n",
            "                    \t     Training Accuracy : 0.7957125\n",
            "                    \t     Validation Accuracy : 0.7873426666666666\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4340676683483534\n",
            "                    \t     Validation Loss : 0.4490605172586358\n",
            "                    \t     Training Accuracy : 0.7960720198675497\n",
            "                    \t     Validation Accuracy : 0.7874596026490066\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.43340363540539617\n",
            "                    \t     Validation Loss : 0.44889155459219576\n",
            "                    \t     Training Accuracy : 0.7964350328947368\n",
            "                    \t     Validation Accuracy : 0.7875828947368421\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4328725771070306\n",
            "                    \t     Validation Loss : 0.44869296968272004\n",
            "                    \t     Training Accuracy : 0.7967401960784314\n",
            "                    \t     Validation Accuracy : 0.7877281045751634\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.43221010777470353\n",
            "                    \t     Validation Loss : 0.44848256328117947\n",
            "                    \t     Training Accuracy : 0.7970982142857143\n",
            "                    \t     Validation Accuracy : 0.7878824675324675\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4315662067859404\n",
            "                    \t     Validation Loss : 0.44826074784979997\n",
            "                    \t     Training Accuracy : 0.7975\n",
            "                    \t     Validation Accuracy : 0.788043870967742\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.43102143321663905\n",
            "                    \t     Validation Loss : 0.4480721516463122\n",
            "                    \t     Training Accuracy : 0.7977764423076923\n",
            "                    \t     Validation Accuracy : 0.7881730769230769\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.43048679090609215\n",
            "                    \t     Validation Loss : 0.44797091391911326\n",
            "                    \t     Training Accuracy : 0.7980414012738853\n",
            "                    \t     Validation Accuracy : 0.7882528662420382\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.43003259986827647\n",
            "                    \t     Validation Loss : 0.44776810563954\n",
            "                    \t     Training Accuracy : 0.7983227848101265\n",
            "                    \t     Validation Accuracy : 0.7883803797468354\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.429513166387501\n",
            "                    \t     Validation Loss : 0.44758263217089495\n",
            "                    \t     Training Accuracy : 0.7986202830188679\n",
            "                    \t     Validation Accuracy : 0.7885176100628931\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4288243963178247\n",
            "                    \t     Validation Loss : 0.44746879185892097\n",
            "                    \t     Training Accuracy : 0.7990078125\n",
            "                    \t     Validation Accuracy : 0.788626875\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4283610363202806\n",
            "                    \t     Validation Loss : 0.44726915059557715\n",
            "                    \t     Training Accuracy : 0.7993245341614906\n",
            "                    \t     Validation Accuracy : 0.7887602484472049\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4277486433162365\n",
            "                    \t     Validation Loss : 0.4471096231618332\n",
            "                    \t     Training Accuracy : 0.7996604938271605\n",
            "                    \t     Validation Accuracy : 0.7889037037037037\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.42714729948826363\n",
            "                    \t     Validation Loss : 0.4471008192238387\n",
            "                    \t     Training Accuracy : 0.8000306748466258\n",
            "                    \t     Validation Accuracy : 0.7889398773006135\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.42650790826758234\n",
            "                    \t     Validation Loss : 0.44698952801068675\n",
            "                    \t     Training Accuracy : 0.8004077743902439\n",
            "                    \t     Validation Accuracy : 0.7890670731707317\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4261206495039391\n",
            "                    \t     Validation Loss : 0.44687894070231565\n",
            "                    \t     Training Accuracy : 0.8006098484848485\n",
            "                    \t     Validation Accuracy : 0.7891533333333334\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4256966178873217\n",
            "                    \t     Validation Loss : 0.4467498529826463\n",
            "                    \t     Training Accuracy : 0.8008772590361446\n",
            "                    \t     Validation Accuracy : 0.789244578313253\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.42521598235575736\n",
            "                    \t     Validation Loss : 0.44665863788513777\n",
            "                    \t     Training Accuracy : 0.801186377245509\n",
            "                    \t     Validation Accuracy : 0.7893263473053892\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.42457682575498307\n",
            "                    \t     Validation Loss : 0.446592241809595\n",
            "                    \t     Training Accuracy : 0.8015252976190477\n",
            "                    \t     Validation Accuracy : 0.7894190476190476\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4242656357806815\n",
            "                    \t     Validation Loss : 0.446413304415678\n",
            "                    \t     Training Accuracy : 0.8017381656804734\n",
            "                    \t     Validation Accuracy : 0.7895260355029586\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.42389637071420166\n",
            "                    \t     Validation Loss : 0.4462715991153638\n",
            "                    \t     Training Accuracy : 0.8019522058823529\n",
            "                    \t     Validation Accuracy : 0.7896376470588236\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4233271896176868\n",
            "                    \t     Validation Loss : 0.44613821494684663\n",
            "                    \t     Training Accuracy : 0.8022807017543859\n",
            "                    \t     Validation Accuracy : 0.7897444444444445\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.422781461063166\n",
            "                    \t     Validation Loss : 0.44599301121186224\n",
            "                    \t     Training Accuracy : 0.8026017441860465\n",
            "                    \t     Validation Accuracy : 0.7898470930232558\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.42232407305454245\n",
            "                    \t     Validation Loss : 0.44586734609923406\n",
            "                    \t     Training Accuracy : 0.8029226878612716\n",
            "                    \t     Validation Accuracy : 0.7899445086705202\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4219465471547225\n",
            "                    \t     Validation Loss : 0.44571601035962144\n",
            "                    \t     Training Accuracy : 0.803157327586207\n",
            "                    \t     Validation Accuracy : 0.7900442528735632\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.421536294235502\n",
            "                    \t     Validation Loss : 0.4455678896308761\n",
            "                    \t     Training Accuracy : 0.8034357142857143\n",
            "                    \t     Validation Accuracy : 0.7901548571428572\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4209802752902562\n",
            "                    \t     Validation Loss : 0.4454149916644186\n",
            "                    \t     Training Accuracy : 0.8037286931818182\n",
            "                    \t     Validation Accuracy : 0.7902625\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.42030131006644944\n",
            "                    \t     Validation Loss : 0.4453382692463602\n",
            "                    \t     Training Accuracy : 0.8040854519774011\n",
            "                    \t     Validation Accuracy : 0.7903824858757063\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4196144373313095\n",
            "                    \t     Validation Loss : 0.4452496667615177\n",
            "                    \t     Training Accuracy : 0.8045119382022472\n",
            "                    \t     Validation Accuracy : 0.7904865168539326\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41910538870695585\n",
            "                    \t     Validation Loss : 0.4451564190208817\n",
            "                    \t     Training Accuracy : 0.8048393854748603\n",
            "                    \t     Validation Accuracy : 0.790577653631285\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4185231396415167\n",
            "                    \t     Validation Loss : 0.4450636280337557\n",
            "                    \t     Training Accuracy : 0.8051631944444444\n",
            "                    \t     Validation Accuracy : 0.7906827777777777\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4178283200639388\n",
            "                    \t     Validation Loss : 0.4449779508475647\n",
            "                    \t     Training Accuracy : 0.8055524861878453\n",
            "                    \t     Validation Accuracy : 0.7907889502762431\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41731944584584496\n",
            "                    \t     Validation Loss : 0.44490417578125424\n",
            "                    \t     Training Accuracy : 0.8058585164835165\n",
            "                    \t     Validation Accuracy : 0.7908752747252747\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41673765418796593\n",
            "                    \t     Validation Loss : 0.4447743752252138\n",
            "                    \t     Training Accuracy : 0.8062602459016394\n",
            "                    \t     Validation Accuracy : 0.7909797814207651\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41619142157228095\n",
            "                    \t     Validation Loss : 0.44466264124965915\n",
            "                    \t     Training Accuracy : 0.8065353260869565\n",
            "                    \t     Validation Accuracy : 0.7911005434782609\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.415657913862048\n",
            "                    \t     Validation Loss : 0.4445635406375858\n",
            "                    \t     Training Accuracy : 0.8068277027027027\n",
            "                    \t     Validation Accuracy : 0.791172972972973\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4150465668337319\n",
            "                    \t     Validation Loss : 0.4444510491287863\n",
            "                    \t     Training Accuracy : 0.8071370967741935\n",
            "                    \t     Validation Accuracy : 0.7912935483870968\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41452703405191554\n",
            "                    \t     Validation Loss : 0.4443650735643599\n",
            "                    \t     Training Accuracy : 0.8074431818181819\n",
            "                    \t     Validation Accuracy : 0.791385026737968\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41405062345431204\n",
            "                    \t     Validation Loss : 0.44423722869327054\n",
            "                    \t     Training Accuracy : 0.8077160904255319\n",
            "                    \t     Validation Accuracy : 0.7914856382978723\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41341369684884155\n",
            "                    \t     Validation Loss : 0.44422801503677073\n",
            "                    \t     Training Accuracy : 0.8080985449735449\n",
            "                    \t     Validation Accuracy : 0.7915619047619048\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.412980878953871\n",
            "                    \t     Validation Loss : 0.44412571291450353\n",
            "                    \t     Training Accuracy : 0.8083256578947369\n",
            "                    \t     Validation Accuracy : 0.7916442105263158\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4124943036543137\n",
            "                    \t     Validation Loss : 0.4440390079488965\n",
            "                    \t     Training Accuracy : 0.8086714659685864\n",
            "                    \t     Validation Accuracy : 0.7917403141361257\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41189615878897406\n",
            "                    \t     Validation Loss : 0.44405035414602567\n",
            "                    \t     Training Accuracy : 0.8089973958333333\n",
            "                    \t     Validation Accuracy : 0.7917963541666667\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.411427189630548\n",
            "                    \t     Validation Loss : 0.44393637680802056\n",
            "                    \t     Training Accuracy : 0.8092551813471502\n",
            "                    \t     Validation Accuracy : 0.7918927461139896\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.41099959004094305\n",
            "                    \t     Validation Loss : 0.4438321786756849\n",
            "                    \t     Training Accuracy : 0.8095328608247423\n",
            "                    \t     Validation Accuracy : 0.7919886597938144\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4105432598246978\n",
            "                    \t     Validation Loss : 0.44372467636131896\n",
            "                    \t     Training Accuracy : 0.8098141025641026\n",
            "                    \t     Validation Accuracy : 0.7920728205128205\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4101567487715154\n",
            "                    \t     Validation Loss : 0.44361549442711834\n",
            "                    \t     Training Accuracy : 0.810031887755102\n",
            "                    \t     Validation Accuracy : 0.7921382653061224\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.40986729019865165\n",
            "                    \t     Validation Loss : 0.4435360279821203\n",
            "                    \t     Training Accuracy : 0.8102220812182741\n",
            "                    \t     Validation Accuracy : 0.7922289340101523\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.40932832489034743\n",
            "                    \t     Validation Loss : 0.4434387502282897\n",
            "                    \t     Training Accuracy : 0.8105460858585859\n",
            "                    \t     Validation Accuracy : 0.7923308080808081\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.4088448401162373\n",
            "                    \t     Validation Loss : 0.4433441883496438\n",
            "                    \t     Training Accuracy : 0.8108071608040202\n",
            "                    \t     Validation Accuracy : 0.7924211055276382\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.40847321993708613\n",
            "                    \t     Validation Loss : 0.44323076552750107\n",
            "                    \t     Training Accuracy : 0.8110375\n",
            "                    \t     Validation Accuracy : 0.7924945\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.40779565526997275\n",
            "                    \t     Validation Loss : 0.4431673967594849\n",
            "                    \t     Training Accuracy : 0.8114303482587064\n",
            "                    \t     Validation Accuracy : 0.7926004975124378\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.407099698942044\n",
            "                    \t     Validation Loss : 0.4431410937085151\n",
            "                    \t     Training Accuracy : 0.8118316831683169\n",
            "                    \t     Validation Accuracy : 0.7927024752475248\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4064873034547409\n",
            "                    \t     Validation Loss : 0.44312948683943776\n",
            "                    \t     Training Accuracy : 0.8121366995073892\n",
            "                    \t     Validation Accuracy : 0.7927778325123153\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4058172256287699\n",
            "                    \t     Validation Loss : 0.4430958537899099\n",
            "                    \t     Training Accuracy : 0.8125030637254902\n",
            "                    \t     Validation Accuracy : 0.7928588235294117\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.40527341849556786\n",
            "                    \t     Validation Loss : 0.44302032370708705\n",
            "                    \t     Training Accuracy : 0.8128384146341463\n",
            "                    \t     Validation Accuracy : 0.792940487804878\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4046206470716347\n",
            "                    \t     Validation Loss : 0.4430198161558166\n",
            "                    \t     Training Accuracy : 0.8131796116504855\n",
            "                    \t     Validation Accuracy : 0.7930145631067961\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.40398258525032354\n",
            "                    \t     Validation Loss : 0.44298498604070446\n",
            "                    \t     Training Accuracy : 0.8134993961352657\n",
            "                    \t     Validation Accuracy : 0.7931\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4035032953859235\n",
            "                    \t     Validation Loss : 0.4429616484045799\n",
            "                    \t     Training Accuracy : 0.8137560096153846\n",
            "                    \t     Validation Accuracy : 0.7931663461538462\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4030939845655238\n",
            "                    \t     Validation Loss : 0.4428512680153925\n",
            "                    \t     Training Accuracy : 0.8140071770334928\n",
            "                    \t     Validation Accuracy : 0.7932454545454546\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.40253690017192134\n",
            "                    \t     Validation Loss : 0.44280408505374724\n",
            "                    \t     Training Accuracy : 0.8142857142857143\n",
            "                    \t     Validation Accuracy : 0.7933361904761905\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.40204256266638\n",
            "                    \t     Validation Loss : 0.44271215199751823\n",
            "                    \t     Training Accuracy : 0.8145616113744076\n",
            "                    \t     Validation Accuracy : 0.7934218009478673\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4014907897376227\n",
            "                    \t     Validation Loss : 0.4426652365530031\n",
            "                    \t     Training Accuracy : 0.8148820754716981\n",
            "                    \t     Validation Accuracy : 0.7934834905660377\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.400996028408758\n",
            "                    \t     Validation Loss : 0.44259407466061823\n",
            "                    \t     Training Accuracy : 0.815143779342723\n",
            "                    \t     Validation Accuracy : 0.7935478873239437\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.40052100867729323\n",
            "                    \t     Validation Loss : 0.44257016747283157\n",
            "                    \t     Training Accuracy : 0.8154147196261682\n",
            "                    \t     Validation Accuracy : 0.793627570093458\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.4000548404579939\n",
            "                    \t     Validation Loss : 0.44251027065886633\n",
            "                    \t     Training Accuracy : 0.8156802325581395\n",
            "                    \t     Validation Accuracy : 0.7936911627906976\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3996060724818596\n",
            "                    \t     Validation Loss : 0.44245639380416707\n",
            "                    \t     Training Accuracy : 0.8159664351851852\n",
            "                    \t     Validation Accuracy : 0.7937583333333333\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3992401168450782\n",
            "                    \t     Validation Loss : 0.4423974659933685\n",
            "                    \t     Training Accuracy : 0.8161693548387097\n",
            "                    \t     Validation Accuracy : 0.7938078341013824\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.39874225689662157\n",
            "                    \t     Validation Loss : 0.44239321233102546\n",
            "                    \t     Training Accuracy : 0.8164850917431192\n",
            "                    \t     Validation Accuracy : 0.7938477064220183\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3981947249500719\n",
            "                    \t     Validation Loss : 0.4424034857778373\n",
            "                    \t     Training Accuracy : 0.8168036529680365\n",
            "                    \t     Validation Accuracy : 0.7939073059360731\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.39765005172653634\n",
            "                    \t     Validation Loss : 0.4423601652493129\n",
            "                    \t     Training Accuracy : 0.8170795454545454\n",
            "                    \t     Validation Accuracy : 0.7939631818181818\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3971758133530347\n",
            "                    \t     Validation Loss : 0.4423457547080244\n",
            "                    \t     Training Accuracy : 0.8173331447963801\n",
            "                    \t     Validation Accuracy : 0.7940316742081448\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.39661425028902453\n",
            "                    \t     Validation Loss : 0.44234367238830363\n",
            "                    \t     Training Accuracy : 0.8176379504504504\n",
            "                    \t     Validation Accuracy : 0.7941018018018018\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3961324433013463\n",
            "                    \t     Validation Loss : 0.4425865885220783\n",
            "                    \t     Training Accuracy : 0.8178979820627803\n",
            "                    \t     Validation Accuracy : 0.7940417040358745\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3957060335869236\n",
            "                    \t     Validation Loss : 0.44256674927786427\n",
            "                    \t     Training Accuracy : 0.8181277901785714\n",
            "                    \t     Validation Accuracy : 0.7941111607142857\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.39519628691805736\n",
            "                    \t     Validation Loss : 0.44256337470372686\n",
            "                    \t     Training Accuracy : 0.8184027777777778\n",
            "                    \t     Validation Accuracy : 0.794176\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.39456265947987545\n",
            "                    \t     Validation Loss : 0.4425514488932019\n",
            "                    \t     Training Accuracy : 0.8187610619469027\n",
            "                    \t     Validation Accuracy : 0.7942460176991151\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.39385218869221894\n",
            "                    \t     Validation Loss : 0.44262752909427694\n",
            "                    \t     Training Accuracy : 0.8191161894273128\n",
            "                    \t     Validation Accuracy : 0.7942929515418502\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3932588007837011\n",
            "                    \t     Validation Loss : 0.44268125345856646\n",
            "                    \t     Training Accuracy : 0.8194161184210527\n",
            "                    \t     Validation Accuracy : 0.7943429824561403\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3926656860477539\n",
            "                    \t     Validation Loss : 0.44276237268569585\n",
            "                    \t     Training Accuracy : 0.8197352620087336\n",
            "                    \t     Validation Accuracy : 0.7943899563318777\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.39206751411570157\n",
            "                    \t     Validation Loss : 0.4428435547329855\n",
            "                    \t     Training Accuracy : 0.820046195652174\n",
            "                    \t     Validation Accuracy : 0.7944395652173913\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.39145254329169465\n",
            "                    \t     Validation Loss : 0.442878233043932\n",
            "                    \t     Training Accuracy : 0.8203896103896103\n",
            "                    \t     Validation Accuracy : 0.7944965367965368\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.39081643611770767\n",
            "                    \t     Validation Loss : 0.4429833364080019\n",
            "                    \t     Training Accuracy : 0.8207112068965517\n",
            "                    \t     Validation Accuracy : 0.7945469827586207\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3902524854914313\n",
            "                    \t     Validation Loss : 0.4429763633943305\n",
            "                    \t     Training Accuracy : 0.8210085836909872\n",
            "                    \t     Validation Accuracy : 0.794587982832618\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3896693298437147\n",
            "                    \t     Validation Loss : 0.443017056648486\n",
            "                    \t     Training Accuracy : 0.8212820512820512\n",
            "                    \t     Validation Accuracy : 0.7946341880341881\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38910548720778304\n",
            "                    \t     Validation Loss : 0.4430086418884015\n",
            "                    \t     Training Accuracy : 0.8216010638297873\n",
            "                    \t     Validation Accuracy : 0.7946970212765957\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3886413333489228\n",
            "                    \t     Validation Loss : 0.44300797216244425\n",
            "                    \t     Training Accuracy : 0.821875\n",
            "                    \t     Validation Accuracy : 0.7947381355932204\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38798261606366324\n",
            "                    \t     Validation Loss : 0.44314655306133377\n",
            "                    \t     Training Accuracy : 0.8222310126582278\n",
            "                    \t     Validation Accuracy : 0.7948071729957806\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38744309061840804\n",
            "                    \t     Validation Loss : 0.4431994146997648\n",
            "                    \t     Training Accuracy : 0.8225236344537815\n",
            "                    \t     Validation Accuracy : 0.7948621848739496\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38685045828754433\n",
            "                    \t     Validation Loss : 0.44328011121304417\n",
            "                    \t     Training Accuracy : 0.8228556485355648\n",
            "                    \t     Validation Accuracy : 0.7949225941422594\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38636808096741637\n",
            "                    \t     Validation Loss : 0.44335018557489425\n",
            "                    \t     Training Accuracy : 0.8230651041666667\n",
            "                    \t     Validation Accuracy : 0.7949608333333333\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3858214282266085\n",
            "                    \t     Validation Loss : 0.44340532302003854\n",
            "                    \t     Training Accuracy : 0.8233609958506224\n",
            "                    \t     Validation Accuracy : 0.7950045643153527\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38530370109522144\n",
            "                    \t     Validation Loss : 0.4434847688712619\n",
            "                    \t     Training Accuracy : 0.8236621900826446\n",
            "                    \t     Validation Accuracy : 0.7950409090909091\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3848240447945801\n",
            "                    \t     Validation Loss : 0.44371547916590065\n",
            "                    \t     Training Accuracy : 0.8239274691358025\n",
            "                    \t     Validation Accuracy : 0.7950275720164609\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38441923152411084\n",
            "                    \t     Validation Loss : 0.44369245562137566\n",
            "                    \t     Training Accuracy : 0.8241675204918033\n",
            "                    \t     Validation Accuracy : 0.7950827868852459\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38390843592067153\n",
            "                    \t     Validation Loss : 0.4436859719281815\n",
            "                    \t     Training Accuracy : 0.8244566326530612\n",
            "                    \t     Validation Accuracy : 0.7951432653061224\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38340829219457095\n",
            "                    \t     Validation Loss : 0.4437331552861458\n",
            "                    \t     Training Accuracy : 0.8247052845528455\n",
            "                    \t     Validation Accuracy : 0.7952052845528456\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.382848594517481\n",
            "                    \t     Validation Loss : 0.4437451939195041\n",
            "                    \t     Training Accuracy : 0.8250126518218623\n",
            "                    \t     Validation Accuracy : 0.7952595141700405\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38244283326090345\n",
            "                    \t     Validation Loss : 0.44378732753806044\n",
            "                    \t     Training Accuracy : 0.8252142137096774\n",
            "                    \t     Validation Accuracy : 0.7952987903225807\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38202244301397636\n",
            "                    \t     Validation Loss : 0.4438423427171691\n",
            "                    \t     Training Accuracy : 0.8254367469879518\n",
            "                    \t     Validation Accuracy : 0.7953421686746988\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.38148914444744586\n",
            "                    \t     Validation Loss : 0.4438905682647571\n",
            "                    \t     Training Accuracy : 0.8257225\n",
            "                    \t     Validation Accuracy : 0.7953864\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3808058988412775\n",
            "                    \t     Validation Loss : 0.44401798681819343\n",
            "                    \t     Training Accuracy : 0.8260557768924303\n",
            "                    \t     Validation Accuracy : 0.7954386454183267\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.38023778737537445\n",
            "                    \t     Validation Loss : 0.44405944468860176\n",
            "                    \t     Training Accuracy : 0.8263343253968254\n",
            "                    \t     Validation Accuracy : 0.7954912698412698\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3795408810845948\n",
            "                    \t     Validation Loss : 0.44418816500591995\n",
            "                    \t     Training Accuracy : 0.8266872529644269\n",
            "                    \t     Validation Accuracy : 0.7955462450592885\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3789943459917476\n",
            "                    \t     Validation Loss : 0.44429755803121807\n",
            "                    \t     Training Accuracy : 0.8269881889763779\n",
            "                    \t     Validation Accuracy : 0.7955917322834646\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3783322743387783\n",
            "                    \t     Validation Loss : 0.44452583345973773\n",
            "                    \t     Training Accuracy : 0.8273431372549019\n",
            "                    \t     Validation Accuracy : 0.7956133333333333\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3777618897985667\n",
            "                    \t     Validation Loss : 0.4446592056482566\n",
            "                    \t     Training Accuracy : 0.82766845703125\n",
            "                    \t     Validation Accuracy : 0.7956359375\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37708980863022434\n",
            "                    \t     Validation Loss : 0.444875153216534\n",
            "                    \t     Training Accuracy : 0.827988813229572\n",
            "                    \t     Validation Accuracy : 0.7956626459143968\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3765739924114111\n",
            "                    \t     Validation Loss : 0.4449916350828642\n",
            "                    \t     Training Accuracy : 0.8282679263565892\n",
            "                    \t     Validation Accuracy : 0.7957046511627907\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3760400854465354\n",
            "                    \t     Validation Loss : 0.44509184537690605\n",
            "                    \t     Training Accuracy : 0.8285472972972973\n",
            "                    \t     Validation Accuracy : 0.7957432432432432\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37538449545605823\n",
            "                    \t     Validation Loss : 0.4452817585657111\n",
            "                    \t     Training Accuracy : 0.8288774038461538\n",
            "                    \t     Validation Accuracy : 0.7957876923076923\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3749031527774316\n",
            "                    \t     Validation Loss : 0.4453939832046094\n",
            "                    \t     Training Accuracy : 0.8291115900383141\n",
            "                    \t     Validation Accuracy : 0.7958264367816092\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37441587155329364\n",
            "                    \t     Validation Loss : 0.4455678851267124\n",
            "                    \t     Training Accuracy : 0.8293678435114504\n",
            "                    \t     Validation Accuracy : 0.7958396946564885\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.373937087850539\n",
            "                    \t     Validation Loss : 0.44565647949635195\n",
            "                    \t     Training Accuracy : 0.8296221482889734\n",
            "                    \t     Validation Accuracy : 0.7958897338403041\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3733986638046124\n",
            "                    \t     Validation Loss : 0.44578007384878626\n",
            "                    \t     Training Accuracy : 0.8298934659090909\n",
            "                    \t     Validation Accuracy : 0.795932196969697\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3728688936627136\n",
            "                    \t     Validation Loss : 0.44586525690337114\n",
            "                    \t     Training Accuracy : 0.8301462264150944\n",
            "                    \t     Validation Accuracy : 0.7959762264150944\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37226644522321406\n",
            "                    \t     Validation Loss : 0.44603206707915133\n",
            "                    \t     Training Accuracy : 0.8304511278195489\n",
            "                    \t     Validation Accuracy : 0.7960266917293233\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37178069458974433\n",
            "                    \t     Validation Loss : 0.44611766313053985\n",
            "                    \t     Training Accuracy : 0.8307045880149813\n",
            "                    \t     Validation Accuracy : 0.7960704119850187\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37124427754431966\n",
            "                    \t     Validation Loss : 0.44624011494351823\n",
            "                    \t     Training Accuracy : 0.8310121268656716\n",
            "                    \t     Validation Accuracy : 0.7961029850746268\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.37077931015243315\n",
            "                    \t     Validation Loss : 0.4462937809233046\n",
            "                    \t     Training Accuracy : 0.83125\n",
            "                    \t     Validation Accuracy : 0.796146468401487\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3703721073104276\n",
            "                    \t     Validation Loss : 0.4463543640940927\n",
            "                    \t     Training Accuracy : 0.8314421296296296\n",
            "                    \t     Validation Accuracy : 0.7961874074074075\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3699893076915803\n",
            "                    \t     Validation Loss : 0.446357540867164\n",
            "                    \t     Training Accuracy : 0.8316120848708487\n",
            "                    \t     Validation Accuracy : 0.7962284132841329\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3695708616664085\n",
            "                    \t     Validation Loss : 0.4464107700606944\n",
            "                    \t     Training Accuracy : 0.8318267463235294\n",
            "                    \t     Validation Accuracy : 0.7962694852941177\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3691017436293455\n",
            "                    \t     Validation Loss : 0.44651601704497546\n",
            "                    \t     Training Accuracy : 0.832081043956044\n",
            "                    \t     Validation Accuracy : 0.7963014652014652\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3686322747051281\n",
            "                    \t     Validation Loss : 0.44655075878605455\n",
            "                    \t     Training Accuracy : 0.8323426094890511\n",
            "                    \t     Validation Accuracy : 0.796357299270073\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.36825670673359523\n",
            "                    \t     Validation Loss : 0.44657435337159995\n",
            "                    \t     Training Accuracy : 0.8325045454545454\n",
            "                    \t     Validation Accuracy : 0.7963901818181818\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3675982046915569\n",
            "                    \t     Validation Loss : 0.4466982405104394\n",
            "                    \t     Training Accuracy : 0.8328623188405797\n",
            "                    \t     Validation Accuracy : 0.7964340579710145\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3669686587851508\n",
            "                    \t     Validation Loss : 0.4468545879714471\n",
            "                    \t     Training Accuracy : 0.8331814079422383\n",
            "                    \t     Validation Accuracy : 0.7964685920577618\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.366297687127811\n",
            "                    \t     Validation Loss : 0.4470249511429784\n",
            "                    \t     Training Accuracy : 0.8335094424460432\n",
            "                    \t     Validation Accuracy : 0.7965086330935252\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3656412621232344\n",
            "                    \t     Validation Loss : 0.44722326533186557\n",
            "                    \t     Training Accuracy : 0.8338463261648745\n",
            "                    \t     Validation Accuracy : 0.7965344086021505\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.36497676677150387\n",
            "                    \t     Validation Loss : 0.44741693833092205\n",
            "                    \t     Training Accuracy : 0.83415625\n",
            "                    \t     Validation Accuracy : 0.7965732142857143\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3643286576365979\n",
            "                    \t     Validation Loss : 0.44763299647811466\n",
            "                    \t     Training Accuracy : 0.8344661921708185\n",
            "                    \t     Validation Accuracy : 0.7966170818505338\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3637121928501742\n",
            "                    \t     Validation Loss : 0.4479211207783201\n",
            "                    \t     Training Accuracy : 0.834780585106383\n",
            "                    \t     Validation Accuracy : 0.7966471631205674\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3631482972417935\n",
            "                    \t     Validation Loss : 0.4480910875646502\n",
            "                    \t     Training Accuracy : 0.8350507950530035\n",
            "                    \t     Validation Accuracy : 0.7966872791519435\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3625324757932357\n",
            "                    \t     Validation Loss : 0.44831095496270107\n",
            "                    \t     Training Accuracy : 0.8353719190140845\n",
            "                    \t     Validation Accuracy : 0.7967137323943662\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.36201669147924376\n",
            "                    \t     Validation Loss : 0.44844687074467937\n",
            "                    \t     Training Accuracy : 0.8356184210526316\n",
            "                    \t     Validation Accuracy : 0.7967375438596491\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3614628674689081\n",
            "                    \t     Validation Loss : 0.4485904825714616\n",
            "                    \t     Training Accuracy : 0.8359156468531469\n",
            "                    \t     Validation Accuracy : 0.7967653846153846\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3609766166356071\n",
            "                    \t     Validation Loss : 0.44875088278986536\n",
            "                    \t     Training Accuracy : 0.8361411149825784\n",
            "                    \t     Validation Accuracy : 0.7967909407665505\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.36044570218745825\n",
            "                    \t     Validation Loss : 0.4489706121554534\n",
            "                    \t     Training Accuracy : 0.8364388020833333\n",
            "                    \t     Validation Accuracy : 0.7968357638888889\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3599013682614664\n",
            "                    \t     Validation Loss : 0.449156482368538\n",
            "                    \t     Training Accuracy : 0.8366998269896194\n",
            "                    \t     Validation Accuracy : 0.7968674740484429\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.359433693230409\n",
            "                    \t     Validation Loss : 0.449395877665605\n",
            "                    \t     Training Accuracy : 0.8369547413793104\n",
            "                    \t     Validation Accuracy : 0.7969037931034483\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35892920928235933\n",
            "                    \t     Validation Loss : 0.4495815508697549\n",
            "                    \t     Training Accuracy : 0.837229381443299\n",
            "                    \t     Validation Accuracy : 0.7969536082474227\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3583836868168046\n",
            "                    \t     Validation Loss : 0.44967465705527554\n",
            "                    \t     Training Accuracy : 0.8375085616438356\n",
            "                    \t     Validation Accuracy : 0.7969941780821918\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3578282066322736\n",
            "                    \t     Validation Loss : 0.4498618459696729\n",
            "                    \t     Training Accuracy : 0.8377751706484642\n",
            "                    \t     Validation Accuracy : 0.7970194539249147\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35732288484822733\n",
            "                    \t     Validation Loss : 0.45011178937167734\n",
            "                    \t     Training Accuracy : 0.838031462585034\n",
            "                    \t     Validation Accuracy : 0.7970445578231292\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35678708955418253\n",
            "                    \t     Validation Loss : 0.45024788232513463\n",
            "                    \t     Training Accuracy : 0.8382944915254237\n",
            "                    \t     Validation Accuracy : 0.797077627118644\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35627382992464746\n",
            "                    \t     Validation Loss : 0.450481163274216\n",
            "                    \t     Training Accuracy : 0.8385388513513513\n",
            "                    \t     Validation Accuracy : 0.7971043918918919\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3557991600781679\n",
            "                    \t     Validation Loss : 0.4507373743059941\n",
            "                    \t     Training Accuracy : 0.8387436868686868\n",
            "                    \t     Validation Accuracy : 0.7971400673400674\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35529748808417544\n",
            "                    \t     Validation Loss : 0.45091993399090613\n",
            "                    \t     Training Accuracy : 0.839010067114094\n",
            "                    \t     Validation Accuracy : 0.7971620805369127\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35483167722522213\n",
            "                    \t     Validation Loss : 0.45100450017511834\n",
            "                    \t     Training Accuracy : 0.8392579431438127\n",
            "                    \t     Validation Accuracy : 0.7971916387959866\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3543400111233195\n",
            "                    \t     Validation Loss : 0.4511714164881359\n",
            "                    \t     Training Accuracy : 0.8394875\n",
            "                    \t     Validation Accuracy : 0.7972196666666667\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3537560456882283\n",
            "                    \t     Validation Loss : 0.45135360002352737\n",
            "                    \t     Training Accuracy : 0.8397757475083056\n",
            "                    \t     Validation Accuracy : 0.7972614617940199\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.35308850319081586\n",
            "                    \t     Validation Loss : 0.4515393752011363\n",
            "                    \t     Training Accuracy : 0.8401158940397351\n",
            "                    \t     Validation Accuracy : 0.7973043046357616\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3525044342956626\n",
            "                    \t     Validation Loss : 0.4517603719183732\n",
            "                    \t     Training Accuracy : 0.8404001650165016\n",
            "                    \t     Validation Accuracy : 0.7973313531353136\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3519339149810472\n",
            "                    \t     Validation Loss : 0.4520045640835392\n",
            "                    \t     Training Accuracy : 0.8406722861842105\n",
            "                    \t     Validation Accuracy : 0.797375\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3513603840698717\n",
            "                    \t     Validation Loss : 0.45223794914791804\n",
            "                    \t     Training Accuracy : 0.8409590163934426\n",
            "                    \t     Validation Accuracy : 0.7974055737704918\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.350745511398182\n",
            "                    \t     Validation Loss : 0.45249583635466534\n",
            "                    \t     Training Accuracy : 0.8412581699346405\n",
            "                    \t     Validation Accuracy : 0.7974437908496732\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.35014934377860074\n",
            "                    \t     Validation Loss : 0.4527606520898665\n",
            "                    \t     Training Accuracy : 0.8415248371335505\n",
            "                    \t     Validation Accuracy : 0.7974814332247557\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34958525565936677\n",
            "                    \t     Validation Loss : 0.45306141192565624\n",
            "                    \t     Training Accuracy : 0.8417999188311688\n",
            "                    \t     Validation Accuracy : 0.7975152597402597\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3490412813310533\n",
            "                    \t     Validation Loss : 0.45326769257125465\n",
            "                    \t     Training Accuracy : 0.8420894012944984\n",
            "                    \t     Validation Accuracy : 0.797536569579288\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3484852338268632\n",
            "                    \t     Validation Loss : 0.4535542135974706\n",
            "                    \t     Training Accuracy : 0.8423548387096774\n",
            "                    \t     Validation Accuracy : 0.7975712903225807\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3479680276581856\n",
            "                    \t     Validation Loss : 0.4537873580124857\n",
            "                    \t     Training Accuracy : 0.8426266077170418\n",
            "                    \t     Validation Accuracy : 0.7976102893890675\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3474458099274824\n",
            "                    \t     Validation Loss : 0.4539989449662954\n",
            "                    \t     Training Accuracy : 0.8428725961538461\n",
            "                    \t     Validation Accuracy : 0.7976602564102564\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3469104193540189\n",
            "                    \t     Validation Loss : 0.454246386417743\n",
            "                    \t     Training Accuracy : 0.8431389776357827\n",
            "                    \t     Validation Accuracy : 0.7976939297124601\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34638128195112206\n",
            "                    \t     Validation Loss : 0.45463630254930487\n",
            "                    \t     Training Accuracy : 0.8434195859872612\n",
            "                    \t     Validation Accuracy : 0.7977044585987261\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3458985665191024\n",
            "                    \t     Validation Loss : 0.454839287769718\n",
            "                    \t     Training Accuracy : 0.8436626984126984\n",
            "                    \t     Validation Accuracy : 0.7977349206349207\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34541823703571684\n",
            "                    \t     Validation Loss : 0.4550477915820536\n",
            "                    \t     Training Accuracy : 0.84390625\n",
            "                    \t     Validation Accuracy : 0.7977610759493671\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34493565448274843\n",
            "                    \t     Validation Loss : 0.4552172811594345\n",
            "                    \t     Training Accuracy : 0.8441522082018927\n",
            "                    \t     Validation Accuracy : 0.7977886435331231\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3444657592546874\n",
            "                    \t     Validation Loss : 0.45539694625556354\n",
            "                    \t     Training Accuracy : 0.8444064465408805\n",
            "                    \t     Validation Accuracy : 0.7978220125786164\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3439581079882654\n",
            "                    \t     Validation Loss : 0.45560121243114043\n",
            "                    \t     Training Accuracy : 0.8446649686520377\n",
            "                    \t     Validation Accuracy : 0.7978476489028213\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3434056074222317\n",
            "                    \t     Validation Loss : 0.45583855711178817\n",
            "                    \t     Training Accuracy : 0.84492578125\n",
            "                    \t     Validation Accuracy : 0.797876875\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34298817689951244\n",
            "                    \t     Validation Loss : 0.4559891587828953\n",
            "                    \t     Training Accuracy : 0.8451343457943925\n",
            "                    \t     Validation Accuracy : 0.7978934579439252\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.342515121910212\n",
            "                    \t     Validation Loss : 0.4561785838392794\n",
            "                    \t     Training Accuracy : 0.8453881987577639\n",
            "                    \t     Validation Accuracy : 0.7979130434782609\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34206899287565484\n",
            "                    \t     Validation Loss : 0.45639078301028285\n",
            "                    \t     Training Accuracy : 0.8456037151702787\n",
            "                    \t     Validation Accuracy : 0.7979303405572755\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34161504823703\n",
            "                    \t     Validation Loss : 0.4565891546082955\n",
            "                    \t     Training Accuracy : 0.8458526234567901\n",
            "                    \t     Validation Accuracy : 0.7979583333333333\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34118845660078984\n",
            "                    \t     Validation Loss : 0.4567764369785991\n",
            "                    \t     Training Accuracy : 0.8460846153846154\n",
            "                    \t     Validation Accuracy : 0.7979886153846154\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3406318434331269\n",
            "                    \t     Validation Loss : 0.45699825429563007\n",
            "                    \t     Training Accuracy : 0.8463631134969325\n",
            "                    \t     Validation Accuracy : 0.7980042944785276\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.34008546202338163\n",
            "                    \t     Validation Loss : 0.45724824885030396\n",
            "                    \t     Training Accuracy : 0.8466112385321101\n",
            "                    \t     Validation Accuracy : 0.7980149847094801\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33950989474644655\n",
            "                    \t     Validation Loss : 0.457534691384076\n",
            "                    \t     Training Accuracy : 0.8468788109756098\n",
            "                    \t     Validation Accuracy : 0.7980368902439025\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33896966230373343\n",
            "                    \t     Validation Loss : 0.4578509255425768\n",
            "                    \t     Training Accuracy : 0.8471295592705167\n",
            "                    \t     Validation Accuracy : 0.7980617021276596\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33843518304249104\n",
            "                    \t     Validation Loss : 0.45813781251487623\n",
            "                    \t     Training Accuracy : 0.8473958333333333\n",
            "                    \t     Validation Accuracy : 0.7980830303030303\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3378716770155507\n",
            "                    \t     Validation Loss : 0.4584131633697935\n",
            "                    \t     Training Accuracy : 0.8476850453172206\n",
            "                    \t     Validation Accuracy : 0.7981018126888217\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33735424727100477\n",
            "                    \t     Validation Loss : 0.45868775346119406\n",
            "                    \t     Training Accuracy : 0.8479273343373493\n",
            "                    \t     Validation Accuracy : 0.7981183734939759\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3368257954169635\n",
            "                    \t     Validation Loss : 0.45902934167062864\n",
            "                    \t     Training Accuracy : 0.8481925675675676\n",
            "                    \t     Validation Accuracy : 0.7981303303303303\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33624724038826403\n",
            "                    \t     Validation Loss : 0.45928320096239567\n",
            "                    \t     Training Accuracy : 0.8484824101796408\n",
            "                    \t     Validation Accuracy : 0.7981610778443113\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33570521748699805\n",
            "                    \t     Validation Loss : 0.4595550133415879\n",
            "                    \t     Training Accuracy : 0.8487369402985074\n",
            "                    \t     Validation Accuracy : 0.7981892537313433\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3351963404815511\n",
            "                    \t     Validation Loss : 0.4598365032748714\n",
            "                    \t     Training Accuracy : 0.8489806547619048\n",
            "                    \t     Validation Accuracy : 0.7982145833333333\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3346721122587426\n",
            "                    \t     Validation Loss : 0.4601454080570056\n",
            "                    \t     Training Accuracy : 0.8492229228486647\n",
            "                    \t     Validation Accuracy : 0.798226706231454\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3341642506016121\n",
            "                    \t     Validation Loss : 0.46036991201395944\n",
            "                    \t     Training Accuracy : 0.849476701183432\n",
            "                    \t     Validation Accuracy : 0.7982417159763313\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3336647438311779\n",
            "                    \t     Validation Loss : 0.46062805161316983\n",
            "                    \t     Training Accuracy : 0.8497050147492625\n",
            "                    \t     Validation Accuracy : 0.7982563421828909\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33312414710256544\n",
            "                    \t     Validation Loss : 0.46095096826738174\n",
            "                    \t     Training Accuracy : 0.8499669117647058\n",
            "                    \t     Validation Accuracy : 0.7982732352941176\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3326444604336298\n",
            "                    \t     Validation Loss : 0.46127712307514\n",
            "                    \t     Training Accuracy : 0.8502071114369502\n",
            "                    \t     Validation Accuracy : 0.7982865102639296\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33212997795872345\n",
            "                    \t     Validation Loss : 0.4615350991743359\n",
            "                    \t     Training Accuracy : 0.8504440789473684\n",
            "                    \t     Validation Accuracy : 0.7983052631578947\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33164731271412906\n",
            "                    \t     Validation Loss : 0.4618143790350658\n",
            "                    \t     Training Accuracy : 0.8506705539358601\n",
            "                    \t     Validation Accuracy : 0.7983206997084548\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33124042012663774\n",
            "                    \t     Validation Loss : 0.46200443470056346\n",
            "                    \t     Training Accuracy : 0.8508811773255814\n",
            "                    \t     Validation Accuracy : 0.7983180232558139\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3307591185576242\n",
            "                    \t     Validation Loss : 0.4623044071926126\n",
            "                    \t     Training Accuracy : 0.8511159420289856\n",
            "                    \t     Validation Accuracy : 0.7983405797101449\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33030308354452165\n",
            "                    \t     Validation Loss : 0.4625551481385101\n",
            "                    \t     Training Accuracy : 0.8513511560693642\n",
            "                    \t     Validation Accuracy : 0.7983656069364162\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3298718547018014\n",
            "                    \t     Validation Loss : 0.4627894781055337\n",
            "                    \t     Training Accuracy : 0.8515543948126801\n",
            "                    \t     Validation Accuracy : 0.7983844380403459\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.32941739137958864\n",
            "                    \t     Validation Loss : 0.4630480310099356\n",
            "                    \t     Training Accuracy : 0.8517672413793104\n",
            "                    \t     Validation Accuracy : 0.7983956896551724\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3289669827090037\n",
            "                    \t     Validation Loss : 0.4632482462848633\n",
            "                    \t     Training Accuracy : 0.8519914040114613\n",
            "                    \t     Validation Accuracy : 0.7984194842406876\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3284906200792108\n",
            "                    \t     Validation Loss : 0.46346958779288255\n",
            "                    \t     Training Accuracy : 0.8522267857142857\n",
            "                    \t     Validation Accuracy : 0.7984448571428572\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32798072466653294\n",
            "                    \t     Validation Loss : 0.4637110212655587\n",
            "                    \t     Training Accuracy : 0.8524750712250713\n",
            "                    \t     Validation Accuracy : 0.7984717948717949\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3274748085219074\n",
            "                    \t     Validation Loss : 0.4639693293810762\n",
            "                    \t     Training Accuracy : 0.85271484375\n",
            "                    \t     Validation Accuracy : 0.7984875\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3269730040680079\n",
            "                    \t     Validation Loss : 0.4642769647164135\n",
            "                    \t     Training Accuracy : 0.8529621104815864\n",
            "                    \t     Validation Accuracy : 0.7984940509915014\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3264674342261617\n",
            "                    \t     Validation Loss : 0.4645785414491991\n",
            "                    \t     Training Accuracy : 0.8532044491525423\n",
            "                    \t     Validation Accuracy : 0.7985149717514124\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3259120201816336\n",
            "                    \t     Validation Loss : 0.4649032553934063\n",
            "                    \t     Training Accuracy : 0.8534718309859155\n",
            "                    \t     Validation Accuracy : 0.7985250704225352\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3253818451167932\n",
            "                    \t     Validation Loss : 0.465200071107672\n",
            "                    \t     Training Accuracy : 0.8537324438202247\n",
            "                    \t     Validation Accuracy : 0.7985477528089887\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3248555229596418\n",
            "                    \t     Validation Loss : 0.4655910468346754\n",
            "                    \t     Training Accuracy : 0.8539880952380953\n",
            "                    \t     Validation Accuracy : 0.7985672268907563\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3243019547674014\n",
            "                    \t     Validation Loss : 0.46592521519774077\n",
            "                    \t     Training Accuracy : 0.8542545391061452\n",
            "                    \t     Validation Accuracy : 0.7985815642458101\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32378088814369854\n",
            "                    \t     Validation Loss : 0.4663104346034591\n",
            "                    \t     Training Accuracy : 0.8545038300835655\n",
            "                    \t     Validation Accuracy : 0.7985883008356546\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32327404380926034\n",
            "                    \t     Validation Loss : 0.46665945254298663\n",
            "                    \t     Training Accuracy : 0.8547482638888889\n",
            "                    \t     Validation Accuracy : 0.7986133333333333\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32277048188269425\n",
            "                    \t     Validation Loss : 0.466961314630818\n",
            "                    \t     Training Accuracy : 0.855001731301939\n",
            "                    \t     Validation Accuracy : 0.7986382271468144\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32229152648503895\n",
            "                    \t     Validation Loss : 0.46724305714239267\n",
            "                    \t     Training Accuracy : 0.8552434392265194\n",
            "                    \t     Validation Accuracy : 0.7986569060773481\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3218800011804179\n",
            "                    \t     Validation Loss : 0.4675202348321302\n",
            "                    \t     Training Accuracy : 0.8554476584022038\n",
            "                    \t     Validation Accuracy : 0.798665564738292\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32146290123171\n",
            "                    \t     Validation Loss : 0.4677644514665478\n",
            "                    \t     Training Accuracy : 0.8556473214285715\n",
            "                    \t     Validation Accuracy : 0.7986722527472527\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3209251591169773\n",
            "                    \t     Validation Loss : 0.46816593114565624\n",
            "                    \t     Training Accuracy : 0.8559109589041096\n",
            "                    \t     Validation Accuracy : 0.7986931506849315\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3204343217074403\n",
            "                    \t     Validation Loss : 0.4685392959095121\n",
            "                    \t     Training Accuracy : 0.8561424180327869\n",
            "                    \t     Validation Accuracy : 0.7987131147540983\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3199658335099245\n",
            "                    \t     Validation Loss : 0.4688131115164628\n",
            "                    \t     Training Accuracy : 0.8563692098092643\n",
            "                    \t     Validation Accuracy : 0.7987288828337875\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3194523826644898\n",
            "                    \t     Validation Loss : 0.4692205014209229\n",
            "                    \t     Training Accuracy : 0.8566236413043479\n",
            "                    \t     Validation Accuracy : 0.7987320652173913\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3190251839637938\n",
            "                    \t     Validation Loss : 0.4694701254904413\n",
            "                    \t     Training Accuracy : 0.8568377371273713\n",
            "                    \t     Validation Accuracy : 0.7987338753387534\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.31858852998756276\n",
            "                    \t     Validation Loss : 0.4697702531678932\n",
            "                    \t     Training Accuracy : 0.8570658783783783\n",
            "                    \t     Validation Accuracy : 0.798737027027027\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3181010934869656\n",
            "                    \t     Validation Loss : 0.47010983633945574\n",
            "                    \t     Training Accuracy : 0.8572894204851752\n",
            "                    \t     Validation Accuracy : 0.7987528301886793\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3176111275282618\n",
            "                    \t     Validation Loss : 0.4704578666008717\n",
            "                    \t     Training Accuracy : 0.857515120967742\n",
            "                    \t     Validation Accuracy : 0.7987545698924731\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3172052987012263\n",
            "                    \t     Validation Loss : 0.4707543503855775\n",
            "                    \t     Training Accuracy : 0.8577128016085791\n",
            "                    \t     Validation Accuracy : 0.7987565683646113\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3167937577254373\n",
            "                    \t     Validation Loss : 0.47101299749670034\n",
            "                    \t     Training Accuracy : 0.857922794117647\n",
            "                    \t     Validation Accuracy : 0.7987524064171123\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3163380492297312\n",
            "                    \t     Validation Loss : 0.4712236596223709\n",
            "                    \t     Training Accuracy : 0.85814\n",
            "                    \t     Validation Accuracy : 0.7987512\n",
            "                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet"
      ],
      "metadata": {
        "id": "enZjb4b4_Uv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the paper, the best result of ResNet on validation was 0.85 but we achieved 0.80:"
      ],
      "metadata": {
        "id": "5-emHQf2m5FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('resnet')\n",
        "\n",
        "optimizer = optim.Adam([{'params': model.feature_extractor.parameters()},\n",
        "    {'params': model.conv_auto_encoder.parameters(), 'lr' : learning_rates[str(model.name)]['CAE LR']},\n",
        "    {'params': model.classifier.parameters(), 'lr' : learning_rates[str(model.name)]['LC LR']}],\n",
        "    lr=0.0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vur4jCc_dtD",
        "outputId": "80999c0c-7981-4b78-df34-a04d9d234ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.8575129628181457\n",
            "                    \t     Validation Loss : 0.8629978181074222\n",
            "                    \t     Training Accuracy : 0.536875\n",
            "                    \t     Validation Accuracy : 0.4967\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7885432541370392\n",
            "                    \t     Validation Loss : 0.7803108251323334\n",
            "                    \t     Training Accuracy : 0.546875\n",
            "                    \t     Validation Accuracy : 0.51185\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.757962236404419\n",
            "                    \t     Validation Loss : 0.7430868788014332\n",
            "                    \t     Training Accuracy : 0.5660416666666667\n",
            "                    \t     Validation Accuracy : 0.5273333333333333\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7340668308734893\n",
            "                    \t     Validation Loss : 0.7886733762658061\n",
            "                    \t     Training Accuracy : 0.578125\n",
            "                    \t     Validation Accuracy : 0.5197\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.713485981464386\n",
            "                    \t     Validation Loss : 0.7660405186228098\n",
            "                    \t     Training Accuracy : 0.59225\n",
            "                    \t     Validation Accuracy : 0.53162\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6932817900180817\n",
            "                    \t     Validation Loss : 0.7506418343994438\n",
            "                    \t     Training Accuracy : 0.6080208333333333\n",
            "                    \t     Validation Accuracy : 0.5402166666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6821406533036913\n",
            "                    \t     Validation Loss : 0.7398754484383606\n",
            "                    \t     Training Accuracy : 0.6160714285714286\n",
            "                    \t     Validation Accuracy : 0.5458428571428572\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6691202410310507\n",
            "                    \t     Validation Loss : 0.7339994212070974\n",
            "                    \t     Training Accuracy : 0.626328125\n",
            "                    \t     Validation Accuracy : 0.5529125\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6569688859913084\n",
            "                    \t     Validation Loss : 0.7192008105054747\n",
            "                    \t     Training Accuracy : 0.6361805555555555\n",
            "                    \t     Validation Accuracy : 0.5645555555555556\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.644069012761116\n",
            "                    \t     Validation Loss : 0.706754303397462\n",
            "                    \t     Training Accuracy : 0.647\n",
            "                    \t     Validation Accuracy : 0.57499\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6340276590802453\n",
            "                    \t     Validation Loss : 0.7059787070287233\n",
            "                    \t     Training Accuracy : 0.6539772727272727\n",
            "                    \t     Validation Accuracy : 0.5795181818181818\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.625604049116373\n",
            "                    \t     Validation Loss : 0.7036978934075251\n",
            "                    \t     Training Accuracy : 0.6611458333333333\n",
            "                    \t     Validation Accuracy : 0.5813166666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6155160745749106\n",
            "                    \t     Validation Loss : 0.7098251604629576\n",
            "                    \t     Training Accuracy : 0.6691826923076923\n",
            "                    \t     Validation Accuracy : 0.5844923076923076\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6089476119194712\n",
            "                    \t     Validation Loss : 0.7076808841927091\n",
            "                    \t     Training Accuracy : 0.6733482142857142\n",
            "                    \t     Validation Accuracy : 0.5877785714285715\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6025430572032928\n",
            "                    \t     Validation Loss : 0.7048973581090141\n",
            "                    \t     Training Accuracy : 0.6775833333333333\n",
            "                    \t     Validation Accuracy : 0.5919266666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.594176795296371\n",
            "                    \t     Validation Loss : 0.7004558624991308\n",
            "                    \t     Training Accuracy : 0.683828125\n",
            "                    \t     Validation Accuracy : 0.59835\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5875924066936269\n",
            "                    \t     Validation Loss : 0.6972305488819422\n",
            "                    \t     Training Accuracy : 0.68875\n",
            "                    \t     Validation Accuracy : 0.6013411764705883\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5836560443043709\n",
            "                    \t     Validation Loss : 0.6994654999098373\n",
            "                    \t     Training Accuracy : 0.6918402777777778\n",
            "                    \t     Validation Accuracy : 0.6017166666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5774139176544391\n",
            "                    \t     Validation Loss : 0.6919270841458354\n",
            "                    \t     Training Accuracy : 0.6966447368421053\n",
            "                    \t     Validation Accuracy : 0.6084105263157895\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5717735269069671\n",
            "                    \t     Validation Loss : 0.6826954280273221\n",
            "                    \t     Training Accuracy : 0.701\n",
            "                    \t     Validation Accuracy : 0.61596\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5664596114697911\n",
            "                    \t     Validation Loss : 0.6851928881336234\n",
            "                    \t     Training Accuracy : 0.7049702380952381\n",
            "                    \t     Validation Accuracy : 0.6161142857142857\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5624644477123564\n",
            "                    \t     Validation Loss : 0.6763250773992783\n",
            "                    \t     Training Accuracy : 0.7081818181818181\n",
            "                    \t     Validation Accuracy : 0.6226181818181818\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5586710158508756\n",
            "                    \t     Validation Loss : 0.6747764510311242\n",
            "                    \t     Training Accuracy : 0.711195652173913\n",
            "                    \t     Validation Accuracy : 0.6251652173913044\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5544927638644973\n",
            "                    \t     Validation Loss : 0.6702340428734296\n",
            "                    \t     Training Accuracy : 0.7140364583333333\n",
            "                    \t     Validation Accuracy : 0.6295458333333334\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5509052720427513\n",
            "                    \t     Validation Loss : 0.6639369248924926\n",
            "                    \t     Training Accuracy : 0.716425\n",
            "                    \t     Validation Accuracy : 0.634532\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5466053171914358\n",
            "                    \t     Validation Loss : 0.6578061307390658\n",
            "                    \t     Training Accuracy : 0.7193509615384616\n",
            "                    \t     Validation Accuracy : 0.6396076923076923\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5429616212734469\n",
            "                    \t     Validation Loss : 0.6510665189012411\n",
            "                    \t     Training Accuracy : 0.7222222222222222\n",
            "                    \t     Validation Accuracy : 0.644762962962963\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5404487169959715\n",
            "                    \t     Validation Loss : 0.6447608965287085\n",
            "                    \t     Training Accuracy : 0.7240178571428572\n",
            "                    \t     Validation Accuracy : 0.6492821428571428\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5372942280461048\n",
            "                    \t     Validation Loss : 0.6387674157707074\n",
            "                    \t     Training Accuracy : 0.7259051724137932\n",
            "                    \t     Validation Accuracy : 0.6538793103448276\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5340673886537551\n",
            "                    \t     Validation Loss : 0.6332934810838506\n",
            "                    \t     Training Accuracy : 0.728\n",
            "                    \t     Validation Accuracy : 0.65802\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5304830118725377\n",
            "                    \t     Validation Loss : 0.630021319710126\n",
            "                    \t     Training Accuracy : 0.7305040322580645\n",
            "                    \t     Validation Accuracy : 0.6614064516129032\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5278359351865948\n",
            "                    \t     Validation Loss : 0.6267844790298218\n",
            "                    \t     Training Accuracy : 0.7326171875\n",
            "                    \t     Validation Accuracy : 0.664075\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5249767725214813\n",
            "                    \t     Validation Loss : 0.6250474408178042\n",
            "                    \t     Training Accuracy : 0.7344318181818181\n",
            "                    \t     Validation Accuracy : 0.6663121212121212\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5221921403969035\n",
            "                    \t     Validation Loss : 0.6213619082779661\n",
            "                    \t     Training Accuracy : 0.7362683823529412\n",
            "                    \t     Validation Accuracy : 0.6691470588235294\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5193643019114221\n",
            "                    \t     Validation Loss : 0.6220728992110025\n",
            "                    \t     Training Accuracy : 0.7380535714285714\n",
            "                    \t     Validation Accuracy : 0.6701142857142857\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5167897917909755\n",
            "                    \t     Validation Loss : 0.6186516769865134\n",
            "                    \t     Training Accuracy : 0.7400520833333334\n",
            "                    \t     Validation Accuracy : 0.6726472222222222\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5143919831594905\n",
            "                    \t     Validation Loss : 0.614410770774742\n",
            "                    \t     Training Accuracy : 0.7416722972972973\n",
            "                    \t     Validation Accuracy : 0.6756567567567567\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5115217603037232\n",
            "                    \t     Validation Loss : 0.611486700199493\n",
            "                    \t     Training Accuracy : 0.7437828947368421\n",
            "                    \t     Validation Accuracy : 0.6780552631578948\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5089025162504269\n",
            "                    \t     Validation Loss : 0.6076352403313715\n",
            "                    \t     Training Accuracy : 0.7454487179487179\n",
            "                    \t     Validation Accuracy : 0.6807230769230769\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5067943161875009\n",
            "                    \t     Validation Loss : 0.6037096871973607\n",
            "                    \t     Training Accuracy : 0.74675\n",
            "                    \t     Validation Accuracy : 0.6834925\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.504224079992713\n",
            "                    \t     Validation Loss : 0.6005799009052543\n",
            "                    \t     Training Accuracy : 0.748719512195122\n",
            "                    \t     Validation Accuracy : 0.6859243902439024\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5024284985661507\n",
            "                    \t     Validation Loss : 0.5978269287731193\n",
            "                    \t     Training Accuracy : 0.7501041666666667\n",
            "                    \t     Validation Accuracy : 0.6879904761904762\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.5006721633672714\n",
            "                    \t     Validation Loss : 0.5957203524971763\n",
            "                    \t     Training Accuracy : 0.7512209302325581\n",
            "                    \t     Validation Accuracy : 0.6894860465116279\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4995128564130176\n",
            "                    \t     Validation Loss : 0.5915346046303235\n",
            "                    \t     Training Accuracy : 0.7520596590909091\n",
            "                    \t     Validation Accuracy : 0.6922840909090909\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.497743246767256\n",
            "                    \t     Validation Loss : 0.589372453901799\n",
            "                    \t     Training Accuracy : 0.7534166666666666\n",
            "                    \t     Validation Accuracy : 0.69402\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.49643951461366986\n",
            "                    \t     Validation Loss : 0.5861873884100205\n",
            "                    \t     Training Accuracy : 0.7545380434782609\n",
            "                    \t     Validation Accuracy : 0.6961695652173913\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4947389132672168\n",
            "                    \t     Validation Loss : 0.584651504498223\n",
            "                    \t     Training Accuracy : 0.7557047872340426\n",
            "                    \t     Validation Accuracy : 0.6975234042553191\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.49261415102208655\n",
            "                    \t     Validation Loss : 0.5824117085363824\n",
            "                    \t     Training Accuracy : 0.7572265625\n",
            "                    \t     Validation Accuracy : 0.69925\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.49092829663534554\n",
            "                    \t     Validation Loss : 0.5791681234249898\n",
            "                    \t     Training Accuracy : 0.7583035714285714\n",
            "                    \t     Validation Accuracy : 0.7013857142857143\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.48923582649827\n",
            "                    \t     Validation Loss : 0.5767419052000243\n",
            "                    \t     Training Accuracy : 0.75945\n",
            "                    \t     Validation Accuracy : 0.70307\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4873610021203172\n",
            "                    \t     Validation Loss : 0.5769861451467012\n",
            "                    \t     Training Accuracy : 0.7606004901960784\n",
            "                    \t     Validation Accuracy : 0.7036823529411764\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.48551033379939884\n",
            "                    \t     Validation Loss : 0.5754602278733127\n",
            "                    \t     Training Accuracy : 0.7617548076923077\n",
            "                    \t     Validation Accuracy : 0.705025\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4832894919109794\n",
            "                    \t     Validation Loss : 0.5740058184356311\n",
            "                    \t     Training Accuracy : 0.7632900943396227\n",
            "                    \t     Validation Accuracy : 0.7063962264150944\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4816169565253788\n",
            "                    \t     Validation Loss : 0.5707340152836554\n",
            "                    \t     Training Accuracy : 0.7645601851851852\n",
            "                    \t     Validation Accuracy : 0.7085203703703704\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.480218611294573\n",
            "                    \t     Validation Loss : 0.5693040058436589\n",
            "                    \t     Training Accuracy : 0.7654318181818182\n",
            "                    \t     Validation Accuracy : 0.7096872727272727\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.47842998277395965\n",
            "                    \t     Validation Loss : 0.5674779381116726\n",
            "                    \t     Training Accuracy : 0.7666183035714286\n",
            "                    \t     Validation Accuracy : 0.7110357142857143\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4774751203311117\n",
            "                    \t     Validation Loss : 0.5658497841726283\n",
            "                    \t     Training Accuracy : 0.7674451754385965\n",
            "                    \t     Validation Accuracy : 0.7121157894736843\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.47640345644334264\n",
            "                    \t     Validation Loss : 0.5644035497100602\n",
            "                    \t     Training Accuracy : 0.768125\n",
            "                    \t     Validation Accuracy : 0.7132413793103448\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4749883020277751\n",
            "                    \t     Validation Loss : 0.5621667014227256\n",
            "                    \t     Training Accuracy : 0.7690466101694915\n",
            "                    \t     Validation Accuracy : 0.7148322033898306\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4736795556396246\n",
            "                    \t     Validation Loss : 0.5603558387992164\n",
            "                    \t     Training Accuracy : 0.7701458333333333\n",
            "                    \t     Validation Accuracy : 0.71612\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.47229118030579365\n",
            "                    \t     Validation Loss : 0.5578324926603161\n",
            "                    \t     Training Accuracy : 0.7711065573770491\n",
            "                    \t     Validation Accuracy : 0.7177295081967213\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.47141719054310555\n",
            "                    \t     Validation Loss : 0.5555060032409982\n",
            "                    \t     Training Accuracy : 0.7717439516129032\n",
            "                    \t     Validation Accuracy : 0.7191629032258064\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.46986584494511285\n",
            "                    \t     Validation Loss : 0.5530766368349073\n",
            "                    \t     Training Accuracy : 0.7726488095238095\n",
            "                    \t     Validation Accuracy : 0.7207428571428571\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.46856832727789877\n",
            "                    \t     Validation Loss : 0.5509394739349834\n",
            "                    \t     Training Accuracy : 0.77357421875\n",
            "                    \t     Validation Accuracy : 0.7221546875\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4673598530567609\n",
            "                    \t     Validation Loss : 0.5493609388818258\n",
            "                    \t     Training Accuracy : 0.7743942307692308\n",
            "                    \t     Validation Accuracy : 0.7233830769230769\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.46600552800478356\n",
            "                    \t     Validation Loss : 0.5471146823386622\n",
            "                    \t     Training Accuracy : 0.7752840909090909\n",
            "                    \t     Validation Accuracy : 0.72485\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4649470708708265\n",
            "                    \t     Validation Loss : 0.5448345028126531\n",
            "                    \t     Training Accuracy : 0.776035447761194\n",
            "                    \t     Validation Accuracy : 0.7262970149253731\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.46398923978647766\n",
            "                    \t     Validation Loss : 0.5436862184316217\n",
            "                    \t     Training Accuracy : 0.7766911764705883\n",
            "                    \t     Validation Accuracy : 0.7271779411764706\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4631672034099482\n",
            "                    \t     Validation Loss : 0.5419624348557393\n",
            "                    \t     Training Accuracy : 0.7772644927536232\n",
            "                    \t     Validation Accuracy : 0.7282391304347826\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4620105161922319\n",
            "                    \t     Validation Loss : 0.5405300001387234\n",
            "                    \t     Training Accuracy : 0.7781428571428571\n",
            "                    \t     Validation Accuracy : 0.7292085714285714\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.46142839789390566\n",
            "                    \t     Validation Loss : 0.5388118140438012\n",
            "                    \t     Training Accuracy : 0.7786707746478874\n",
            "                    \t     Validation Accuracy : 0.7302661971830986\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4606370972800586\n",
            "                    \t     Validation Loss : 0.5369832391421191\n",
            "                    \t     Training Accuracy : 0.7792274305555555\n",
            "                    \t     Validation Accuracy : 0.7313805555555556\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.45982317363154396\n",
            "                    \t     Validation Loss : 0.5350972809524546\n",
            "                    \t     Training Accuracy : 0.7796489726027397\n",
            "                    \t     Validation Accuracy : 0.7325219178082192\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4584984883303578\n",
            "                    \t     Validation Loss : 0.5332873341665296\n",
            "                    \t     Training Accuracy : 0.7804138513513513\n",
            "                    \t     Validation Accuracy : 0.7337351351351351\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.45716955651044844\n",
            "                    \t     Validation Loss : 0.5316412683197865\n",
            "                    \t     Training Accuracy : 0.7812166666666667\n",
            "                    \t     Validation Accuracy : 0.7348026666666667\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.45563689476761376\n",
            "                    \t     Validation Loss : 0.5303910035490914\n",
            "                    \t     Training Accuracy : 0.7822203947368421\n",
            "                    \t     Validation Accuracy : 0.7358157894736842\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.45445653925661916\n",
            "                    \t     Validation Loss : 0.529503994231627\n",
            "                    \t     Training Accuracy : 0.7830681818181818\n",
            "                    \t     Validation Accuracy : 0.736577922077922\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.45303527179627845\n",
            "                    \t     Validation Loss : 0.5286809367725024\n",
            "                    \t     Training Accuracy : 0.7838060897435898\n",
            "                    \t     Validation Accuracy : 0.7372846153846154\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.45227511212606974\n",
            "                    \t     Validation Loss : 0.5277712460469138\n",
            "                    \t     Training Accuracy : 0.7843512658227848\n",
            "                    \t     Validation Accuracy : 0.7379746835443038\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4512318213004619\n",
            "                    \t     Validation Loss : 0.5265987034086673\n",
            "                    \t     Training Accuracy : 0.7849609375\n",
            "                    \t     Validation Accuracy : 0.73886375\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4499750614810137\n",
            "                    \t     Validation Loss : 0.5255849057404368\n",
            "                    \t     Training Accuracy : 0.7857793209876544\n",
            "                    \t     Validation Accuracy : 0.7397024691358025\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4490020393325788\n",
            "                    \t     Validation Loss : 0.5243654545844484\n",
            "                    \t     Training Accuracy : 0.7863262195121952\n",
            "                    \t     Validation Accuracy : 0.7405439024390243\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.44768907968717886\n",
            "                    \t     Validation Loss : 0.5227523422158844\n",
            "                    \t     Training Accuracy : 0.7871686746987951\n",
            "                    \t     Validation Accuracy : 0.7416144578313253\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4468442852990258\n",
            "                    \t     Validation Loss : 0.5224678052432589\n",
            "                    \t     Training Accuracy : 0.7877901785714285\n",
            "                    \t     Validation Accuracy : 0.7420738095238095\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.44606251090239074\n",
            "                    \t     Validation Loss : 0.5214603195329219\n",
            "                    \t     Training Accuracy : 0.7883088235294118\n",
            "                    \t     Validation Accuracy : 0.7428247058823529\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.44551904937035813\n",
            "                    \t     Validation Loss : 0.520256383178043\n",
            "                    \t     Training Accuracy : 0.7887427325581395\n",
            "                    \t     Validation Accuracy : 0.7435651162790697\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4447835493515963\n",
            "                    \t     Validation Loss : 0.5191704328634132\n",
            "                    \t     Training Accuracy : 0.7892169540229885\n",
            "                    \t     Validation Accuracy : 0.7442977011494253\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4438199355639517\n",
            "                    \t     Validation Loss : 0.5189066316860488\n",
            "                    \t     Training Accuracy : 0.789737215909091\n",
            "                    \t     Validation Accuracy : 0.7447079545454546\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.44299585056606305\n",
            "                    \t     Validation Loss : 0.517636974615075\n",
            "                    \t     Training Accuracy : 0.790245786516854\n",
            "                    \t     Validation Accuracy : 0.7455426966292135\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.44207535392211544\n",
            "                    \t     Validation Loss : 0.5161590697785345\n",
            "                    \t     Training Accuracy : 0.7907430555555556\n",
            "                    \t     Validation Accuracy : 0.74644\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4412117714688673\n",
            "                    \t     Validation Loss : 0.5149672290753837\n",
            "                    \t     Training Accuracy : 0.7912912087912088\n",
            "                    \t     Validation Accuracy : 0.7472505494505495\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.440604838464895\n",
            "                    \t     Validation Loss : 0.513587159378518\n",
            "                    \t     Training Accuracy : 0.7917255434782609\n",
            "                    \t     Validation Accuracy : 0.7481021739130435\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4400056041713043\n",
            "                    \t     Validation Loss : 0.512982477228928\n",
            "                    \t     Training Accuracy : 0.7920698924731183\n",
            "                    \t     Validation Accuracy : 0.7485720430107526\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.43924559180565337\n",
            "                    \t     Validation Loss : 0.5116848400323909\n",
            "                    \t     Training Accuracy : 0.7925398936170213\n",
            "                    \t     Validation Accuracy : 0.7494042553191489\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4386015851858415\n",
            "                    \t     Validation Loss : 0.5105191682063372\n",
            "                    \t     Training Accuracy : 0.7929605263157895\n",
            "                    \t     Validation Accuracy : 0.7501347368421053\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4379545448611801\n",
            "                    \t     Validation Loss : 0.5091802140542121\n",
            "                    \t     Training Accuracy : 0.793359375\n",
            "                    \t     Validation Accuracy : 0.750946875\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4373687420723979\n",
            "                    \t     Validation Loss : 0.508014025395282\n",
            "                    \t     Training Accuracy : 0.7937371134020619\n",
            "                    \t     Validation Accuracy : 0.7516701030927835\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.43689395913816226\n",
            "                    \t     Validation Loss : 0.5076033827895065\n",
            "                    \t     Training Accuracy : 0.7940369897959184\n",
            "                    \t     Validation Accuracy : 0.7520234693877551\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.43618208434395117\n",
            "                    \t     Validation Loss : 0.5065888003499209\n",
            "                    \t     Training Accuracy : 0.7944381313131313\n",
            "                    \t     Validation Accuracy : 0.7526868686868687\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4357523940756917\n",
            "                    \t     Validation Loss : 0.505459345419186\n",
            "                    \t     Training Accuracy : 0.79466875\n",
            "                    \t     Validation Accuracy : 0.753374\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.435004971486212\n",
            "                    \t     Validation Loss : 0.5047068867786583\n",
            "                    \t     Training Accuracy : 0.7950495049504951\n",
            "                    \t     Validation Accuracy : 0.753929702970297\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4340290505205299\n",
            "                    \t     Validation Loss : 0.5039351220483459\n",
            "                    \t     Training Accuracy : 0.7956372549019608\n",
            "                    \t     Validation Accuracy : 0.754543137254902\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.43327739243513175\n",
            "                    \t     Validation Loss : 0.5031651855987211\n",
            "                    \t     Training Accuracy : 0.7960800970873786\n",
            "                    \t     Validation Accuracy : 0.7550757281553399\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.43256243005251654\n",
            "                    \t     Validation Loss : 0.5023621605955473\n",
            "                    \t     Training Accuracy : 0.7965204326923077\n",
            "                    \t     Validation Accuracy : 0.7556375\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.43176866671159153\n",
            "                    \t     Validation Loss : 0.5019023456759655\n",
            "                    \t     Training Accuracy : 0.7969821428571429\n",
            "                    \t     Validation Accuracy : 0.7560857142857142\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4311875445817439\n",
            "                    \t     Validation Loss : 0.5007660554528715\n",
            "                    \t     Training Accuracy : 0.7973172169811321\n",
            "                    \t     Validation Accuracy : 0.7567584905660377\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4305538497336\n",
            "                    \t     Validation Loss : 0.4996477256083185\n",
            "                    \t     Training Accuracy : 0.7976635514018692\n",
            "                    \t     Validation Accuracy : 0.7574205607476635\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42962454239941306\n",
            "                    \t     Validation Loss : 0.4986675108395364\n",
            "                    \t     Training Accuracy : 0.7982118055555556\n",
            "                    \t     Validation Accuracy : 0.7580694444444445\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4291221435750843\n",
            "                    \t     Validation Loss : 0.4976391985531579\n",
            "                    \t     Training Accuracy : 0.7984690366972477\n",
            "                    \t     Validation Accuracy : 0.7587146788990826\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4282024866220626\n",
            "                    \t     Validation Loss : 0.4970968690997565\n",
            "                    \t     Training Accuracy : 0.7990568181818182\n",
            "                    \t     Validation Accuracy : 0.7591827272727273\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.427583710106912\n",
            "                    \t     Validation Loss : 0.49618971669309875\n",
            "                    \t     Training Accuracy : 0.7993918918918919\n",
            "                    \t     Validation Accuracy : 0.7597459459459459\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42696099750564565\n",
            "                    \t     Validation Loss : 0.4952036209055063\n",
            "                    \t     Training Accuracy : 0.7997321428571429\n",
            "                    \t     Validation Accuracy : 0.7603473214285714\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4262843921160803\n",
            "                    \t     Validation Loss : 0.4942670519007365\n",
            "                    \t     Training Accuracy : 0.8001438053097345\n",
            "                    \t     Validation Accuracy : 0.7609150442477877\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42555674772644253\n",
            "                    \t     Validation Loss : 0.49366864432491975\n",
            "                    \t     Training Accuracy : 0.8005646929824561\n",
            "                    \t     Validation Accuracy : 0.7613368421052632\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42494563828214355\n",
            "                    \t     Validation Loss : 0.49263059642641455\n",
            "                    \t     Training Accuracy : 0.801\n",
            "                    \t     Validation Accuracy : 0.7619217391304348\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4246045449003577\n",
            "                    \t     Validation Loss : 0.49188967475373535\n",
            "                    \t     Training Accuracy : 0.8012715517241379\n",
            "                    \t     Validation Accuracy : 0.7623672413793103\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4240044875009957\n",
            "                    \t     Validation Loss : 0.4914242451928776\n",
            "                    \t     Training Accuracy : 0.8016452991452991\n",
            "                    \t     Validation Accuracy : 0.7626982905982906\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42333537502435303\n",
            "                    \t     Validation Loss : 0.4907015935825128\n",
            "                    \t     Training Accuracy : 0.8020444915254237\n",
            "                    \t     Validation Accuracy : 0.7631364406779662\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.422956344706922\n",
            "                    \t     Validation Loss : 0.48973269091662675\n",
            "                    \t     Training Accuracy : 0.8022899159663865\n",
            "                    \t     Validation Accuracy : 0.7636941176470589\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4223744348001977\n",
            "                    \t     Validation Loss : 0.4888170281502481\n",
            "                    \t     Training Accuracy : 0.8026666666666666\n",
            "                    \t     Validation Accuracy : 0.7642333333333333\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42183552558387605\n",
            "                    \t     Validation Loss : 0.4878433632877559\n",
            "                    \t     Training Accuracy : 0.802918388429752\n",
            "                    \t     Validation Accuracy : 0.7648380165289256\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4211329049275058\n",
            "                    \t     Validation Loss : 0.48697732229741614\n",
            "                    \t     Training Accuracy : 0.8033247950819672\n",
            "                    \t     Validation Accuracy : 0.7653885245901639\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.4203780366771105\n",
            "                    \t     Validation Loss : 0.4864974068998578\n",
            "                    \t     Training Accuracy : 0.8038313008130081\n",
            "                    \t     Validation Accuracy : 0.7657569105691057\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.42002949211986795\n",
            "                    \t     Validation Loss : 0.48564922305555963\n",
            "                    \t     Training Accuracy : 0.8040625\n",
            "                    \t     Validation Accuracy : 0.7662822580645161\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.41955003056645396\n",
            "                    \t     Validation Loss : 0.48469238516031365\n",
            "                    \t     Training Accuracy : 0.804295\n",
            "                    \t     Validation Accuracy : 0.7668408\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4188251465712748\n",
            "                    \t     Validation Loss : 0.48403195851769654\n",
            "                    \t     Training Accuracy : 0.8047123015873016\n",
            "                    \t     Validation Accuracy : 0.7673190476190476\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4180753747860747\n",
            "                    \t     Validation Loss : 0.4832978523732182\n",
            "                    \t     Training Accuracy : 0.8051328740157481\n",
            "                    \t     Validation Accuracy : 0.7678511811023622\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4173513810266741\n",
            "                    \t     Validation Loss : 0.482581771705069\n",
            "                    \t     Training Accuracy : 0.805537109375\n",
            "                    \t     Validation Accuracy : 0.7683359375\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4167243409780569\n",
            "                    \t     Validation Loss : 0.4818258521952964\n",
            "                    \t     Training Accuracy : 0.8058527131782945\n",
            "                    \t     Validation Accuracy : 0.7688302325581395\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4159878190916318\n",
            "                    \t     Validation Loss : 0.4810201407612308\n",
            "                    \t     Training Accuracy : 0.8063125\n",
            "                    \t     Validation Accuracy : 0.7693476923076923\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.41534671056816597\n",
            "                    \t     Validation Loss : 0.48022738127971637\n",
            "                    \t     Training Accuracy : 0.806655534351145\n",
            "                    \t     Validation Accuracy : 0.7697969465648855\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4146937968435161\n",
            "                    \t     Validation Loss : 0.4794165461204866\n",
            "                    \t     Training Accuracy : 0.8069744318181818\n",
            "                    \t     Validation Accuracy : 0.7702992424242424\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4140610263255754\n",
            "                    \t     Validation Loss : 0.4790985785134232\n",
            "                    \t     Training Accuracy : 0.8073637218045113\n",
            "                    \t     Validation Accuracy : 0.7705398496240602\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.41348944029590085\n",
            "                    \t     Validation Loss : 0.4785753178643962\n",
            "                    \t     Training Accuracy : 0.8076632462686567\n",
            "                    \t     Validation Accuracy : 0.7708985074626866\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4127963770329952\n",
            "                    \t     Validation Loss : 0.47787130787385\n",
            "                    \t     Training Accuracy : 0.8080787037037037\n",
            "                    \t     Validation Accuracy : 0.77136\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.41232699509162235\n",
            "                    \t     Validation Loss : 0.47714543859237196\n",
            "                    \t     Training Accuracy : 0.8084466911764706\n",
            "                    \t     Validation Accuracy : 0.7718169117647059\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4118096358660799\n",
            "                    \t     Validation Loss : 0.4763417892598141\n",
            "                    \t     Training Accuracy : 0.8087636861313868\n",
            "                    \t     Validation Accuracy : 0.7722963503649635\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4112013631054889\n",
            "                    \t     Validation Loss : 0.4755601870998186\n",
            "                    \t     Training Accuracy : 0.8091213768115942\n",
            "                    \t     Validation Accuracy : 0.7727608695652174\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4108921084461881\n",
            "                    \t     Validation Loss : 0.47479702153040815\n",
            "                    \t     Training Accuracy : 0.8093435251798561\n",
            "                    \t     Validation Accuracy : 0.7732035971223021\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4102830778243286\n",
            "                    \t     Validation Loss : 0.4742108058332309\n",
            "                    \t     Training Accuracy : 0.8096919642857143\n",
            "                    \t     Validation Accuracy : 0.7735842857142857\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.40982827586379456\n",
            "                    \t     Validation Loss : 0.4736998847712365\n",
            "                    \t     Training Accuracy : 0.8099290780141843\n",
            "                    \t     Validation Accuracy : 0.7738702127659575\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4093155375269937\n",
            "                    \t     Validation Loss : 0.47298887074654156\n",
            "                    \t     Training Accuracy : 0.8102552816901408\n",
            "                    \t     Validation Accuracy : 0.7742978873239437\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.40887909814611184\n",
            "                    \t     Validation Loss : 0.4723958881766356\n",
            "                    \t     Training Accuracy : 0.8105681818181818\n",
            "                    \t     Validation Accuracy : 0.7747006993006993\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4083127960873147\n",
            "                    \t     Validation Loss : 0.47172568996747993\n",
            "                    \t     Training Accuracy : 0.8109331597222222\n",
            "                    \t     Validation Accuracy : 0.7751284722222223\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4078677905469105\n",
            "                    \t     Validation Loss : 0.47113701398495184\n",
            "                    \t     Training Accuracy : 0.8112586206896552\n",
            "                    \t     Validation Accuracy : 0.775483448275862\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4074625163045648\n",
            "                    \t     Validation Loss : 0.47055546670961035\n",
            "                    \t     Training Accuracy : 0.8115282534246575\n",
            "                    \t     Validation Accuracy : 0.7758342465753425\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.4069124180037959\n",
            "                    \t     Validation Loss : 0.46995025324482975\n",
            "                    \t     Training Accuracy : 0.8117984693877551\n",
            "                    \t     Validation Accuracy : 0.7762394557823129\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.40647006750509546\n",
            "                    \t     Validation Loss : 0.46926807617954736\n",
            "                    \t     Training Accuracy : 0.8120608108108108\n",
            "                    \t     Validation Accuracy : 0.7766621621621622\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.40614125810413554\n",
            "                    \t     Validation Loss : 0.46860577069219894\n",
            "                    \t     Training Accuracy : 0.8122902684563759\n",
            "                    \t     Validation Accuracy : 0.777058389261745\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.40596731985608736\n",
            "                    \t     Validation Loss : 0.46823796034954224\n",
            "                    \t     Training Accuracy : 0.8123708333333334\n",
            "                    \t     Validation Accuracy : 0.7773033333333333\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4053378963509932\n",
            "                    \t     Validation Loss : 0.46772145979292284\n",
            "                    \t     Training Accuracy : 0.8126862582781457\n",
            "                    \t     Validation Accuracy : 0.7776337748344371\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.40477570505322596\n",
            "                    \t     Validation Loss : 0.467199971932277\n",
            "                    \t     Training Accuracy : 0.8130263157894737\n",
            "                    \t     Validation Accuracy : 0.7779809210526316\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4042733423947509\n",
            "                    \t     Validation Loss : 0.46654300686374073\n",
            "                    \t     Training Accuracy : 0.8133578431372549\n",
            "                    \t     Validation Accuracy : 0.7783862745098039\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4037587422267957\n",
            "                    \t     Validation Loss : 0.465914315623711\n",
            "                    \t     Training Accuracy : 0.8136323051948052\n",
            "                    \t     Validation Accuracy : 0.778775974025974\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4032398892698749\n",
            "                    \t     Validation Loss : 0.4653905186707318\n",
            "                    \t     Training Accuracy : 0.8139193548387097\n",
            "                    \t     Validation Accuracy : 0.7791167741935484\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.40277749457229406\n",
            "                    \t     Validation Loss : 0.46481423353344664\n",
            "                    \t     Training Accuracy : 0.8142588141025641\n",
            "                    \t     Validation Accuracy : 0.779476282051282\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4021363234235223\n",
            "                    \t     Validation Loss : 0.46436731595276054\n",
            "                    \t     Training Accuracy : 0.8146377388535032\n",
            "                    \t     Validation Accuracy : 0.7798082802547771\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.4015261675832392\n",
            "                    \t     Validation Loss : 0.46399484800358104\n",
            "                    \t     Training Accuracy : 0.8149525316455696\n",
            "                    \t     Validation Accuracy : 0.7800607594936709\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.40091308226937766\n",
            "                    \t     Validation Loss : 0.46344687811551094\n",
            "                    \t     Training Accuracy : 0.8153262578616353\n",
            "                    \t     Validation Accuracy : 0.7804025157232705\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.40066937206313014\n",
            "                    \t     Validation Loss : 0.462889792667196\n",
            "                    \t     Training Accuracy : 0.815453125\n",
            "                    \t     Validation Accuracy : 0.780719375\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.40030018859953614\n",
            "                    \t     Validation Loss : 0.4623563663123515\n",
            "                    \t     Training Accuracy : 0.8157104037267081\n",
            "                    \t     Validation Accuracy : 0.7810521739130435\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.39985038129635797\n",
            "                    \t     Validation Loss : 0.46197811803281535\n",
            "                    \t     Training Accuracy : 0.8159567901234568\n",
            "                    \t     Validation Accuracy : 0.781291975308642\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.399260181906216\n",
            "                    \t     Validation Loss : 0.46148538114132276\n",
            "                    \t     Training Accuracy : 0.8162653374233129\n",
            "                    \t     Validation Accuracy : 0.7815717791411043\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3988735810003993\n",
            "                    \t     Validation Loss : 0.46107617127201445\n",
            "                    \t     Training Accuracy : 0.816451981707317\n",
            "                    \t     Validation Accuracy : 0.7818371951219513\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.39834042608286396\n",
            "                    \t     Validation Loss : 0.46053672767133286\n",
            "                    \t     Training Accuracy : 0.8167878787878788\n",
            "                    \t     Validation Accuracy : 0.7821678787878787\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.39788611861147793\n",
            "                    \t     Validation Loss : 0.4602231390599593\n",
            "                    \t     Training Accuracy : 0.8170933734939759\n",
            "                    \t     Validation Accuracy : 0.7823957831325301\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3974867366664781\n",
            "                    \t     Validation Loss : 0.45979213119476803\n",
            "                    \t     Training Accuracy : 0.817372754491018\n",
            "                    \t     Validation Accuracy : 0.7826299401197605\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3970856272792887\n",
            "                    \t     Validation Loss : 0.45926743193726355\n",
            "                    \t     Training Accuracy : 0.8175967261904762\n",
            "                    \t     Validation Accuracy : 0.7829416666666666\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3965704829514732\n",
            "                    \t     Validation Loss : 0.45871989867775204\n",
            "                    \t     Training Accuracy : 0.8178735207100591\n",
            "                    \t     Validation Accuracy : 0.7832674556213017\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3959318745662184\n",
            "                    \t     Validation Loss : 0.4582293620970527\n",
            "                    \t     Training Accuracy : 0.8182205882352941\n",
            "                    \t     Validation Accuracy : 0.7835882352941177\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.39563799873255845\n",
            "                    \t     Validation Loss : 0.45772455794942035\n",
            "                    \t     Training Accuracy : 0.8184210526315789\n",
            "                    \t     Validation Accuracy : 0.7838736842105263\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3952780789180204\n",
            "                    \t     Validation Loss : 0.4573179434038861\n",
            "                    \t     Training Accuracy : 0.8185864825581395\n",
            "                    \t     Validation Accuracy : 0.7841476744186047\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3948483069309954\n",
            "                    \t     Validation Loss : 0.4570237466053002\n",
            "                    \t     Training Accuracy : 0.8188439306358382\n",
            "                    \t     Validation Accuracy : 0.7843751445086705\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3944582011927476\n",
            "                    \t     Validation Loss : 0.45661027019146516\n",
            "                    \t     Training Accuracy : 0.8190625\n",
            "                    \t     Validation Accuracy : 0.7846413793103448\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.39412788582699637\n",
            "                    \t     Validation Loss : 0.4561072274080861\n",
            "                    \t     Training Accuracy : 0.8193142857142857\n",
            "                    \t     Validation Accuracy : 0.7849462857142857\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39358474188399584\n",
            "                    \t     Validation Loss : 0.4557153777443327\n",
            "                    \t     Training Accuracy : 0.8196271306818181\n",
            "                    \t     Validation Accuracy : 0.7852232954545455\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39326326956519975\n",
            "                    \t     Validation Loss : 0.4553813531487006\n",
            "                    \t     Training Accuracy : 0.8198446327683616\n",
            "                    \t     Validation Accuracy : 0.7854610169491525\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39268400303935735\n",
            "                    \t     Validation Loss : 0.45507279535513534\n",
            "                    \t     Training Accuracy : 0.820182584269663\n",
            "                    \t     Validation Accuracy : 0.7857123595505618\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39210618775566863\n",
            "                    \t     Validation Loss : 0.4547042064415933\n",
            "                    \t     Training Accuracy : 0.8205377094972067\n",
            "                    \t     Validation Accuracy : 0.7859765363128491\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3916484050171243\n",
            "                    \t     Validation Loss : 0.454282303397267\n",
            "                    \t     Training Accuracy : 0.8208368055555556\n",
            "                    \t     Validation Accuracy : 0.7862261111111111\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39112994854127503\n",
            "                    \t     Validation Loss : 0.4543296511909708\n",
            "                    \t     Training Accuracy : 0.8211740331491713\n",
            "                    \t     Validation Accuracy : 0.7863331491712707\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39061137968612897\n",
            "                    \t     Validation Loss : 0.4540523347853453\n",
            "                    \t     Training Accuracy : 0.8214766483516484\n",
            "                    \t     Validation Accuracy : 0.7865285714285715\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.39021842391764533\n",
            "                    \t     Validation Loss : 0.4536248484417674\n",
            "                    \t     Training Accuracy : 0.821676912568306\n",
            "                    \t     Validation Accuracy : 0.7867803278688524\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38971892228269056\n",
            "                    \t     Validation Loss : 0.4532121787793911\n",
            "                    \t     Training Accuracy : 0.8219327445652174\n",
            "                    \t     Validation Accuracy : 0.787041847826087\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38929099333125194\n",
            "                    \t     Validation Loss : 0.4527323535268207\n",
            "                    \t     Training Accuracy : 0.822152027027027\n",
            "                    \t     Validation Accuracy : 0.7873297297297297\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38872794450130516\n",
            "                    \t     Validation Loss : 0.45250941378304504\n",
            "                    \t     Training Accuracy : 0.8224126344086021\n",
            "                    \t     Validation Accuracy : 0.7875446236559139\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3883943417182262\n",
            "                    \t     Validation Loss : 0.45209212932706466\n",
            "                    \t     Training Accuracy : 0.822533422459893\n",
            "                    \t     Validation Accuracy : 0.7877737967914439\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3879855397208891\n",
            "                    \t     Validation Loss : 0.4517724929434034\n",
            "                    \t     Training Accuracy : 0.8227692819148936\n",
            "                    \t     Validation Accuracy : 0.7879813829787234\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3874943230186821\n",
            "                    \t     Validation Loss : 0.45132797204544567\n",
            "                    \t     Training Accuracy : 0.8231150793650793\n",
            "                    \t     Validation Accuracy : 0.7882476190476191\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38715274160159263\n",
            "                    \t     Validation Loss : 0.45090333791150555\n",
            "                    \t     Training Accuracy : 0.8233125\n",
            "                    \t     Validation Accuracy : 0.7884926315789473\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3867384299105375\n",
            "                    \t     Validation Loss : 0.45054377062431616\n",
            "                    \t     Training Accuracy : 0.8235471204188481\n",
            "                    \t     Validation Accuracy : 0.7887261780104712\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38625068705218535\n",
            "                    \t     Validation Loss : 0.45016510290635753\n",
            "                    \t     Training Accuracy : 0.8237727864583333\n",
            "                    \t     Validation Accuracy : 0.7889979166666666\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3858473449621176\n",
            "                    \t     Validation Loss : 0.4497654410333655\n",
            "                    \t     Training Accuracy : 0.8239961139896373\n",
            "                    \t     Validation Accuracy : 0.7892476683937824\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3855685885588533\n",
            "                    \t     Validation Loss : 0.44939331165808905\n",
            "                    \t     Training Accuracy : 0.8242139175257732\n",
            "                    \t     Validation Accuracy : 0.7894670103092783\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3852235932090344\n",
            "                    \t     Validation Loss : 0.44899171756222955\n",
            "                    \t     Training Accuracy : 0.8244134615384615\n",
            "                    \t     Validation Accuracy : 0.78972\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38489777464799735\n",
            "                    \t     Validation Loss : 0.4486593775194443\n",
            "                    \t     Training Accuracy : 0.8245758928571428\n",
            "                    \t     Validation Accuracy : 0.7899127551020408\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38445723393014847\n",
            "                    \t     Validation Loss : 0.44831175508480836\n",
            "                    \t     Training Accuracy : 0.8248413705583756\n",
            "                    \t     Validation Accuracy : 0.7901253807106599\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3839247622175349\n",
            "                    \t     Validation Loss : 0.4479384475033612\n",
            "                    \t     Training Accuracy : 0.8251104797979798\n",
            "                    \t     Validation Accuracy : 0.7903782828282828\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3836115176728622\n",
            "                    \t     Validation Loss : 0.44756524419716415\n",
            "                    \t     Training Accuracy : 0.8253140703517587\n",
            "                    \t     Validation Accuracy : 0.7906020100502512\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.38330020143017174\n",
            "                    \t     Validation Loss : 0.4471606258062509\n",
            "                    \t     Training Accuracy : 0.825503125\n",
            "                    \t     Validation Accuracy : 0.7908405\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.38276378253131954\n",
            "                    \t     Validation Loss : 0.44677395585246926\n",
            "                    \t     Training Accuracy : 0.8258084577114427\n",
            "                    \t     Validation Accuracy : 0.7910920398009951\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3822846161729038\n",
            "                    \t     Validation Loss : 0.4464445737696758\n",
            "                    \t     Training Accuracy : 0.8260581683168317\n",
            "                    \t     Validation Accuracy : 0.7913029702970297\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.38178770297193176\n",
            "                    \t     Validation Loss : 0.44610530765532425\n",
            "                    \t     Training Accuracy : 0.8263485221674877\n",
            "                    \t     Validation Accuracy : 0.7915206896551724\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.38135266790714334\n",
            "                    \t     Validation Loss : 0.4458650110559814\n",
            "                    \t     Training Accuracy : 0.8265747549019608\n",
            "                    \t     Validation Accuracy : 0.7916990196078432\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3809056068433494\n",
            "                    \t     Validation Loss : 0.44570934599049045\n",
            "                    \t     Training Accuracy : 0.8267957317073171\n",
            "                    \t     Validation Accuracy : 0.7918273170731708\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3804243317108999\n",
            "                    \t     Validation Loss : 0.445470384352006\n",
            "                    \t     Training Accuracy : 0.8270813106796117\n",
            "                    \t     Validation Accuracy : 0.791971359223301\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37996949942287617\n",
            "                    \t     Validation Loss : 0.44514936509192976\n",
            "                    \t     Training Accuracy : 0.8273037439613526\n",
            "                    \t     Validation Accuracy : 0.7921545893719807\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3795518238118921\n",
            "                    \t     Validation Loss : 0.4448810522536099\n",
            "                    \t     Training Accuracy : 0.8275120192307692\n",
            "                    \t     Validation Accuracy : 0.7923221153846154\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37909390614292265\n",
            "                    \t     Validation Loss : 0.4448263890857796\n",
            "                    \t     Training Accuracy : 0.8277452153110048\n",
            "                    \t     Validation Accuracy : 0.7924511961722488\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.378665073592748\n",
            "                    \t     Validation Loss : 0.44452252681478327\n",
            "                    \t     Training Accuracy : 0.8279672619047619\n",
            "                    \t     Validation Accuracy : 0.7926604761904762\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37820347165538803\n",
            "                    \t     Validation Loss : 0.44425265907450673\n",
            "                    \t     Training Accuracy : 0.8282138625592417\n",
            "                    \t     Validation Accuracy : 0.7928535545023697\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37773052426230797\n",
            "                    \t     Validation Loss : 0.4439484383231589\n",
            "                    \t     Training Accuracy : 0.8284846698113207\n",
            "                    \t     Validation Accuracy : 0.7930570754716981\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37740597574643686\n",
            "                    \t     Validation Loss : 0.44372400530781747\n",
            "                    \t     Training Accuracy : 0.8286678403755868\n",
            "                    \t     Validation Accuracy : 0.793224882629108\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37706019775471955\n",
            "                    \t     Validation Loss : 0.44346551766325376\n",
            "                    \t     Training Accuracy : 0.8288405373831775\n",
            "                    \t     Validation Accuracy : 0.7934056074766355\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3766944429416989\n",
            "                    \t     Validation Loss : 0.4431096208348867\n",
            "                    \t     Training Accuracy : 0.8290174418604651\n",
            "                    \t     Validation Accuracy : 0.793619534883721\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3763721603927789\n",
            "                    \t     Validation Loss : 0.44277323869327767\n",
            "                    \t     Training Accuracy : 0.829146412037037\n",
            "                    \t     Validation Accuracy : 0.7938185185185185\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37586818533902344\n",
            "                    \t     Validation Loss : 0.4425478833099604\n",
            "                    \t     Training Accuracy : 0.829375\n",
            "                    \t     Validation Accuracy : 0.7940096774193548\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37544964303390693\n",
            "                    \t     Validation Loss : 0.44240477823775143\n",
            "                    \t     Training Accuracy : 0.8295584862385321\n",
            "                    \t     Validation Accuracy : 0.7941477064220184\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37500786146616827\n",
            "                    \t     Validation Loss : 0.4423739878734101\n",
            "                    \t     Training Accuracy : 0.829777397260274\n",
            "                    \t     Validation Accuracy : 0.7942114155251142\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37466265146163374\n",
            "                    \t     Validation Loss : 0.4420718291652668\n",
            "                    \t     Training Accuracy : 0.8299573863636364\n",
            "                    \t     Validation Accuracy : 0.7944068181818181\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3742288765459578\n",
            "                    \t     Validation Loss : 0.4418836767044978\n",
            "                    \t     Training Accuracy : 0.8302205882352941\n",
            "                    \t     Validation Accuracy : 0.7945547511312218\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3739832692385257\n",
            "                    \t     Validation Loss : 0.44158074744164755\n",
            "                    \t     Training Accuracy : 0.8303181306306306\n",
            "                    \t     Validation Accuracy : 0.7947297297297298\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3736136426987135\n",
            "                    \t     Validation Loss : 0.4413259398977745\n",
            "                    \t     Training Accuracy : 0.8305128923766816\n",
            "                    \t     Validation Accuracy : 0.7948784753363228\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3732574155108471\n",
            "                    \t     Validation Loss : 0.4410302554054669\n",
            "                    \t     Training Accuracy : 0.83068359375\n",
            "                    \t     Validation Accuracy : 0.7950482142857143\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.37293981228868167\n",
            "                    \t     Validation Loss : 0.44074069398586574\n",
            "                    \t     Training Accuracy : 0.8308111111111111\n",
            "                    \t     Validation Accuracy : 0.79522\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.37249226961779386\n",
            "                    \t     Validation Loss : 0.44046456031902587\n",
            "                    \t     Training Accuracy : 0.8310425884955752\n",
            "                    \t     Validation Accuracy : 0.7953942477876106\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3719745248313255\n",
            "                    \t     Validation Loss : 0.44042091020097257\n",
            "                    \t     Training Accuracy : 0.8313078193832599\n",
            "                    \t     Validation Accuracy : 0.7955167400881057\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3714540433262785\n",
            "                    \t     Validation Loss : 0.4402042785795678\n",
            "                    \t     Training Accuracy : 0.8315597587719298\n",
            "                    \t     Validation Accuracy : 0.7956741228070175\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3709906862734707\n",
            "                    \t     Validation Loss : 0.4401109279165018\n",
            "                    \t     Training Accuracy : 0.8318395196506551\n",
            "                    \t     Validation Accuracy : 0.7957960698689956\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.37046873596116253\n",
            "                    \t     Validation Loss : 0.44014162094969933\n",
            "                    \t     Training Accuracy : 0.8321114130434782\n",
            "                    \t     Validation Accuracy : 0.7958960869565217\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.37001131944132576\n",
            "                    \t     Validation Loss : 0.43996860915062436\n",
            "                    \t     Training Accuracy : 0.8323241341991342\n",
            "                    \t     Validation Accuracy : 0.7960441558441559\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3696420784557945\n",
            "                    \t     Validation Loss : 0.43978683748581576\n",
            "                    \t     Training Accuracy : 0.8325350215517241\n",
            "                    \t     Validation Accuracy : 0.796185775862069\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3691671600861099\n",
            "                    \t     Validation Loss : 0.4395621244671532\n",
            "                    \t     Training Accuracy : 0.8327655579399141\n",
            "                    \t     Validation Accuracy : 0.7963557939914163\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3689050734043121\n",
            "                    \t     Validation Loss : 0.4393453387526927\n",
            "                    \t     Training Accuracy : 0.8328792735042735\n",
            "                    \t     Validation Accuracy : 0.796492735042735\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.36846990638464056\n",
            "                    \t     Validation Loss : 0.43914701814059454\n",
            "                    \t     Training Accuracy : 0.8331010638297872\n",
            "                    \t     Validation Accuracy : 0.7966565957446808\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3681113221205897\n",
            "                    \t     Validation Loss : 0.4389402263967724\n",
            "                    \t     Training Accuracy : 0.8333183262711864\n",
            "                    \t     Validation Accuracy : 0.7968266949152543\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3677996960364062\n",
            "                    \t     Validation Loss : 0.438731909097623\n",
            "                    \t     Training Accuracy : 0.833462552742616\n",
            "                    \t     Validation Accuracy : 0.7969561181434599\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3673404382225596\n",
            "                    \t     Validation Loss : 0.43857153122596293\n",
            "                    \t     Training Accuracy : 0.8336974789915966\n",
            "                    \t     Validation Accuracy : 0.7970890756302521\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3670390437543392\n",
            "                    \t     Validation Loss : 0.4383281655177853\n",
            "                    \t     Training Accuracy : 0.8338284518828452\n",
            "                    \t     Validation Accuracy : 0.7972338912133892\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3666349111441523\n",
            "                    \t     Validation Loss : 0.4382696667561135\n",
            "                    \t     Training Accuracy : 0.8340520833333334\n",
            "                    \t     Validation Accuracy : 0.79731125\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3662598730524793\n",
            "                    \t     Validation Loss : 0.4380329888933154\n",
            "                    \t     Training Accuracy : 0.8342245850622406\n",
            "                    \t     Validation Accuracy : 0.7974639004149378\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.36590452051913935\n",
            "                    \t     Validation Loss : 0.4377876309533808\n",
            "                    \t     Training Accuracy : 0.8344240702479339\n",
            "                    \t     Validation Accuracy : 0.7976371900826447\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3655977910266492\n",
            "                    \t     Validation Loss : 0.43756473163125\n",
            "                    \t     Training Accuracy : 0.8346039094650206\n",
            "                    \t     Validation Accuracy : 0.7977798353909465\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.36526869701679615\n",
            "                    \t     Validation Loss : 0.43734180453542526\n",
            "                    \t     Training Accuracy : 0.8347489754098361\n",
            "                    \t     Validation Accuracy : 0.7979413934426229\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3648734553772576\n",
            "                    \t     Validation Loss : 0.43714317692103793\n",
            "                    \t     Training Accuracy : 0.8349719387755102\n",
            "                    \t     Validation Accuracy : 0.7980861224489796\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3644715332500334\n",
            "                    \t     Validation Loss : 0.43691973751086444\n",
            "                    \t     Training Accuracy : 0.8351651422764228\n",
            "                    \t     Validation Accuracy : 0.7982365853658536\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.36410726554420314\n",
            "                    \t     Validation Loss : 0.4368965088862601\n",
            "                    \t     Training Accuracy : 0.835371963562753\n",
            "                    \t     Validation Accuracy : 0.7982914979757085\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3637680301641024\n",
            "                    \t     Validation Loss : 0.43670687503539896\n",
            "                    \t     Training Accuracy : 0.8355594758064516\n",
            "                    \t     Validation Accuracy : 0.7984100806451613\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3634337046425266\n",
            "                    \t     Validation Loss : 0.4365065672665149\n",
            "                    \t     Training Accuracy : 0.8357078313253012\n",
            "                    \t     Validation Accuracy : 0.7985429718875502\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3631434292000532\n",
            "                    \t     Validation Loss : 0.43626920856797274\n",
            "                    \t     Training Accuracy : 0.8358725\n",
            "                    \t     Validation Accuracy : 0.7986872\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3626429156383195\n",
            "                    \t     Validation Loss : 0.4362534573019418\n",
            "                    \t     Training Accuracy : 0.8361155378486056\n",
            "                    \t     Validation Accuracy : 0.7987860557768924\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3622590690531901\n",
            "                    \t     Validation Loss : 0.43604887715859675\n",
            "                    \t     Training Accuracy : 0.8363045634920635\n",
            "                    \t     Validation Accuracy : 0.7989142857142857\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3618553800132906\n",
            "                    \t     Validation Loss : 0.4359296881565009\n",
            "                    \t     Training Accuracy : 0.8365167984189723\n",
            "                    \t     Validation Accuracy : 0.7990383399209486\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.36149154696056224\n",
            "                    \t     Validation Loss : 0.43573090555239347\n",
            "                    \t     Training Accuracy : 0.8367175196850394\n",
            "                    \t     Validation Accuracy : 0.7991685039370079\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3610337450977634\n",
            "                    \t     Validation Loss : 0.43556013545727945\n",
            "                    \t     Training Accuracy : 0.8369730392156862\n",
            "                    \t     Validation Accuracy : 0.7993109803921569\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3606371468206635\n",
            "                    \t     Validation Loss : 0.4353518761105288\n",
            "                    \t     Training Accuracy : 0.837197265625\n",
            "                    \t     Validation Accuracy : 0.799445703125\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.36021480057200106\n",
            "                    \t     Validation Loss : 0.4352484003804733\n",
            "                    \t     Training Accuracy : 0.837431906614786\n",
            "                    \t     Validation Accuracy : 0.7995439688715953\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.359804174833635\n",
            "                    \t     Validation Loss : 0.4350299904665961\n",
            "                    \t     Training Accuracy : 0.8376477713178294\n",
            "                    \t     Validation Accuracy : 0.7997\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3594324936266111\n",
            "                    \t     Validation Loss : 0.4348823126049202\n",
            "                    \t     Training Accuracy : 0.8378740347490348\n",
            "                    \t     Validation Accuracy : 0.7998324324324324\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3590457524909423\n",
            "                    \t     Validation Loss : 0.4346866818731314\n",
            "                    \t     Training Accuracy : 0.8380865384615385\n",
            "                    \t     Validation Accuracy : 0.7999588461538462\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3586806287996157\n",
            "                    \t     Validation Loss : 0.43447818757666723\n",
            "                    \t     Training Accuracy : 0.8382590996168582\n",
            "                    \t     Validation Accuracy : 0.8000942528735632\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.35835858949950633\n",
            "                    \t     Validation Loss : 0.43425211539130004\n",
            "                    \t     Training Accuracy : 0.838425572519084\n",
            "                    \t     Validation Accuracy : 0.8002370229007634\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3579935350390895\n",
            "                    \t     Validation Loss : 0.43405628846875577\n",
            "                    \t     Training Accuracy : 0.8386311787072244\n",
            "                    \t     Validation Accuracy : 0.8003604562737643\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.35761662816911033\n",
            "                    \t     Validation Loss : 0.4338441313495875\n",
            "                    \t     Training Accuracy : 0.8387997159090909\n",
            "                    \t     Validation Accuracy : 0.8004977272727273\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.35723285194500437\n",
            "                    \t     Validation Loss : 0.4337174295744023\n",
            "                    \t     Training Accuracy : 0.8389811320754716\n",
            "                    \t     Validation Accuracy : 0.8006018867924528\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3568844088553486\n",
            "                    \t     Validation Loss : 0.43356961097266966\n",
            "                    \t     Training Accuracy : 0.8391353383458646\n",
            "                    \t     Validation Accuracy : 0.8006947368421052\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3565125699614764\n",
            "                    \t     Validation Loss : 0.433457127684133\n",
            "                    \t     Training Accuracy : 0.8393398876404494\n",
            "                    \t     Validation Accuracy : 0.8007925093632959\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3562020286895446\n",
            "                    \t     Validation Loss : 0.43323405346686217\n",
            "                    \t     Training Accuracy : 0.8395032649253731\n",
            "                    \t     Validation Accuracy : 0.8009369402985075\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.355807718410811\n",
            "                    \t     Validation Loss : 0.4330552427127644\n",
            "                    \t     Training Accuracy : 0.8396816914498141\n",
            "                    \t     Validation Accuracy : 0.8010676579925651\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3555310313359455\n",
            "                    \t     Validation Loss : 0.43284248846347567\n",
            "                    \t     Training Accuracy : 0.8398287037037037\n",
            "                    \t     Validation Accuracy : 0.8011996296296297\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3551370378597416\n",
            "                    \t     Validation Loss : 0.43280473070181236\n",
            "                    \t     Training Accuracy : 0.8400438191881919\n",
            "                    \t     Validation Accuracy : 0.8013107011070111\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3547670347396942\n",
            "                    \t     Validation Loss : 0.43266252469030936\n",
            "                    \t     Training Accuracy : 0.840227481617647\n",
            "                    \t     Validation Accuracy : 0.8014349264705882\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3543835488125518\n",
            "                    \t     Validation Loss : 0.43253578093470046\n",
            "                    \t     Training Accuracy : 0.8404304029304029\n",
            "                    \t     Validation Accuracy : 0.8015538461538462\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.35404158893673526\n",
            "                    \t     Validation Loss : 0.43232374557559944\n",
            "                    \t     Training Accuracy : 0.8406158759124087\n",
            "                    \t     Validation Accuracy : 0.8016952554744525\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.3535536637839946\n",
            "                    \t     Validation Loss : 0.43227729551994\n",
            "                    \t     Training Accuracy : 0.8408522727272727\n",
            "                    \t     Validation Accuracy : 0.8018214545454545\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3529829033321121\n",
            "                    \t     Validation Loss : 0.43226612822561955\n",
            "                    \t     Training Accuracy : 0.8411413043478261\n",
            "                    \t     Validation Accuracy : 0.8019362318840579\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35253704528542845\n",
            "                    \t     Validation Loss : 0.4321283802844347\n",
            "                    \t     Training Accuracy : 0.8413537906137184\n",
            "                    \t     Validation Accuracy : 0.8020732851985559\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35208132838173734\n",
            "                    \t     Validation Loss : 0.4320201658992212\n",
            "                    \t     Training Accuracy : 0.841607464028777\n",
            "                    \t     Validation Accuracy : 0.8021856115107914\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3517104279701214\n",
            "                    \t     Validation Loss : 0.4318388324607461\n",
            "                    \t     Training Accuracy : 0.8417965949820788\n",
            "                    \t     Validation Accuracy : 0.8023200716845879\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3513540581757469\n",
            "                    \t     Validation Loss : 0.43166950440169444\n",
            "                    \t     Training Accuracy : 0.8419732142857143\n",
            "                    \t     Validation Accuracy : 0.8024503571428572\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3509811697889689\n",
            "                    \t     Validation Loss : 0.43157683926106877\n",
            "                    \t     Training Accuracy : 0.8421730427046263\n",
            "                    \t     Validation Accuracy : 0.802532384341637\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3505352373822784\n",
            "                    \t     Validation Loss : 0.4315316717832564\n",
            "                    \t     Training Accuracy : 0.8424002659574468\n",
            "                    \t     Validation Accuracy : 0.8026553191489362\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.35011639426485386\n",
            "                    \t     Validation Loss : 0.4313356204844494\n",
            "                    \t     Training Accuracy : 0.8426082155477032\n",
            "                    \t     Validation Accuracy : 0.8027844522968198\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3497030848658211\n",
            "                    \t     Validation Loss : 0.43119425450465965\n",
            "                    \t     Training Accuracy : 0.8427904929577464\n",
            "                    \t     Validation Accuracy : 0.8028823943661972\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3493524243465641\n",
            "                    \t     Validation Loss : 0.43105206266951784\n",
            "                    \t     Training Accuracy : 0.8429583333333334\n",
            "                    \t     Validation Accuracy : 0.8029961403508772\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3489605013609349\n",
            "                    \t     Validation Loss : 0.4309431736126401\n",
            "                    \t     Training Accuracy : 0.8431774475524475\n",
            "                    \t     Validation Accuracy : 0.8031125874125874\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3485596812633272\n",
            "                    \t     Validation Loss : 0.43082046772363997\n",
            "                    \t     Training Accuracy : 0.8434037456445993\n",
            "                    \t     Validation Accuracy : 0.8032080139372823\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.34818906088618357\n",
            "                    \t     Validation Loss : 0.43068900494092405\n",
            "                    \t     Training Accuracy : 0.8435828993055555\n",
            "                    \t     Validation Accuracy : 0.8033239583333334\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.34783445667075863\n",
            "                    \t     Validation Loss : 0.4305694314403486\n",
            "                    \t     Training Accuracy : 0.8437716262975778\n",
            "                    \t     Validation Accuracy : 0.8034235294117648\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3474921053992263\n",
            "                    \t     Validation Loss : 0.4305219824604917\n",
            "                    \t     Training Accuracy : 0.8439590517241379\n",
            "                    \t     Validation Accuracy : 0.8035320689655172\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.34710835680263147\n",
            "                    \t     Validation Loss : 0.43057845372975323\n",
            "                    \t     Training Accuracy : 0.8441451890034364\n",
            "                    \t     Validation Accuracy : 0.8035807560137457\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3468096026655746\n",
            "                    \t     Validation Loss : 0.4304730345920701\n",
            "                    \t     Training Accuracy : 0.8442936643835617\n",
            "                    \t     Validation Accuracy : 0.8036743150684932\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3464187341834396\n",
            "                    \t     Validation Loss : 0.43052424904604947\n",
            "                    \t     Training Accuracy : 0.8445029863481228\n",
            "                    \t     Validation Accuracy : 0.8037337883959045\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3461090240419722\n",
            "                    \t     Validation Loss : 0.43039590628817553\n",
            "                    \t     Training Accuracy : 0.8446513605442176\n",
            "                    \t     Validation Accuracy : 0.8038414965986395\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3458604712476165\n",
            "                    \t     Validation Loss : 0.4302885518291352\n",
            "                    \t     Training Accuracy : 0.8448008474576271\n",
            "                    \t     Validation Accuracy : 0.8039335593220339\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3455185113424385\n",
            "                    \t     Validation Loss : 0.4301794476145437\n",
            "                    \t     Training Accuracy : 0.8449683277027027\n",
            "                    \t     Validation Accuracy : 0.8040280405405406\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3451269385012914\n",
            "                    \t     Validation Loss : 0.4301242586384965\n",
            "                    \t     Training Accuracy : 0.8451746632996633\n",
            "                    \t     Validation Accuracy : 0.8041198653198653\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.34478387421659573\n",
            "                    \t     Validation Loss : 0.4300727142674825\n",
            "                    \t     Training Accuracy : 0.8453166946308724\n",
            "                    \t     Validation Accuracy : 0.8041869127516779\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.3444575164335029\n",
            "                    \t     Validation Loss : 0.4299271773775697\n",
            "                    \t     Training Accuracy : 0.845443143812709\n",
            "                    \t     Validation Accuracy : 0.8042882943143813\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.34416778177320956\n",
            "                    \t     Validation Loss : 0.4298185710656567\n",
            "                    \t     Training Accuracy : 0.8456\n",
            "                    \t     Validation Accuracy : 0.8043833333333333\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3437379485274668\n",
            "                    \t     Validation Loss : 0.429744252157495\n",
            "                    \t     Training Accuracy : 0.8457994186046511\n",
            "                    \t     Validation Accuracy : 0.8044873754152824\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34328425875217317\n",
            "                    \t     Validation Loss : 0.4298123888749194\n",
            "                    \t     Training Accuracy : 0.8460202814569536\n",
            "                    \t     Validation Accuracy : 0.8045609271523179\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34278354494460544\n",
            "                    \t     Validation Loss : 0.429780320748851\n",
            "                    \t     Training Accuracy : 0.8462788778877888\n",
            "                    \t     Validation Accuracy : 0.804656105610561\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3423916573746522\n",
            "                    \t     Validation Loss : 0.429690160918381\n",
            "                    \t     Training Accuracy : 0.846467927631579\n",
            "                    \t     Validation Accuracy : 0.8047569078947369\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3419033361216549\n",
            "                    \t     Validation Loss : 0.4296188881695395\n",
            "                    \t     Training Accuracy : 0.8467008196721312\n",
            "                    \t     Validation Accuracy : 0.8048649180327869\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.34142892041115785\n",
            "                    \t     Validation Loss : 0.4296778918809537\n",
            "                    \t     Training Accuracy : 0.8469240196078431\n",
            "                    \t     Validation Accuracy : 0.8049424836601308\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3409867708591277\n",
            "                    \t     Validation Loss : 0.4297779822391713\n",
            "                    \t     Training Accuracy : 0.8471457654723127\n",
            "                    \t     Validation Accuracy : 0.8050045602605863\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3405539380062323\n",
            "                    \t     Validation Loss : 0.4297142593583609\n",
            "                    \t     Training Accuracy : 0.8473681006493506\n",
            "                    \t     Validation Accuracy : 0.805101948051948\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3401537377929803\n",
            "                    \t     Validation Loss : 0.42967289644361517\n",
            "                    \t     Training Accuracy : 0.8475728155339806\n",
            "                    \t     Validation Accuracy : 0.8051906148867314\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3397551546390018\n",
            "                    \t     Validation Loss : 0.4296040920806563\n",
            "                    \t     Training Accuracy : 0.8477459677419354\n",
            "                    \t     Validation Accuracy : 0.8052825806451613\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.339321017979234\n",
            "                    \t     Validation Loss : 0.4296803701078361\n",
            "                    \t     Training Accuracy : 0.8479742765273311\n",
            "                    \t     Validation Accuracy : 0.8053495176848875\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3389254830323924\n",
            "                    \t     Validation Loss : 0.42968781673905393\n",
            "                    \t     Training Accuracy : 0.8481610576923077\n",
            "                    \t     Validation Accuracy : 0.8054092948717949\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33860638624134537\n",
            "                    \t     Validation Loss : 0.4296051787683452\n",
            "                    \t     Training Accuracy : 0.8483446485623003\n",
            "                    \t     Validation Accuracy : 0.8054916932907348\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33823947981474506\n",
            "                    \t     Validation Loss : 0.42951449128638597\n",
            "                    \t     Training Accuracy : 0.8485250796178344\n",
            "                    \t     Validation Accuracy : 0.8055907643312102\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3378955928418371\n",
            "                    \t     Validation Loss : 0.4294121053465993\n",
            "                    \t     Training Accuracy : 0.8486746031746032\n",
            "                    \t     Validation Accuracy : 0.8056784126984127\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3375436095082307\n",
            "                    \t     Validation Loss : 0.4293202690000288\n",
            "                    \t     Training Accuracy : 0.8488370253164557\n",
            "                    \t     Validation Accuracy : 0.8057667721518987\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3372174501108822\n",
            "                    \t     Validation Loss : 0.4292878823261559\n",
            "                    \t     Training Accuracy : 0.8490023659305994\n",
            "                    \t     Validation Accuracy : 0.8058362776025236\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33685292184915183\n",
            "                    \t     Validation Loss : 0.42930406677937943\n",
            "                    \t     Training Accuracy : 0.8491666666666666\n",
            "                    \t     Validation Accuracy : 0.8058971698113208\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3364437718687106\n",
            "                    \t     Validation Loss : 0.42928441436581943\n",
            "                    \t     Training Accuracy : 0.8493534482758621\n",
            "                    \t     Validation Accuracy : 0.8059705329153605\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33615753272664733\n",
            "                    \t     Validation Loss : 0.42918866060398214\n",
            "                    \t     Training Accuracy : 0.849498046875\n",
            "                    \t     Validation Accuracy : 0.8060509375\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3357517803564807\n",
            "                    \t     Validation Loss : 0.4291373163965717\n",
            "                    \t     Training Accuracy : 0.8497098909657321\n",
            "                    \t     Validation Accuracy : 0.8061267912772586\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.3353096429948111\n",
            "                    \t     Validation Loss : 0.4290971552143907\n",
            "                    \t     Training Accuracy : 0.8499281832298137\n",
            "                    \t     Validation Accuracy : 0.8062040372670808\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33488280901691125\n",
            "                    \t     Validation Loss : 0.4290734156007426\n",
            "                    \t     Training Accuracy : 0.8501547987616099\n",
            "                    \t     Validation Accuracy : 0.8062922600619195\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33455624614830737\n",
            "                    \t     Validation Loss : 0.4290400695908545\n",
            "                    \t     Training Accuracy : 0.8503298611111111\n",
            "                    \t     Validation Accuracy : 0.8063601851851852\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.33414248652641587\n",
            "                    \t     Validation Loss : 0.4289998302245263\n",
            "                    \t     Training Accuracy : 0.8505076923076923\n",
            "                    \t     Validation Accuracy : 0.8064335384615384\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3336741070191096\n",
            "                    \t     Validation Loss : 0.4289565270063419\n",
            "                    \t     Training Accuracy : 0.8507438650306749\n",
            "                    \t     Validation Accuracy : 0.8065288343558282\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33320183675702014\n",
            "                    \t     Validation Loss : 0.4289566211303343\n",
            "                    \t     Training Accuracy : 0.8509747706422018\n",
            "                    \t     Validation Accuracy : 0.8066262996941896\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3327472749084416\n",
            "                    \t     Validation Loss : 0.4289403575705709\n",
            "                    \t     Training Accuracy : 0.8511985518292683\n",
            "                    \t     Validation Accuracy : 0.8067128048780488\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33228300094898894\n",
            "                    \t     Validation Loss : 0.42897417603443216\n",
            "                    \t     Training Accuracy : 0.8514266717325228\n",
            "                    \t     Validation Accuracy : 0.8067975683890577\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33184470052746207\n",
            "                    \t     Validation Loss : 0.4291017951522957\n",
            "                    \t     Training Accuracy : 0.8516363636363636\n",
            "                    \t     Validation Accuracy : 0.8068542424242424\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33141404568541266\n",
            "                    \t     Validation Loss : 0.4291535390936902\n",
            "                    \t     Training Accuracy : 0.8518617824773413\n",
            "                    \t     Validation Accuracy : 0.8069308157099698\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3310083577389189\n",
            "                    \t     Validation Loss : 0.4291636489070813\n",
            "                    \t     Training Accuracy : 0.8520594879518072\n",
            "                    \t     Validation Accuracy : 0.8070012048192771\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33056749233053073\n",
            "                    \t     Validation Loss : 0.42918266475614253\n",
            "                    \t     Training Accuracy : 0.8522597597597598\n",
            "                    \t     Validation Accuracy : 0.8070663663663664\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.33011278668228916\n",
            "                    \t     Validation Loss : 0.42935915766283694\n",
            "                    \t     Training Accuracy : 0.8524943862275449\n",
            "                    \t     Validation Accuracy : 0.8071191616766467\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.329781244876447\n",
            "                    \t     Validation Loss : 0.4293517626775098\n",
            "                    \t     Training Accuracy : 0.8526679104477612\n",
            "                    \t     Validation Accuracy : 0.8071474626865671\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3293753314894136\n",
            "                    \t     Validation Loss : 0.42936862041076646\n",
            "                    \t     Training Accuracy : 0.8528608630952381\n",
            "                    \t     Validation Accuracy : 0.8072306547619048\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3289832350664747\n",
            "                    \t     Validation Loss : 0.4293037775115555\n",
            "                    \t     Training Accuracy : 0.8530730712166172\n",
            "                    \t     Validation Accuracy : 0.8073118694362018\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3286197670077431\n",
            "                    \t     Validation Loss : 0.42923395623302024\n",
            "                    \t     Training Accuracy : 0.8532618343195266\n",
            "                    \t     Validation Accuracy : 0.8073878698224852\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3281924189332664\n",
            "                    \t     Validation Loss : 0.42932014095718435\n",
            "                    \t     Training Accuracy : 0.8534587020648967\n",
            "                    \t     Validation Accuracy : 0.8074424778761062\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3277731879710713\n",
            "                    \t     Validation Loss : 0.42932300945025254\n",
            "                    \t     Training Accuracy : 0.8536636029411765\n",
            "                    \t     Validation Accuracy : 0.8074961764705882\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.32733617887272337\n",
            "                    \t     Validation Loss : 0.4293631995131618\n",
            "                    \t     Training Accuracy : 0.8538984604105572\n",
            "                    \t     Validation Accuracy : 0.8075439882697947\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3270029974872606\n",
            "                    \t     Validation Loss : 0.4293505216689265\n",
            "                    \t     Training Accuracy : 0.8540551900584795\n",
            "                    \t     Validation Accuracy : 0.8076108187134503\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.32664160128671993\n",
            "                    \t     Validation Loss : 0.42932537804719373\n",
            "                    \t     Training Accuracy : 0.8542474489795918\n",
            "                    \t     Validation Accuracy : 0.8076860058309038\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.326313394055117\n",
            "                    \t     Validation Loss : 0.42929771250783394\n",
            "                    \t     Training Accuracy : 0.854405886627907\n",
            "                    \t     Validation Accuracy : 0.807753488372093\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3259976443777914\n",
            "                    \t     Validation Loss : 0.429478515473786\n",
            "                    \t     Training Accuracy : 0.8545634057971014\n",
            "                    \t     Validation Accuracy : 0.8077637681159421\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3257004492936624\n",
            "                    \t     Validation Loss : 0.4294477157975084\n",
            "                    \t     Training Accuracy : 0.8547218208092485\n",
            "                    \t     Validation Accuracy : 0.8078199421965317\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.32532417156918764\n",
            "                    \t     Validation Loss : 0.4294323929005694\n",
            "                    \t     Training Accuracy : 0.8548901296829972\n",
            "                    \t     Validation Accuracy : 0.8078864553314121\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.3249522246692287\n",
            "                    \t     Validation Loss : 0.42945172179892255\n",
            "                    \t     Training Accuracy : 0.8550718390804598\n",
            "                    \t     Validation Accuracy : 0.8079485632183908\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.32460316625335667\n",
            "                    \t     Validation Loss : 0.42946577038105527\n",
            "                    \t     Training Accuracy : 0.8552542979942693\n",
            "                    \t     Validation Accuracy : 0.8080120343839542\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.324239614645711\n",
            "                    \t     Validation Loss : 0.42944452084621326\n",
            "                    \t     Training Accuracy : 0.8554553571428571\n",
            "                    \t     Validation Accuracy : 0.8080802857142857\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32373983033128784\n",
            "                    \t     Validation Loss : 0.4295147044141768\n",
            "                    \t     Training Accuracy : 0.8556891025641026\n",
            "                    \t     Validation Accuracy : 0.8081532763532764\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32327079751020804\n",
            "                    \t     Validation Loss : 0.4295803405567444\n",
            "                    \t     Training Accuracy : 0.8559161931818182\n",
            "                    \t     Validation Accuracy : 0.8082173295454546\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3228547745569485\n",
            "                    \t     Validation Loss : 0.42963308154467034\n",
            "                    \t     Training Accuracy : 0.8561048158640227\n",
            "                    \t     Validation Accuracy : 0.8082881019830028\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32238580988499066\n",
            "                    \t     Validation Loss : 0.42971118007668413\n",
            "                    \t     Training Accuracy : 0.8563435734463277\n",
            "                    \t     Validation Accuracy : 0.8083460451977401\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32195431355082654\n",
            "                    \t     Validation Loss : 0.4298163325923486\n",
            "                    \t     Training Accuracy : 0.8565475352112676\n",
            "                    \t     Validation Accuracy : 0.8084143661971831\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32155254206630624\n",
            "                    \t     Validation Loss : 0.4298362314583934\n",
            "                    \t     Training Accuracy : 0.8567450842696629\n",
            "                    \t     Validation Accuracy : 0.8084887640449439\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.32115942965702515\n",
            "                    \t     Validation Loss : 0.4298997674991456\n",
            "                    \t     Training Accuracy : 0.856938025210084\n",
            "                    \t     Validation Accuracy : 0.8085434173669468\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.320776372935061\n",
            "                    \t     Validation Loss : 0.42994875010945227\n",
            "                    \t     Training Accuracy : 0.8571141759776536\n",
            "                    \t     Validation Accuracy : 0.8086055865921787\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3203341904305399\n",
            "                    \t     Validation Loss : 0.4300651247681717\n",
            "                    \t     Training Accuracy : 0.8573346100278552\n",
            "                    \t     Validation Accuracy : 0.80866713091922\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3198837440687542\n",
            "                    \t     Validation Loss : 0.4301567474035973\n",
            "                    \t     Training Accuracy : 0.8575538194444444\n",
            "                    \t     Validation Accuracy : 0.8087213888888889\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.31946677665992373\n",
            "                    \t     Validation Loss : 0.43020554787915927\n",
            "                    \t     Training Accuracy : 0.8577527700831025\n",
            "                    \t     Validation Accuracy : 0.8087767313019391\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.31908861524564375\n",
            "                    \t     Validation Loss : 0.430236308626983\n",
            "                    \t     Training Accuracy : 0.8579281767955801\n",
            "                    \t     Validation Accuracy : 0.8088279005524862\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3187003414342103\n",
            "                    \t     Validation Loss : 0.4303013806633238\n",
            "                    \t     Training Accuracy : 0.8581198347107438\n",
            "                    \t     Validation Accuracy : 0.8088710743801653\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.31830357113720054\n",
            "                    \t     Validation Loss : 0.4303422261163084\n",
            "                    \t     Training Accuracy : 0.8583121565934065\n",
            "                    \t     Validation Accuracy : 0.8089200549450549\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3179719853238904\n",
            "                    \t     Validation Loss : 0.4303831864043544\n",
            "                    \t     Training Accuracy : 0.8584691780821918\n",
            "                    \t     Validation Accuracy : 0.808973698630137\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.31755123014302283\n",
            "                    \t     Validation Loss : 0.43046600908605137\n",
            "                    \t     Training Accuracy : 0.8586680327868852\n",
            "                    \t     Validation Accuracy : 0.8090333333333334\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3171845426500777\n",
            "                    \t     Validation Loss : 0.43047468903270936\n",
            "                    \t     Training Accuracy : 0.8588589918256131\n",
            "                    \t     Validation Accuracy : 0.8090972752043597\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3168305556013492\n",
            "                    \t     Validation Loss : 0.4305708835488202\n",
            "                    \t     Training Accuracy : 0.8590285326086956\n",
            "                    \t     Validation Accuracy : 0.809141847826087\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3164616139634919\n",
            "                    \t     Validation Loss : 0.43066908800034515\n",
            "                    \t     Training Accuracy : 0.8592107046070461\n",
            "                    \t     Validation Accuracy : 0.8091956639566396\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.316102992597464\n",
            "                    \t     Validation Loss : 0.4307238513908913\n",
            "                    \t     Training Accuracy : 0.8593935810810811\n",
            "                    \t     Validation Accuracy : 0.8092554054054054\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3156588517814232\n",
            "                    \t     Validation Loss : 0.43086188635903344\n",
            "                    \t     Training Accuracy : 0.8595990566037736\n",
            "                    \t     Validation Accuracy : 0.8093040431266847\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.31525543991977006\n",
            "                    \t     Validation Loss : 0.43097352043382026\n",
            "                    \t     Training Accuracy : 0.8597983870967741\n",
            "                    \t     Validation Accuracy : 0.809363440860215\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3149395211468433\n",
            "                    \t     Validation Loss : 0.4310297913119159\n",
            "                    \t     Training Accuracy : 0.8599731903485255\n",
            "                    \t     Validation Accuracy : 0.8094067024128686\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.314577221154051\n",
            "                    \t     Validation Loss : 0.43107404776913727\n",
            "                    \t     Training Accuracy : 0.8601437165775401\n",
            "                    \t     Validation Accuracy : 0.8094641711229946\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.3141910213559866\n",
            "                    \t     Validation Loss : 0.43119483204266895\n",
            "                    \t     Training Accuracy : 0.8603416666666667\n",
            "                    \t     Validation Accuracy : 0.8095024\n",
            "                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNext"
      ],
      "metadata": {
        "id": "Rc8SBj-H_lE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ResNext accuracy on validation was 0.85 but here we have 0.81:"
      ],
      "metadata": {
        "id": "S2kdivvKnJ6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('resnext')\n",
        "\n",
        "optimizer = optim.Adam([{'params': model.feature_extractor.parameters()},\n",
        "    {'params': model.conv_auto_encoder.parameters(), 'lr' : learning_rates[str(model.name)]['CAE LR']},\n",
        "    {'params': model.classifier.parameters(), 'lr' : learning_rates[str(model.name)]['LC LR']}],\n",
        "    lr=0.0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euytHY3u_pe_",
        "outputId": "47a31727-6986-4640-a12e-9409f1d54ac9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.9217997193336487\n",
            "                    \t     Validation Loss : 0.6492835372781601\n",
            "                    \t     Training Accuracy : 0.5475\n",
            "                    \t     Validation Accuracy : 0.6291\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7712770956754684\n",
            "                    \t     Validation Loss : 0.5970987487620059\n",
            "                    \t     Training Accuracy : 0.60125\n",
            "                    \t     Validation Accuracy : 0.67655\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6982699722051621\n",
            "                    \t     Validation Loss : 0.5603028067702048\n",
            "                    \t     Training Accuracy : 0.6414583333333334\n",
            "                    \t     Validation Accuracy : 0.7057666666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6501203415542841\n",
            "                    \t     Validation Loss : 0.5459037795900917\n",
            "                    \t     Training Accuracy : 0.6709375\n",
            "                    \t     Validation Accuracy : 0.718075\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6251104968190193\n",
            "                    \t     Validation Loss : 0.5372761733615741\n",
            "                    \t     Training Accuracy : 0.68475\n",
            "                    \t     Validation Accuracy : 0.7258\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5984351070225239\n",
            "                    \t     Validation Loss : 0.5210284711723637\n",
            "                    \t     Training Accuracy : 0.700625\n",
            "                    \t     Validation Accuracy : 0.73745\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5827290686113494\n",
            "                    \t     Validation Loss : 0.5114938973877213\n",
            "                    \t     Training Accuracy : 0.7083035714285715\n",
            "                    \t     Validation Accuracy : 0.7447857142857143\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5656422522291541\n",
            "                    \t     Validation Loss : 0.5041229482026051\n",
            "                    \t     Training Accuracy : 0.7190625\n",
            "                    \t     Validation Accuracy : 0.750925\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.555332679119375\n",
            "                    \t     Validation Loss : 0.49832956611390733\n",
            "                    \t     Training Accuracy : 0.7254861111111112\n",
            "                    \t     Validation Accuracy : 0.7554444444444445\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5455662845671176\n",
            "                    \t     Validation Loss : 0.49229727716872484\n",
            "                    \t     Training Accuracy : 0.7320625\n",
            "                    \t     Validation Accuracy : 0.75997\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5369383996183222\n",
            "                    \t     Validation Loss : 0.4855824918108834\n",
            "                    \t     Training Accuracy : 0.7373295454545454\n",
            "                    \t     Validation Accuracy : 0.7644454545454545\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5292467462271452\n",
            "                    \t     Validation Loss : 0.4802428723349612\n",
            "                    \t     Training Accuracy : 0.7421354166666667\n",
            "                    \t     Validation Accuracy : 0.7679083333333333\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5208155590754289\n",
            "                    \t     Validation Loss : 0.47834094492391277\n",
            "                    \t     Training Accuracy : 0.7466346153846154\n",
            "                    \t     Validation Accuracy : 0.7692615384615384\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5154069456032344\n",
            "                    \t     Validation Loss : 0.47409213661453814\n",
            "                    \t     Training Accuracy : 0.7500892857142857\n",
            "                    \t     Validation Accuracy : 0.7718357142857143\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5094374635815621\n",
            "                    \t     Validation Loss : 0.47186762636906293\n",
            "                    \t     Training Accuracy : 0.7533333333333333\n",
            "                    \t     Validation Accuracy : 0.7738266666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5035028497315943\n",
            "                    \t     Validation Loss : 0.4677364235333265\n",
            "                    \t     Training Accuracy : 0.7563671875\n",
            "                    \t     Validation Accuracy : 0.776175\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.49921595897744686\n",
            "                    \t     Validation Loss : 0.4647968804487898\n",
            "                    \t     Training Accuracy : 0.7585661764705882\n",
            "                    \t     Validation Accuracy : 0.7780588235294118\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4956908689936002\n",
            "                    \t     Validation Loss : 0.46235999423728835\n",
            "                    \t     Training Accuracy : 0.7605555555555555\n",
            "                    \t     Validation Accuracy : 0.7798\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4919284741972622\n",
            "                    \t     Validation Loss : 0.45980948125321824\n",
            "                    \t     Training Accuracy : 0.7633552631578947\n",
            "                    \t     Validation Accuracy : 0.7815684210526316\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.48864355370402335\n",
            "                    \t     Validation Loss : 0.45753185303685384\n",
            "                    \t     Training Accuracy : 0.7654375\n",
            "                    \t     Validation Accuracy : 0.782935\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4859202904360635\n",
            "                    \t     Validation Loss : 0.4548856111992336\n",
            "                    \t     Training Accuracy : 0.7673511904761905\n",
            "                    \t     Validation Accuracy : 0.7844619047619048\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4823304914750836\n",
            "                    \t     Validation Loss : 0.4527817379565319\n",
            "                    \t     Training Accuracy : 0.7696306818181818\n",
            "                    \t     Validation Accuracy : 0.7858136363636363\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.47875760439945303\n",
            "                    \t     Validation Loss : 0.4504877456502296\n",
            "                    \t     Training Accuracy : 0.7715217391304348\n",
            "                    \t     Validation Accuracy : 0.7873434782608696\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.47646681309988104\n",
            "                    \t     Validation Loss : 0.4481476923099722\n",
            "                    \t     Training Accuracy : 0.7730989583333333\n",
            "                    \t     Validation Accuracy : 0.7887625\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.47350880150794983\n",
            "                    \t     Validation Loss : 0.4475220982278117\n",
            "                    \t     Training Accuracy : 0.774875\n",
            "                    \t     Validation Accuracy : 0.789392\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.46946988727037725\n",
            "                    \t     Validation Loss : 0.44576351428631045\n",
            "                    \t     Training Accuracy : 0.7773798076923077\n",
            "                    \t     Validation Accuracy : 0.7903576923076923\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4658458812810757\n",
            "                    \t     Validation Loss : 0.4442111014625107\n",
            "                    \t     Training Accuracy : 0.7797453703703704\n",
            "                    \t     Validation Accuracy : 0.7912222222222223\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4619527396240405\n",
            "                    \t     Validation Loss : 0.4425920923582662\n",
            "                    \t     Training Accuracy : 0.7818973214285714\n",
            "                    \t     Validation Accuracy : 0.792225\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4579230513963206\n",
            "                    \t     Validation Loss : 0.44086223439989314\n",
            "                    \t     Training Accuracy : 0.7842456896551724\n",
            "                    \t     Validation Accuracy : 0.7932724137931034\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.45480184376239774\n",
            "                    \t     Validation Loss : 0.4395694017029418\n",
            "                    \t     Training Accuracy : 0.7865208333333333\n",
            "                    \t     Validation Accuracy : 0.7942333333333333\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4510197863319228\n",
            "                    \t     Validation Loss : 0.43847260746490974\n",
            "                    \t     Training Accuracy : 0.7885887096774193\n",
            "                    \t     Validation Accuracy : 0.7949774193548387\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.448497918904759\n",
            "                    \t     Validation Loss : 0.4372882707350956\n",
            "                    \t     Training Accuracy : 0.7902734375\n",
            "                    \t     Validation Accuracy : 0.795471875\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4460364332569368\n",
            "                    \t     Validation Loss : 0.4368198074163109\n",
            "                    \t     Training Accuracy : 0.7916666666666666\n",
            "                    \t     Validation Accuracy : 0.7958848484848485\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44292809909319175\n",
            "                    \t     Validation Loss : 0.43586362380127647\n",
            "                    \t     Training Accuracy : 0.7936764705882353\n",
            "                    \t     Validation Accuracy : 0.7964588235294118\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4407402110993862\n",
            "                    \t     Validation Loss : 0.4347033452819004\n",
            "                    \t     Training Accuracy : 0.7947321428571429\n",
            "                    \t     Validation Accuracy : 0.7972485714285714\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43930830745647353\n",
            "                    \t     Validation Loss : 0.43482992990503805\n",
            "                    \t     Training Accuracy : 0.7956597222222223\n",
            "                    \t     Validation Accuracy : 0.7974027777777778\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4369650956948061\n",
            "                    \t     Validation Loss : 0.43408094327866276\n",
            "                    \t     Training Accuracy : 0.7971283783783784\n",
            "                    \t     Validation Accuracy : 0.7978027027027027\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43475989899745116\n",
            "                    \t     Validation Loss : 0.4328772504291696\n",
            "                    \t     Training Accuracy : 0.7982565789473685\n",
            "                    \t     Validation Accuracy : 0.7983842105263158\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43301675595916234\n",
            "                    \t     Validation Loss : 0.4316939022494269\n",
            "                    \t     Training Accuracy : 0.7993429487179488\n",
            "                    \t     Validation Accuracy : 0.7989461538461539\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43180611841753125\n",
            "                    \t     Validation Loss : 0.43060660614563634\n",
            "                    \t     Training Accuracy : 0.800171875\n",
            "                    \t     Validation Accuracy : 0.799445\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4299987328234242\n",
            "                    \t     Validation Loss : 0.4302244666088011\n",
            "                    \t     Training Accuracy : 0.8010670731707317\n",
            "                    \t     Validation Accuracy : 0.7998317073170732\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4286890513662781\n",
            "                    \t     Validation Loss : 0.42918401554671215\n",
            "                    \t     Training Accuracy : 0.8017857142857143\n",
            "                    \t     Validation Accuracy : 0.800395238095238\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.42654710356925807\n",
            "                    \t     Validation Loss : 0.4281453153467106\n",
            "                    \t     Training Accuracy : 0.8029651162790697\n",
            "                    \t     Validation Accuracy : 0.800960465116279\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4254751380837776\n",
            "                    \t     Validation Loss : 0.4273019137903464\n",
            "                    \t     Training Accuracy : 0.8035369318181819\n",
            "                    \t     Validation Accuracy : 0.8013227272727272\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.424585674441523\n",
            "                    \t     Validation Loss : 0.4267548277064296\n",
            "                    \t     Training Accuracy : 0.8041527777777778\n",
            "                    \t     Validation Accuracy : 0.80176\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.42295224592413594\n",
            "                    \t     Validation Loss : 0.4259330752079421\n",
            "                    \t     Training Accuracy : 0.8050271739130435\n",
            "                    \t     Validation Accuracy : 0.8022652173913043\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4218493859723527\n",
            "                    \t     Validation Loss : 0.4249927554874407\n",
            "                    \t     Training Accuracy : 0.8059042553191489\n",
            "                    \t     Validation Accuracy : 0.8027446808510639\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.42048642156956095\n",
            "                    \t     Validation Loss : 0.4242634254862793\n",
            "                    \t     Training Accuracy : 0.8065885416666667\n",
            "                    \t     Validation Accuracy : 0.8031291666666667\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.41918311735501096\n",
            "                    \t     Validation Loss : 0.4237907852030464\n",
            "                    \t     Training Accuracy : 0.8074234693877551\n",
            "                    \t     Validation Accuracy : 0.8034204081632653\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.41829276676476\n",
            "                    \t     Validation Loss : 0.42302918712980453\n",
            "                    \t     Training Accuracy : 0.807925\n",
            "                    \t     Validation Accuracy : 0.80381\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4158828200633619\n",
            "                    \t     Validation Loss : 0.4226812890519073\n",
            "                    \t     Training Accuracy : 0.8091789215686275\n",
            "                    \t     Validation Accuracy : 0.8042078431372549\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41349271233551776\n",
            "                    \t     Validation Loss : 0.4221265832716167\n",
            "                    \t     Training Accuracy : 0.8105649038461539\n",
            "                    \t     Validation Accuracy : 0.8046480769230769\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4110540028956701\n",
            "                    \t     Validation Loss : 0.42150920530244107\n",
            "                    \t     Training Accuracy : 0.8119221698113207\n",
            "                    \t     Validation Accuracy : 0.8050716981132076\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.409083087860986\n",
            "                    \t     Validation Loss : 0.4214352976767506\n",
            "                    \t     Training Accuracy : 0.8130208333333333\n",
            "                    \t     Validation Accuracy : 0.8054203703703704\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4079870538521897\n",
            "                    \t     Validation Loss : 0.42085320033022666\n",
            "                    \t     Training Accuracy : 0.8135681818181818\n",
            "                    \t     Validation Accuracy : 0.8058018181818182\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40612247753622277\n",
            "                    \t     Validation Loss : 0.42049844083743915\n",
            "                    \t     Training Accuracy : 0.8144196428571429\n",
            "                    \t     Validation Accuracy : 0.8060946428571428\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4041199459240102\n",
            "                    \t     Validation Loss : 0.42016800678963684\n",
            "                    \t     Training Accuracy : 0.8154495614035088\n",
            "                    \t     Validation Accuracy : 0.8063175438596492\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4027710671697197\n",
            "                    \t     Validation Loss : 0.4198243260134077\n",
            "                    \t     Training Accuracy : 0.8160560344827587\n",
            "                    \t     Validation Accuracy : 0.8064965517241379\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40146838635458787\n",
            "                    \t     Validation Loss : 0.41945535753943236\n",
            "                    \t     Training Accuracy : 0.8167690677966102\n",
            "                    \t     Validation Accuracy : 0.8067881355932204\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40011202640583116\n",
            "                    \t     Validation Loss : 0.4190169268776687\n",
            "                    \t     Training Accuracy : 0.8175416666666667\n",
            "                    \t     Validation Accuracy : 0.8070083333333333\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39869050446836674\n",
            "                    \t     Validation Loss : 0.41850680616932395\n",
            "                    \t     Training Accuracy : 0.8183913934426229\n",
            "                    \t     Validation Accuracy : 0.8072540983606558\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39740501557867375\n",
            "                    \t     Validation Loss : 0.41861988257224764\n",
            "                    \t     Training Accuracy : 0.819163306451613\n",
            "                    \t     Validation Accuracy : 0.807216129032258\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39695080165115615\n",
            "                    \t     Validation Loss : 0.4181436056137913\n",
            "                    \t     Training Accuracy : 0.8195238095238095\n",
            "                    \t     Validation Accuracy : 0.8075253968253968\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3958351418399252\n",
            "                    \t     Validation Loss : 0.41776293195737974\n",
            "                    \t     Training Accuracy : 0.820126953125\n",
            "                    \t     Validation Accuracy : 0.80776875\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39474444378568574\n",
            "                    \t     Validation Loss : 0.417687046936555\n",
            "                    \t     Training Accuracy : 0.8207692307692308\n",
            "                    \t     Validation Accuracy : 0.8077061538461539\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39362333523730436\n",
            "                    \t     Validation Loss : 0.4174595245724871\n",
            "                    \t     Training Accuracy : 0.8212973484848485\n",
            "                    \t     Validation Accuracy : 0.8079621212121212\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3926420646861418\n",
            "                    \t     Validation Loss : 0.41784618362364445\n",
            "                    \t     Training Accuracy : 0.822080223880597\n",
            "                    \t     Validation Accuracy : 0.8078985074626865\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3920057222553912\n",
            "                    \t     Validation Loss : 0.41772043113287816\n",
            "                    \t     Training Accuracy : 0.8226930147058824\n",
            "                    \t     Validation Accuracy : 0.8080161764705882\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3911230701942375\n",
            "                    \t     Validation Loss : 0.41744388703024154\n",
            "                    \t     Training Accuracy : 0.8233152173913043\n",
            "                    \t     Validation Accuracy : 0.8081478260869566\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3903026458450726\n",
            "                    \t     Validation Loss : 0.4171049754449435\n",
            "                    \t     Training Accuracy : 0.8237053571428572\n",
            "                    \t     Validation Accuracy : 0.8083528571428571\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3897692301785442\n",
            "                    \t     Validation Loss : 0.41746757789009337\n",
            "                    \t     Training Accuracy : 0.8240404929577465\n",
            "                    \t     Validation Accuracy : 0.8082478873239437\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.388909524621235\n",
            "                    \t     Validation Loss : 0.41725871369228124\n",
            "                    \t     Training Accuracy : 0.8244270833333334\n",
            "                    \t     Validation Accuracy : 0.8083972222222222\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.38789789251268725\n",
            "                    \t     Validation Loss : 0.4174755703015653\n",
            "                    \t     Training Accuracy : 0.8248801369863014\n",
            "                    \t     Validation Accuracy : 0.8085547945205479\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3873666011884406\n",
            "                    \t     Validation Loss : 0.4171264513010765\n",
            "                    \t     Training Accuracy : 0.8251942567567567\n",
            "                    \t     Validation Accuracy : 0.8087445945945946\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.38658678910334904\n",
            "                    \t     Validation Loss : 0.4169382241263557\n",
            "                    \t     Training Accuracy : 0.8256416666666667\n",
            "                    \t     Validation Accuracy : 0.808984\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3848130887374282\n",
            "                    \t     Validation Loss : 0.41686347858770134\n",
            "                    \t     Training Accuracy : 0.8265131578947369\n",
            "                    \t     Validation Accuracy : 0.8092026315789473\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.38324989627321043\n",
            "                    \t     Validation Loss : 0.41726172196503264\n",
            "                    \t     Training Accuracy : 0.827426948051948\n",
            "                    \t     Validation Accuracy : 0.8092389610389611\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.38188814603365384\n",
            "                    \t     Validation Loss : 0.4172181988583132\n",
            "                    \t     Training Accuracy : 0.8281089743589743\n",
            "                    \t     Validation Accuracy : 0.8093423076923076\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.38034867976096615\n",
            "                    \t     Validation Loss : 0.4170558158219832\n",
            "                    \t     Training Accuracy : 0.8288528481012658\n",
            "                    \t     Validation Accuracy : 0.8095962025316455\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.37892094888724387\n",
            "                    \t     Validation Loss : 0.4172472583213315\n",
            "                    \t     Training Accuracy : 0.8296875\n",
            "                    \t     Validation Accuracy : 0.80970125\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3775671868265411\n",
            "                    \t     Validation Loss : 0.41739450211024764\n",
            "                    \t     Training Accuracy : 0.8303317901234568\n",
            "                    \t     Validation Accuracy : 0.8098074074074074\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3762250831486975\n",
            "                    \t     Validation Loss : 0.41716328921253865\n",
            "                    \t     Training Accuracy : 0.830967987804878\n",
            "                    \t     Validation Accuracy : 0.8099353658536586\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.37526894650365933\n",
            "                    \t     Validation Loss : 0.41687866972729326\n",
            "                    \t     Training Accuracy : 0.8314834337349397\n",
            "                    \t     Validation Accuracy : 0.8101518072289157\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3743499328604057\n",
            "                    \t     Validation Loss : 0.41671332320439003\n",
            "                    \t     Training Accuracy : 0.832046130952381\n",
            "                    \t     Validation Accuracy : 0.8103369047619048\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3731011618691332\n",
            "                    \t     Validation Loss : 0.4165573928574493\n",
            "                    \t     Training Accuracy : 0.83275\n",
            "                    \t     Validation Accuracy : 0.8104082352941177\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3719832050193881\n",
            "                    \t     Validation Loss : 0.4166041051246377\n",
            "                    \t     Training Accuracy : 0.8332848837209302\n",
            "                    \t     Validation Accuracy : 0.8105220930232558\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.37110858985747414\n",
            "                    \t     Validation Loss : 0.4165823869069273\n",
            "                    \t     Training Accuracy : 0.8338505747126437\n",
            "                    \t     Validation Accuracy : 0.810628735632184\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3700646429237994\n",
            "                    \t     Validation Loss : 0.41644268181589394\n",
            "                    \t     Training Accuracy : 0.8343963068181818\n",
            "                    \t     Validation Accuracy : 0.8107215909090909\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3688445423761111\n",
            "                    \t     Validation Loss : 0.4164695445114239\n",
            "                    \t     Training Accuracy : 0.8349859550561798\n",
            "                    \t     Validation Accuracy : 0.810823595505618\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3679946494085921\n",
            "                    \t     Validation Loss : 0.4162707862863102\n",
            "                    \t     Training Accuracy : 0.8355416666666666\n",
            "                    \t     Validation Accuracy : 0.8109122222222223\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36700482561856834\n",
            "                    \t     Validation Loss : 0.4165048462554582\n",
            "                    \t     Training Accuracy : 0.8360096153846154\n",
            "                    \t     Validation Accuracy : 0.8110703296703297\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3659275747009593\n",
            "                    \t     Validation Loss : 0.4162322188409182\n",
            "                    \t     Training Accuracy : 0.8365692934782609\n",
            "                    \t     Validation Accuracy : 0.8112195652173914\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3652814481751893\n",
            "                    \t     Validation Loss : 0.41613646318370784\n",
            "                    \t     Training Accuracy : 0.8368548387096775\n",
            "                    \t     Validation Accuracy : 0.8113989247311828\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36450908332111986\n",
            "                    \t     Validation Loss : 0.4160415744134842\n",
            "                    \t     Training Accuracy : 0.8372938829787234\n",
            "                    \t     Validation Accuracy : 0.8115436170212766\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36342143406209193\n",
            "                    \t     Validation Loss : 0.41619887334750805\n",
            "                    \t     Training Accuracy : 0.8379276315789473\n",
            "                    \t     Validation Accuracy : 0.8116978947368421\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3627632726061468\n",
            "                    \t     Validation Loss : 0.41588618161297614\n",
            "                    \t     Training Accuracy : 0.8382356770833334\n",
            "                    \t     Validation Accuracy : 0.81185625\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36163056881157396\n",
            "                    \t     Validation Loss : 0.4158978231553327\n",
            "                    \t     Training Accuracy : 0.8388273195876289\n",
            "                    \t     Validation Accuracy : 0.8119824742268041\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3607619983064277\n",
            "                    \t     Validation Loss : 0.4159580870152157\n",
            "                    \t     Training Accuracy : 0.8392984693877551\n",
            "                    \t     Validation Accuracy : 0.8121489795918367\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3602008273234271\n",
            "                    \t     Validation Loss : 0.41567021484909666\n",
            "                    \t     Training Accuracy : 0.839665404040404\n",
            "                    \t     Validation Accuracy : 0.8122737373737374\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3594798647135496\n",
            "                    \t     Validation Loss : 0.41559397774906204\n",
            "                    \t     Training Accuracy : 0.8399875\n",
            "                    \t     Validation Accuracy : 0.812327\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.35785335309877253\n",
            "                    \t     Validation Loss : 0.41571830257919995\n",
            "                    \t     Training Accuracy : 0.8407611386138614\n",
            "                    \t     Validation Accuracy : 0.8124366336633664\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3562406259986992\n",
            "                    \t     Validation Loss : 0.41597091865763214\n",
            "                    \t     Training Accuracy : 0.8415563725490196\n",
            "                    \t     Validation Accuracy : 0.8125382352941176\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.35487828284429696\n",
            "                    \t     Validation Loss : 0.41708771866854316\n",
            "                    \t     Training Accuracy : 0.8422208737864078\n",
            "                    \t     Validation Accuracy : 0.812626213592233\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3535616651385163\n",
            "                    \t     Validation Loss : 0.41750161994191864\n",
            "                    \t     Training Accuracy : 0.8428846153846153\n",
            "                    \t     Validation Accuracy : 0.8126990384615385\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3524009980296805\n",
            "                    \t     Validation Loss : 0.4182986057005969\n",
            "                    \t     Training Accuracy : 0.8435119047619047\n",
            "                    \t     Validation Accuracy : 0.8128114285714285\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.35114814234159464\n",
            "                    \t     Validation Loss : 0.41890272279787333\n",
            "                    \t     Training Accuracy : 0.8441981132075471\n",
            "                    \t     Validation Accuracy : 0.8128028301886793\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.34999760697726334\n",
            "                    \t     Validation Loss : 0.4198770961057355\n",
            "                    \t     Training Accuracy : 0.8447429906542057\n",
            "                    \t     Validation Accuracy : 0.812781308411215\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.348769171188275\n",
            "                    \t     Validation Loss : 0.42021550289123244\n",
            "                    \t     Training Accuracy : 0.8454050925925926\n",
            "                    \t     Validation Accuracy : 0.8128907407407407\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3474425548205682\n",
            "                    \t     Validation Loss : 0.42061642934989024\n",
            "                    \t     Training Accuracy : 0.8460435779816514\n",
            "                    \t     Validation Accuracy : 0.8129669724770642\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3462564665824175\n",
            "                    \t     Validation Loss : 0.4209942416295803\n",
            "                    \t     Training Accuracy : 0.8466477272727273\n",
            "                    \t     Validation Accuracy : 0.8130827272727272\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3451535655256059\n",
            "                    \t     Validation Loss : 0.421156905455742\n",
            "                    \t     Training Accuracy : 0.8471227477477478\n",
            "                    \t     Validation Accuracy : 0.8132027027027027\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3442222405384694\n",
            "                    \t     Validation Loss : 0.42126524376515884\n",
            "                    \t     Training Accuracy : 0.8476506696428572\n",
            "                    \t     Validation Accuracy : 0.81323125\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3432638543329935\n",
            "                    \t     Validation Loss : 0.4215038852773687\n",
            "                    \t     Training Accuracy : 0.8480365044247787\n",
            "                    \t     Validation Accuracy : 0.8132637168141593\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3425190363105452\n",
            "                    \t     Validation Loss : 0.4215090993634588\n",
            "                    \t     Training Accuracy : 0.8484320175438597\n",
            "                    \t     Validation Accuracy : 0.813390350877193\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.34136354429436766\n",
            "                    \t     Validation Loss : 0.4219486265579749\n",
            "                    \t     Training Accuracy : 0.8490217391304348\n",
            "                    \t     Validation Accuracy : 0.8134730434782609\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3404794374596456\n",
            "                    \t     Validation Loss : 0.4222708246365421\n",
            "                    \t     Training Accuracy : 0.8494558189655173\n",
            "                    \t     Validation Accuracy : 0.8135181034482759\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3396519445430519\n",
            "                    \t     Validation Loss : 0.4223237153155813\n",
            "                    \t     Training Accuracy : 0.8498183760683761\n",
            "                    \t     Validation Accuracy : 0.8135820512820513\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33863014894143\n",
            "                    \t     Validation Loss : 0.42237908364559906\n",
            "                    \t     Training Accuracy : 0.850365466101695\n",
            "                    \t     Validation Accuracy : 0.8136652542372881\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33760286760680813\n",
            "                    \t     Validation Loss : 0.4225631149148504\n",
            "                    \t     Training Accuracy : 0.8508140756302521\n",
            "                    \t     Validation Accuracy : 0.8137663865546219\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3367485465357701\n",
            "                    \t     Validation Loss : 0.42271032001589115\n",
            "                    \t     Training Accuracy : 0.8511822916666667\n",
            "                    \t     Validation Accuracy : 0.8138233333333333\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33594278561182256\n",
            "                    \t     Validation Loss : 0.4228998427056871\n",
            "                    \t     Training Accuracy : 0.8515289256198347\n",
            "                    \t     Validation Accuracy : 0.8139033057851239\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33527609042823314\n",
            "                    \t     Validation Loss : 0.4232635058968743\n",
            "                    \t     Training Accuracy : 0.8518493852459016\n",
            "                    \t     Validation Accuracy : 0.8140024590163935\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33446724995728433\n",
            "                    \t     Validation Loss : 0.4241421602763335\n",
            "                    \t     Training Accuracy : 0.8522967479674797\n",
            "                    \t     Validation Accuracy : 0.8140845528455285\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3336465845461334\n",
            "                    \t     Validation Loss : 0.42417539070455096\n",
            "                    \t     Training Accuracy : 0.8527570564516129\n",
            "                    \t     Validation Accuracy : 0.8141548387096774\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33306163006424905\n",
            "                    \t     Validation Loss : 0.42418029672954793\n",
            "                    \t     Training Accuracy : 0.853105\n",
            "                    \t     Validation Accuracy : 0.8141992\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3316891956589525\n",
            "                    \t     Validation Loss : 0.42477221092850315\n",
            "                    \t     Training Accuracy : 0.8537549603174603\n",
            "                    \t     Validation Accuracy : 0.8142452380952381\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.33025693427888664\n",
            "                    \t     Validation Loss : 0.4255711340111926\n",
            "                    \t     Training Accuracy : 0.8543700787401575\n",
            "                    \t     Validation Accuracy : 0.8142858267716535\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.32914746692084007\n",
            "                    \t     Validation Loss : 0.4259363385841634\n",
            "                    \t     Training Accuracy : 0.8548583984375\n",
            "                    \t     Validation Accuracy : 0.8143453125\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3278934207705911\n",
            "                    \t     Validation Loss : 0.42702506229100223\n",
            "                    \t     Training Accuracy : 0.8554748062015504\n",
            "                    \t     Validation Accuracy : 0.8143519379844961\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.32663379590241953\n",
            "                    \t     Validation Loss : 0.4278513617659778\n",
            "                    \t     Training Accuracy : 0.8560625\n",
            "                    \t     Validation Accuracy : 0.814363076923077\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.32531845138813476\n",
            "                    \t     Validation Loss : 0.42851605546781035\n",
            "                    \t     Training Accuracy : 0.8566937022900764\n",
            "                    \t     Validation Accuracy : 0.8144038167938932\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.32445452242807454\n",
            "                    \t     Validation Loss : 0.42883560408322613\n",
            "                    \t     Training Accuracy : 0.8570738636363636\n",
            "                    \t     Validation Accuracy : 0.8143916666666666\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3234047346514531\n",
            "                    \t     Validation Loss : 0.4291852598870673\n",
            "                    \t     Training Accuracy : 0.8576315789473684\n",
            "                    \t     Validation Accuracy : 0.8143902255639097\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.32233031068859036\n",
            "                    \t     Validation Loss : 0.42939626689371274\n",
            "                    \t     Training Accuracy : 0.8581296641791045\n",
            "                    \t     Validation Accuracy : 0.8144074626865672\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3212719629669079\n",
            "                    \t     Validation Loss : 0.4304687170144962\n",
            "                    \t     Training Accuracy : 0.8586759259259259\n",
            "                    \t     Validation Accuracy : 0.8144429629629629\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.32028173911905683\n",
            "                    \t     Validation Loss : 0.43095956271501346\n",
            "                    \t     Training Accuracy : 0.8591176470588235\n",
            "                    \t     Validation Accuracy : 0.8144941176470588\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3192228584668606\n",
            "                    \t     Validation Loss : 0.4316923567221941\n",
            "                    \t     Training Accuracy : 0.8596167883211678\n",
            "                    \t     Validation Accuracy : 0.8145306569343066\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.318357429622902\n",
            "                    \t     Validation Loss : 0.43245801183599014\n",
            "                    \t     Training Accuracy : 0.8600769927536231\n",
            "                    \t     Validation Accuracy : 0.8145876811594203\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.31737207233557385\n",
            "                    \t     Validation Loss : 0.4326373100219797\n",
            "                    \t     Training Accuracy : 0.8605395683453237\n",
            "                    \t     Validation Accuracy : 0.8146100719424461\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.31651085276821894\n",
            "                    \t     Validation Loss : 0.43315195024918063\n",
            "                    \t     Training Accuracy : 0.861\n",
            "                    \t     Validation Accuracy : 0.8146628571428571\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.315690197283336\n",
            "                    \t     Validation Loss : 0.43316058534924134\n",
            "                    \t     Training Accuracy : 0.8614007092198581\n",
            "                    \t     Validation Accuracy : 0.8147375886524822\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3150801033644714\n",
            "                    \t     Validation Loss : 0.43313190908598403\n",
            "                    \t     Training Accuracy : 0.8617077464788733\n",
            "                    \t     Validation Accuracy : 0.8148147887323943\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.31426407630653025\n",
            "                    \t     Validation Loss : 0.4335006824165543\n",
            "                    \t     Training Accuracy : 0.8621022727272727\n",
            "                    \t     Validation Accuracy : 0.8148629370629371\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3133293153389564\n",
            "                    \t     Validation Loss : 0.43364582453990924\n",
            "                    \t     Training Accuracy : 0.8626041666666666\n",
            "                    \t     Validation Accuracy : 0.8149361111111111\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.31249109913074763\n",
            "                    \t     Validation Loss : 0.43405685821063617\n",
            "                    \t     Training Accuracy : 0.8629956896551724\n",
            "                    \t     Validation Accuracy : 0.8149379310344828\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3116013340220774\n",
            "                    \t     Validation Loss : 0.4348287275159243\n",
            "                    \t     Training Accuracy : 0.8634503424657535\n",
            "                    \t     Validation Accuracy : 0.814913698630137\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3109110951806311\n",
            "                    \t     Validation Loss : 0.43533664777930325\n",
            "                    \t     Training Accuracy : 0.8637627551020408\n",
            "                    \t     Validation Accuracy : 0.814934693877551\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.31008163287455365\n",
            "                    \t     Validation Loss : 0.43567512252173984\n",
            "                    \t     Training Accuracy : 0.8641722972972973\n",
            "                    \t     Validation Accuracy : 0.8149641891891892\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3093705616133825\n",
            "                    \t     Validation Loss : 0.4362904437848526\n",
            "                    \t     Training Accuracy : 0.8644714765100671\n",
            "                    \t     Validation Accuracy : 0.8149161073825504\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.30865278329675394\n",
            "                    \t     Validation Loss : 0.43662119198562743\n",
            "                    \t     Training Accuracy : 0.8648\n",
            "                    \t     Validation Accuracy : 0.8149566666666667\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.30745833575059445\n",
            "                    \t     Validation Loss : 0.43784460928779373\n",
            "                    \t     Training Accuracy : 0.8653476821192053\n",
            "                    \t     Validation Accuracy : 0.8149695364238411\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3062258665062683\n",
            "                    \t     Validation Loss : 0.4388488892403032\n",
            "                    \t     Training Accuracy : 0.8658840460526316\n",
            "                    \t     Validation Accuracy : 0.8149861842105263\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3050614397449334\n",
            "                    \t     Validation Loss : 0.4404589080743056\n",
            "                    \t     Training Accuracy : 0.8664665032679738\n",
            "                    \t     Validation Accuracy : 0.8149882352941177\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3040418606597398\n",
            "                    \t     Validation Loss : 0.4420246075592111\n",
            "                    \t     Training Accuracy : 0.866939935064935\n",
            "                    \t     Validation Accuracy : 0.8150201298701298\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.303074257790802\n",
            "                    \t     Validation Loss : 0.44273475401420626\n",
            "                    \t     Training Accuracy : 0.8673951612903226\n",
            "                    \t     Validation Accuracy : 0.8150006451612903\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3019647658463472\n",
            "                    \t     Validation Loss : 0.44376146234823705\n",
            "                    \t     Training Accuracy : 0.8678806089743589\n",
            "                    \t     Validation Accuracy : 0.8149846153846154\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.30105609182814125\n",
            "                    \t     Validation Loss : 0.4444689668632521\n",
            "                    \t     Training Accuracy : 0.868296178343949\n",
            "                    \t     Validation Accuracy : 0.8149859872611465\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2999145283583033\n",
            "                    \t     Validation Loss : 0.44579497481332736\n",
            "                    \t     Training Accuracy : 0.8688053797468355\n",
            "                    \t     Validation Accuracy : 0.8150107594936709\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2989064590941599\n",
            "                    \t     Validation Loss : 0.446267837473147\n",
            "                    \t     Training Accuracy : 0.8692688679245283\n",
            "                    \t     Validation Accuracy : 0.8150012578616352\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2980931550179957\n",
            "                    \t     Validation Loss : 0.44718597457727816\n",
            "                    \t     Training Accuracy : 0.869671875\n",
            "                    \t     Validation Accuracy : 0.8150075\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29722558799917054\n",
            "                    \t     Validation Loss : 0.4480031123767209\n",
            "                    \t     Training Accuracy : 0.8701164596273292\n",
            "                    \t     Validation Accuracy : 0.8150347826086957\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29621688528003653\n",
            "                    \t     Validation Loss : 0.44924844781479256\n",
            "                    \t     Training Accuracy : 0.8705825617283951\n",
            "                    \t     Validation Accuracy : 0.8150308641975309\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2952096745266116\n",
            "                    \t     Validation Loss : 0.4506913952268173\n",
            "                    \t     Training Accuracy : 0.8710161042944785\n",
            "                    \t     Validation Accuracy : 0.8149865030674847\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29436865278968316\n",
            "                    \t     Validation Loss : 0.4511204858567137\n",
            "                    \t     Training Accuracy : 0.8713643292682927\n",
            "                    \t     Validation Accuracy : 0.8149304878048781\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29351575485159725\n",
            "                    \t     Validation Loss : 0.45184281390679315\n",
            "                    \t     Training Accuracy : 0.8717803030303031\n",
            "                    \t     Validation Accuracy : 0.8149181818181818\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29266631798005205\n",
            "                    \t     Validation Loss : 0.4527385855738738\n",
            "                    \t     Training Accuracy : 0.8721762048192772\n",
            "                    \t     Validation Accuracy : 0.8148632530120482\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29196057926389407\n",
            "                    \t     Validation Loss : 0.45352997382936827\n",
            "                    \t     Training Accuracy : 0.8725224550898204\n",
            "                    \t     Validation Accuracy : 0.8147964071856287\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.291240918801022\n",
            "                    \t     Validation Loss : 0.45410911335430476\n",
            "                    \t     Training Accuracy : 0.8728534226190476\n",
            "                    \t     Validation Accuracy : 0.8147577380952381\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.29053647384593073\n",
            "                    \t     Validation Loss : 0.4549041555744301\n",
            "                    \t     Training Accuracy : 0.8731952662721894\n",
            "                    \t     Validation Accuracy : 0.814791124260355\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.289752223963411\n",
            "                    \t     Validation Loss : 0.45519766209314855\n",
            "                    \t     Training Accuracy : 0.873547794117647\n",
            "                    \t     Validation Accuracy : 0.8147976470588235\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.289120720813748\n",
            "                    \t     Validation Loss : 0.4557221577689894\n",
            "                    \t     Training Accuracy : 0.8738523391812866\n",
            "                    \t     Validation Accuracy : 0.814806432748538\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.28855399693920125\n",
            "                    \t     Validation Loss : 0.4558737827219635\n",
            "                    \t     Training Accuracy : 0.8740697674418605\n",
            "                    \t     Validation Accuracy : 0.8147668604651163\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2878611373735021\n",
            "                    \t     Validation Loss : 0.4562187353531052\n",
            "                    \t     Training Accuracy : 0.874367774566474\n",
            "                    \t     Validation Accuracy : 0.8147682080924855\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2872340106152148\n",
            "                    \t     Validation Loss : 0.4566282479795374\n",
            "                    \t     Training Accuracy : 0.8747054597701149\n",
            "                    \t     Validation Accuracy : 0.814798275862069\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.28653614150429413\n",
            "                    \t     Validation Loss : 0.4567868177404705\n",
            "                    \t     Training Accuracy : 0.8750428571428571\n",
            "                    \t     Validation Accuracy : 0.8148451428571428\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.285502085908242\n",
            "                    \t     Validation Loss : 0.457648932145747\n",
            "                    \t     Training Accuracy : 0.8755326704545454\n",
            "                    \t     Validation Accuracy : 0.8148869318181818\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.28440353276960467\n",
            "                    \t     Validation Loss : 0.45873791905073047\n",
            "                    \t     Training Accuracy : 0.8760381355932203\n",
            "                    \t     Validation Accuracy : 0.8149316384180791\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.28342322113144136\n",
            "                    \t     Validation Loss : 0.4595976537230592\n",
            "                    \t     Training Accuracy : 0.8764782303370786\n",
            "                    \t     Validation Accuracy : 0.8149696629213483\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2823700970688616\n",
            "                    \t     Validation Loss : 0.46043499259598897\n",
            "                    \t     Training Accuracy : 0.8769797486033519\n",
            "                    \t     Validation Accuracy : 0.8149949720670391\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2814445893393519\n",
            "                    \t     Validation Loss : 0.4614044403526066\n",
            "                    \t     Training Accuracy : 0.8774340277777778\n",
            "                    \t     Validation Accuracy : 0.8150155555555556\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2806153248935341\n",
            "                    \t     Validation Loss : 0.46254296604339884\n",
            "                    \t     Training Accuracy : 0.8777935082872929\n",
            "                    \t     Validation Accuracy : 0.8150419889502762\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2796423750250999\n",
            "                    \t     Validation Loss : 0.46359200949060614\n",
            "                    \t     Training Accuracy : 0.8782554945054946\n",
            "                    \t     Validation Accuracy : 0.8150631868131868\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.27874291821041963\n",
            "                    \t     Validation Loss : 0.4641775295102133\n",
            "                    \t     Training Accuracy : 0.8786646174863388\n",
            "                    \t     Validation Accuracy : 0.8150622950819673\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2779058553083071\n",
            "                    \t     Validation Loss : 0.4645816175407012\n",
            "                    \t     Training Accuracy : 0.8790455163043478\n",
            "                    \t     Validation Accuracy : 0.815096195652174\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.27711881291433366\n",
            "                    \t     Validation Loss : 0.4655239472145278\n",
            "                    \t     Training Accuracy : 0.8793851351351352\n",
            "                    \t     Validation Accuracy : 0.8151194594594594\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.27636060129380435\n",
            "                    \t     Validation Loss : 0.46641625460126435\n",
            "                    \t     Training Accuracy : 0.879744623655914\n",
            "                    \t     Validation Accuracy : 0.815147311827957\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2755207301609537\n",
            "                    \t     Validation Loss : 0.4668463412089916\n",
            "                    \t     Training Accuracy : 0.8801236631016043\n",
            "                    \t     Validation Accuracy : 0.8151754010695187\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2747039771851826\n",
            "                    \t     Validation Loss : 0.46737761303621533\n",
            "                    \t     Training Accuracy : 0.8804853723404256\n",
            "                    \t     Validation Accuracy : 0.8151702127659575\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2739578336986797\n",
            "                    \t     Validation Loss : 0.4681253573864065\n",
            "                    \t     Training Accuracy : 0.8808267195767195\n",
            "                    \t     Validation Accuracy : 0.8152243386243386\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.27318698550496057\n",
            "                    \t     Validation Loss : 0.4687245219412515\n",
            "                    \t     Training Accuracy : 0.8811973684210527\n",
            "                    \t     Validation Accuracy : 0.8152194736842105\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2723895428004962\n",
            "                    \t     Validation Loss : 0.4696580822187969\n",
            "                    \t     Training Accuracy : 0.8815903141361257\n",
            "                    \t     Validation Accuracy : 0.8152397905759162\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.271686600894803\n",
            "                    \t     Validation Loss : 0.47031397891344445\n",
            "                    \t     Training Accuracy : 0.8819108072916667\n",
            "                    \t     Validation Accuracy : 0.8152354166666667\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.27100181792925443\n",
            "                    \t     Validation Loss : 0.4709654968130103\n",
            "                    \t     Training Accuracy : 0.8822247409326425\n",
            "                    \t     Validation Accuracy : 0.8152740932642487\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.27028078597125393\n",
            "                    \t     Validation Loss : 0.4718270990311047\n",
            "                    \t     Training Accuracy : 0.8825773195876289\n",
            "                    \t     Validation Accuracy : 0.8153149484536083\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.26963858216934095\n",
            "                    \t     Validation Loss : 0.47230135155300784\n",
            "                    \t     Training Accuracy : 0.8828878205128206\n",
            "                    \t     Validation Accuracy : 0.8152594871794872\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2689210814333578\n",
            "                    \t     Validation Loss : 0.4728414667111412\n",
            "                    \t     Training Accuracy : 0.8832206632653061\n",
            "                    \t     Validation Accuracy : 0.8153071428571429\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2681859020503985\n",
            "                    \t     Validation Loss : 0.4733670660632482\n",
            "                    \t     Training Accuracy : 0.8835850253807107\n",
            "                    \t     Validation Accuracy : 0.8153370558375634\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2676110103810112\n",
            "                    \t     Validation Loss : 0.473682514426373\n",
            "                    \t     Training Accuracy : 0.8838510101010101\n",
            "                    \t     Validation Accuracy : 0.8153550505050505\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2669154872974596\n",
            "                    \t     Validation Loss : 0.47457290506234256\n",
            "                    \t     Training Accuracy : 0.8841928391959799\n",
            "                    \t     Validation Accuracy : 0.8153884422110553\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.26623605764815583\n",
            "                    \t     Validation Loss : 0.4750542445782536\n",
            "                    \t     Training Accuracy : 0.884521875\n",
            "                    \t     Validation Accuracy : 0.815411\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.26536743840554833\n",
            "                    \t     Validation Loss : 0.4763771778571611\n",
            "                    \t     Training Accuracy : 0.8849440298507463\n",
            "                    \t     Validation Accuracy : 0.8154213930348259\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2645127215287141\n",
            "                    \t     Validation Loss : 0.4776081119369736\n",
            "                    \t     Training Accuracy : 0.885315594059406\n",
            "                    \t     Validation Accuracy : 0.815450495049505\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2637852181062066\n",
            "                    \t     Validation Loss : 0.4781174412661682\n",
            "                    \t     Training Accuracy : 0.8856681034482758\n",
            "                    \t     Validation Accuracy : 0.8154463054187192\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.26303707855342723\n",
            "                    \t     Validation Loss : 0.4786090498642188\n",
            "                    \t     Training Accuracy : 0.8860232843137255\n",
            "                    \t     Validation Accuracy : 0.8154299019607844\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.262230872584098\n",
            "                    \t     Validation Loss : 0.47997168896324005\n",
            "                    \t     Training Accuracy : 0.886405487804878\n",
            "                    \t     Validation Accuracy : 0.8154141463414634\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2614540370135993\n",
            "                    \t     Validation Loss : 0.4811164484866281\n",
            "                    \t     Training Accuracy : 0.8867779126213592\n",
            "                    \t     Validation Accuracy : 0.8154621359223301\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.26074442153279154\n",
            "                    \t     Validation Loss : 0.481774709665119\n",
            "                    \t     Training Accuracy : 0.8870923913043478\n",
            "                    \t     Validation Accuracy : 0.8155033816425121\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.26000604864017357\n",
            "                    \t     Validation Loss : 0.48278574266421304\n",
            "                    \t     Training Accuracy : 0.8874248798076924\n",
            "                    \t     Validation Accuracy : 0.8155153846153846\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2593421425093322\n",
            "                    \t     Validation Loss : 0.48314591791973766\n",
            "                    \t     Training Accuracy : 0.8877332535885167\n",
            "                    \t     Validation Accuracy : 0.8155354066985646\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2586413714346875\n",
            "                    \t     Validation Loss : 0.4836315252211029\n",
            "                    \t     Training Accuracy : 0.8880327380952381\n",
            "                    \t     Validation Accuracy : 0.8155733333333334\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2578102063034083\n",
            "                    \t     Validation Loss : 0.4881449586006891\n",
            "                    \t     Training Accuracy : 0.8884093601895735\n",
            "                    \t     Validation Accuracy : 0.81559336492891\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2572066473124004\n",
            "                    \t     Validation Loss : 0.48876761000933994\n",
            "                    \t     Training Accuracy : 0.8887057783018868\n",
            "                    \t     Validation Accuracy : 0.8156117924528302\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.25659102983095033\n",
            "                    \t     Validation Loss : 0.48913182927872134\n",
            "                    \t     Training Accuracy : 0.8890023474178403\n",
            "                    \t     Validation Accuracy : 0.815618309859155\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.25596799328057185\n",
            "                    \t     Validation Loss : 0.4897128484911487\n",
            "                    \t     Training Accuracy : 0.8893165887850467\n",
            "                    \t     Validation Accuracy : 0.8156457943925234\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2552506538795437\n",
            "                    \t     Validation Loss : 0.4899388465449935\n",
            "                    \t     Training Accuracy : 0.8896598837209302\n",
            "                    \t     Validation Accuracy : 0.8156637209302325\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.25454325376350123\n",
            "                    \t     Validation Loss : 0.4906605778570256\n",
            "                    \t     Training Accuracy : 0.8899768518518518\n",
            "                    \t     Validation Accuracy : 0.815687037037037\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.253906363214276\n",
            "                    \t     Validation Loss : 0.4910225498071509\n",
            "                    \t     Training Accuracy : 0.8902937788018433\n",
            "                    \t     Validation Accuracy : 0.815684331797235\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2532759977615259\n",
            "                    \t     Validation Loss : 0.49193667732467433\n",
            "                    \t     Training Accuracy : 0.8905905963302753\n",
            "                    \t     Validation Accuracy : 0.8157\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2526310519430123\n",
            "                    \t     Validation Loss : 0.4926874656659277\n",
            "                    \t     Training Accuracy : 0.8908932648401826\n",
            "                    \t     Validation Accuracy : 0.8156949771689498\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.25194326273140244\n",
            "                    \t     Validation Loss : 0.49365480531606476\n",
            "                    \t     Training Accuracy : 0.8912102272727273\n",
            "                    \t     Validation Accuracy : 0.8157090909090909\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2513727346395576\n",
            "                    \t     Validation Loss : 0.4940164877072724\n",
            "                    \t     Training Accuracy : 0.891447963800905\n",
            "                    \t     Validation Accuracy : 0.8157393665158371\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2507378585139071\n",
            "                    \t     Validation Loss : 0.49427231307099745\n",
            "                    \t     Training Accuracy : 0.8917454954954955\n",
            "                    \t     Validation Accuracy : 0.8157297297297297\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2500844630036052\n",
            "                    \t     Validation Loss : 0.49511126918541104\n",
            "                    \t     Training Accuracy : 0.8920403587443946\n",
            "                    \t     Validation Accuracy : 0.8157399103139014\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.24953206019767094\n",
            "                    \t     Validation Loss : 0.4955207017905866\n",
            "                    \t     Training Accuracy : 0.89232421875\n",
            "                    \t     Validation Accuracy : 0.8157848214285714\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2489310606043372\n",
            "                    \t     Validation Loss : 0.4958786081995605\n",
            "                    \t     Training Accuracy : 0.8925777777777778\n",
            "                    \t     Validation Accuracy : 0.8157991111111111\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24818276682930412\n",
            "                    \t     Validation Loss : 0.49638484162720187\n",
            "                    \t     Training Accuracy : 0.8929341814159292\n",
            "                    \t     Validation Accuracy : 0.8158261061946903\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24740826288562284\n",
            "                    \t     Validation Loss : 0.4975564029731324\n",
            "                    \t     Training Accuracy : 0.8932846916299559\n",
            "                    \t     Validation Accuracy : 0.8158334801762115\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24669815960781355\n",
            "                    \t     Validation Loss : 0.49883661478299846\n",
            "                    \t     Training Accuracy : 0.8936101973684211\n",
            "                    \t     Validation Accuracy : 0.8158456140350877\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2459085697179465\n",
            "                    \t     Validation Loss : 0.5003383992830016\n",
            "                    \t     Training Accuracy : 0.8939737991266375\n",
            "                    \t     Validation Accuracy : 0.815849344978166\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2452125269562087\n",
            "                    \t     Validation Loss : 0.5011332969681765\n",
            "                    \t     Training Accuracy : 0.8942989130434783\n",
            "                    \t     Validation Accuracy : 0.8158708695652174\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24452466446845852\n",
            "                    \t     Validation Loss : 0.5018609090402701\n",
            "                    \t     Training Accuracy : 0.8945968614718615\n",
            "                    \t     Validation Accuracy : 0.8158865800865801\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.243788466850669\n",
            "                    \t     Validation Loss : 0.5029206473682337\n",
            "                    \t     Training Accuracy : 0.894943426724138\n",
            "                    \t     Validation Accuracy : 0.8158974137931034\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2430696011129007\n",
            "                    \t     Validation Loss : 0.5042755824604236\n",
            "                    \t     Training Accuracy : 0.8952736051502146\n",
            "                    \t     Validation Accuracy : 0.815918025751073\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24243707202858505\n",
            "                    \t     Validation Loss : 0.5050265010787243\n",
            "                    \t     Training Accuracy : 0.8955582264957265\n",
            "                    \t     Validation Accuracy : 0.8159324786324786\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24185919447708876\n",
            "                    \t     Validation Loss : 0.5052782082063015\n",
            "                    \t     Training Accuracy : 0.8958457446808511\n",
            "                    \t     Validation Accuracy : 0.81594\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24129433455569196\n",
            "                    \t     Validation Loss : 0.5071437225341501\n",
            "                    \t     Training Accuracy : 0.8961467161016949\n",
            "                    \t     Validation Accuracy : 0.8159296610169492\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.24103712093423\n",
            "                    \t     Validation Loss : 0.5073573264941059\n",
            "                    \t     Training Accuracy : 0.8963396624472574\n",
            "                    \t     Validation Accuracy : 0.815931223628692\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2405328158145974\n",
            "                    \t     Validation Loss : 0.5081569196764464\n",
            "                    \t     Training Accuracy : 0.8965835084033613\n",
            "                    \t     Validation Accuracy : 0.8159567226890756\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2400197531020261\n",
            "                    \t     Validation Loss : 0.5087631132179986\n",
            "                    \t     Training Accuracy : 0.8968279288702928\n",
            "                    \t     Validation Accuracy : 0.8159769874476988\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.23953545845268914\n",
            "                    \t     Validation Loss : 0.5091100525807468\n",
            "                    \t     Training Accuracy : 0.8970494791666667\n",
            "                    \t     Validation Accuracy : 0.8159879166666667\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.23899097687406348\n",
            "                    \t     Validation Loss : 0.5097745091860433\n",
            "                    \t     Training Accuracy : 0.8973054979253112\n",
            "                    \t     Validation Accuracy : 0.8160070539419088\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.23844808965220987\n",
            "                    \t     Validation Loss : 0.5102693324842121\n",
            "                    \t     Training Accuracy : 0.8975594008264463\n",
            "                    \t     Validation Accuracy : 0.8160314049586777\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2378700025004829\n",
            "                    \t     Validation Loss : 0.5113428060570164\n",
            "                    \t     Training Accuracy : 0.8978163580246914\n",
            "                    \t     Validation Accuracy : 0.8160432098765432\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.23727114292487625\n",
            "                    \t     Validation Loss : 0.5122309435586119\n",
            "                    \t     Training Accuracy : 0.8980788934426229\n",
            "                    \t     Validation Accuracy : 0.8160389344262295\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2367437125879188\n",
            "                    \t     Validation Loss : 0.5125899073557003\n",
            "                    \t     Training Accuracy : 0.8983265306122449\n",
            "                    \t     Validation Accuracy : 0.8160595918367347\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.23616010575272273\n",
            "                    \t     Validation Loss : 0.5134539780759473\n",
            "                    \t     Training Accuracy : 0.8986255081300814\n",
            "                    \t     Validation Accuracy : 0.8160723577235772\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2355945690323199\n",
            "                    \t     Validation Loss : 0.5140591168867973\n",
            "                    \t     Training Accuracy : 0.8988790485829959\n",
            "                    \t     Validation Accuracy : 0.816074898785425\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.23503274671681743\n",
            "                    \t     Validation Loss : 0.5147910630949294\n",
            "                    \t     Training Accuracy : 0.8991431451612903\n",
            "                    \t     Validation Accuracy : 0.8160346774193549\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2345143158404796\n",
            "                    \t     Validation Loss : 0.5153073630421847\n",
            "                    \t     Training Accuracy : 0.8993674698795181\n",
            "                    \t     Validation Accuracy : 0.816052610441767\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2339652772224415\n",
            "                    \t     Validation Loss : 0.5154748800173402\n",
            "                    \t     Training Accuracy : 0.8996275\n",
            "                    \t     Validation Accuracy : 0.8160508\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.23330506537177328\n",
            "                    \t     Validation Loss : 0.5161922508868594\n",
            "                    \t     Training Accuracy : 0.8999402390438247\n",
            "                    \t     Validation Accuracy : 0.8160521912350598\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.23260425611074814\n",
            "                    \t     Validation Loss : 0.5176526155311503\n",
            "                    \t     Training Accuracy : 0.9002430555555555\n",
            "                    \t     Validation Accuracy : 0.8160674603174604\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.23199065535378058\n",
            "                    \t     Validation Loss : 0.5185323077327726\n",
            "                    \t     Training Accuracy : 0.9005088932806324\n",
            "                    \t     Validation Accuracy : 0.816095652173913\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.23129521327873317\n",
            "                    \t     Validation Loss : 0.5197203565523728\n",
            "                    \t     Training Accuracy : 0.9008169291338582\n",
            "                    \t     Validation Accuracy : 0.8160992125984252\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.23066386394618152\n",
            "                    \t     Validation Loss : 0.5204480449391994\n",
            "                    \t     Training Accuracy : 0.9010931372549019\n",
            "                    \t     Validation Accuracy : 0.8161227450980392\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2300326112563289\n",
            "                    \t     Validation Loss : 0.5213684007563707\n",
            "                    \t     Training Accuracy : 0.90136474609375\n",
            "                    \t     Validation Accuracy : 0.81613828125\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22944023103769398\n",
            "                    \t     Validation Loss : 0.5218215630494771\n",
            "                    \t     Training Accuracy : 0.9016293774319066\n",
            "                    \t     Validation Accuracy : 0.8161443579766537\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22886436348218767\n",
            "                    \t     Validation Loss : 0.5226993515263534\n",
            "                    \t     Training Accuracy : 0.9018798449612403\n",
            "                    \t     Validation Accuracy : 0.8161220930232558\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22832871982835873\n",
            "                    \t     Validation Loss : 0.5234702966190253\n",
            "                    \t     Training Accuracy : 0.9021066602316602\n",
            "                    \t     Validation Accuracy : 0.8161343629343629\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22769256110121316\n",
            "                    \t     Validation Loss : 0.524871154915167\n",
            "                    \t     Training Accuracy : 0.9023846153846153\n",
            "                    \t     Validation Accuracy : 0.8161376923076923\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22715572856870656\n",
            "                    \t     Validation Loss : 0.5252968184491252\n",
            "                    \t     Training Accuracy : 0.9026293103448276\n",
            "                    \t     Validation Accuracy : 0.8161574712643678\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22654644498350063\n",
            "                    \t     Validation Loss : 0.5265851907094193\n",
            "                    \t     Training Accuracy : 0.9029031488549618\n",
            "                    \t     Validation Accuracy : 0.8161286259541984\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22592952972771105\n",
            "                    \t     Validation Loss : 0.5275557521374238\n",
            "                    \t     Training Accuracy : 0.9031749049429658\n",
            "                    \t     Validation Accuracy : 0.816168060836502\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22535696113511222\n",
            "                    \t     Validation Loss : 0.528410303046994\n",
            "                    \t     Training Accuracy : 0.9034351325757576\n",
            "                    \t     Validation Accuracy : 0.8161689393939394\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22485157121332222\n",
            "                    \t     Validation Loss : 0.5292458763257486\n",
            "                    \t     Training Accuracy : 0.9036627358490567\n",
            "                    \t     Validation Accuracy : 0.8161796226415095\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22434130085128906\n",
            "                    \t     Validation Loss : 0.5305777380208759\n",
            "                    \t     Training Accuracy : 0.9038956766917293\n",
            "                    \t     Validation Accuracy : 0.8161898496240602\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22393297553077263\n",
            "                    \t     Validation Loss : 0.5314870802783352\n",
            "                    \t     Training Accuracy : 0.9040870786516854\n",
            "                    \t     Validation Accuracy : 0.8162063670411985\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22349062598775205\n",
            "                    \t     Validation Loss : 0.5316523006844268\n",
            "                    \t     Training Accuracy : 0.9043003731343283\n",
            "                    \t     Validation Accuracy : 0.8162194029850747\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22304364181687142\n",
            "                    \t     Validation Loss : 0.5318617255368971\n",
            "                    \t     Training Accuracy : 0.9045144052044609\n",
            "                    \t     Validation Accuracy : 0.8162074349442379\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22258523173405168\n",
            "                    \t     Validation Loss : 0.5325112922798166\n",
            "                    \t     Training Accuracy : 0.9047337962962962\n",
            "                    \t     Validation Accuracy : 0.8162025925925926\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22208270582094672\n",
            "                    \t     Validation Loss : 0.5330166914812611\n",
            "                    \t     Training Accuracy : 0.9049838560885609\n",
            "                    \t     Validation Accuracy : 0.8162103321033211\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2216167294261686\n",
            "                    \t     Validation Loss : 0.5334695644377694\n",
            "                    \t     Training Accuracy : 0.9052068014705882\n",
            "                    \t     Validation Accuracy : 0.8162154411764706\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22119248022181204\n",
            "                    \t     Validation Loss : 0.5337954632218607\n",
            "                    \t     Training Accuracy : 0.9053846153846153\n",
            "                    \t     Validation Accuracy : 0.8162307692307692\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.22077526347224777\n",
            "                    \t     Validation Loss : 0.5339892401581138\n",
            "                    \t     Training Accuracy : 0.9055679744525548\n",
            "                    \t     Validation Accuracy : 0.816257299270073\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2202668373912827\n",
            "                    \t     Validation Loss : 0.5351959512834584\n",
            "                    \t     Training Accuracy : 0.9058068181818182\n",
            "                    \t     Validation Accuracy : 0.8162734545454545\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21965788037631748\n",
            "                    \t     Validation Loss : 0.5367444953161054\n",
            "                    \t     Training Accuracy : 0.9060620471014493\n",
            "                    \t     Validation Accuracy : 0.8163014492753623\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2191263840646678\n",
            "                    \t     Validation Loss : 0.5373539662167596\n",
            "                    \t     Training Accuracy : 0.9063244584837545\n",
            "                    \t     Validation Accuracy : 0.8163108303249097\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21861677905972612\n",
            "                    \t     Validation Loss : 0.5379669327300811\n",
            "                    \t     Training Accuracy : 0.9065445143884892\n",
            "                    \t     Validation Accuracy : 0.816301798561151\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21820364930786318\n",
            "                    \t     Validation Loss : 0.5388094692352129\n",
            "                    \t     Training Accuracy : 0.9067540322580645\n",
            "                    \t     Validation Accuracy : 0.8163086021505377\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2176805956948665\n",
            "                    \t     Validation Loss : 0.5397803704107044\n",
            "                    \t     Training Accuracy : 0.9069977678571428\n",
            "                    \t     Validation Accuracy : 0.8163375\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21725688264326581\n",
            "                    \t     Validation Loss : 0.540771122794371\n",
            "                    \t     Training Accuracy : 0.9072064056939502\n",
            "                    \t     Validation Accuracy : 0.8163501779359431\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2167697521208716\n",
            "                    \t     Validation Loss : 0.5419913368667465\n",
            "                    \t     Training Accuracy : 0.9074290780141844\n",
            "                    \t     Validation Accuracy : 0.8163592198581561\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21631923329526914\n",
            "                    \t     Validation Loss : 0.5431306232579884\n",
            "                    \t     Training Accuracy : 0.9076590106007068\n",
            "                    \t     Validation Accuracy : 0.8163650176678445\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2158683125889273\n",
            "                    \t     Validation Loss : 0.5435484143468576\n",
            "                    \t     Training Accuracy : 0.9078785211267606\n",
            "                    \t     Validation Accuracy : 0.8163887323943662\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21533712407226854\n",
            "                    \t     Validation Loss : 0.5445780091574216\n",
            "                    \t     Training Accuracy : 0.9081118421052632\n",
            "                    \t     Validation Accuracy : 0.8164098245614035\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2148084437660303\n",
            "                    \t     Validation Loss : 0.5452875457736319\n",
            "                    \t     Training Accuracy : 0.9083457167832167\n",
            "                    \t     Validation Accuracy : 0.8164356643356644\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21432677041451229\n",
            "                    \t     Validation Loss : 0.5457993821184448\n",
            "                    \t     Training Accuracy : 0.908558362369338\n",
            "                    \t     Validation Accuracy : 0.8164585365853658\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21390179936706974\n",
            "                    \t     Validation Loss : 0.5463127968658248\n",
            "                    \t     Training Accuracy : 0.9087565104166667\n",
            "                    \t     Validation Accuracy : 0.8164649305555556\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21341989596437577\n",
            "                    \t     Validation Loss : 0.5471953525626737\n",
            "                    \t     Training Accuracy : 0.908981401384083\n",
            "                    \t     Validation Accuracy : 0.8164757785467128\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21290126575981186\n",
            "                    \t     Validation Loss : 0.5480213714355164\n",
            "                    \t     Training Accuracy : 0.9092176724137931\n",
            "                    \t     Validation Accuracy : 0.8164827586206896\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21240637764392686\n",
            "                    \t     Validation Loss : 0.5485358758608501\n",
            "                    \t     Training Accuracy : 0.909458762886598\n",
            "                    \t     Validation Accuracy : 0.8164941580756013\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21189757038102794\n",
            "                    \t     Validation Loss : 0.5494131161577386\n",
            "                    \t     Training Accuracy : 0.9096789383561644\n",
            "                    \t     Validation Accuracy : 0.8165054794520548\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2113879257944411\n",
            "                    \t     Validation Loss : 0.5503711414824453\n",
            "                    \t     Training Accuracy : 0.9098954778156997\n",
            "                    \t     Validation Accuracy : 0.8165204778156997\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2109252958014476\n",
            "                    \t     Validation Loss : 0.5510461168136057\n",
            "                    \t     Training Accuracy : 0.9100977891156462\n",
            "                    \t     Validation Accuracy : 0.8165299319727891\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.210512125541239\n",
            "                    \t     Validation Loss : 0.5518807069127191\n",
            "                    \t     Training Accuracy : 0.9103029661016949\n",
            "                    \t     Validation Accuracy : 0.8165047457627118\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.21006033265040133\n",
            "                    \t     Validation Loss : 0.5523828166580332\n",
            "                    \t     Training Accuracy : 0.9105004222972973\n",
            "                    \t     Validation Accuracy : 0.8165074324324324\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2095413704019946\n",
            "                    \t     Validation Loss : 0.5537308574546274\n",
            "                    \t     Training Accuracy : 0.9107323232323232\n",
            "                    \t     Validation Accuracy : 0.8164939393939394\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.209152945950557\n",
            "                    \t     Validation Loss : 0.5541608440677461\n",
            "                    \t     Training Accuracy : 0.9109249161073826\n",
            "                    \t     Validation Accuracy : 0.8164785234899329\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.20873995034798923\n",
            "                    \t     Validation Loss : 0.5542985397696958\n",
            "                    \t     Training Accuracy : 0.911128762541806\n",
            "                    \t     Validation Accuracy : 0.8164749163879599\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2082943799001087\n",
            "                    \t     Validation Loss : 0.5551358398823693\n",
            "                    \t     Training Accuracy : 0.9113270833333333\n",
            "                    \t     Validation Accuracy : 0.8164963333333334\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2077720724750369\n",
            "                    \t     Validation Loss : 0.5560997595853924\n",
            "                    \t     Training Accuracy : 0.91156146179402\n",
            "                    \t     Validation Accuracy : 0.8165139534883721\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20726568730120912\n",
            "                    \t     Validation Loss : 0.5569585401256963\n",
            "                    \t     Training Accuracy : 0.9117818708609271\n",
            "                    \t     Validation Accuracy : 0.8165182119205298\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20678959933867241\n",
            "                    \t     Validation Loss : 0.5578164896428828\n",
            "                    \t     Training Accuracy : 0.9119987623762377\n",
            "                    \t     Validation Accuracy : 0.8165392739273928\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20637083698638506\n",
            "                    \t     Validation Loss : 0.5580648991694852\n",
            "                    \t     Training Accuracy : 0.9122018914473684\n",
            "                    \t     Validation Accuracy : 0.8165496710526315\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20594767023178703\n",
            "                    \t     Validation Loss : 0.5585998632624111\n",
            "                    \t     Training Accuracy : 0.9123934426229509\n",
            "                    \t     Validation Accuracy : 0.8165540983606557\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20547744670998475\n",
            "                    \t     Validation Loss : 0.559503914638211\n",
            "                    \t     Training Accuracy : 0.912593954248366\n",
            "                    \t     Validation Accuracy : 0.816564705882353\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2050035621295304\n",
            "                    \t     Validation Loss : 0.5602782028677561\n",
            "                    \t     Training Accuracy : 0.9128094462540717\n",
            "                    \t     Validation Accuracy : 0.8165257328990227\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20455357583304687\n",
            "                    \t     Validation Loss : 0.5609800616931104\n",
            "                    \t     Training Accuracy : 0.9130133928571429\n",
            "                    \t     Validation Accuracy : 0.8165386363636363\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20410226662530984\n",
            "                    \t     Validation Loss : 0.562036567706037\n",
            "                    \t     Training Accuracy : 0.9132119741100324\n",
            "                    \t     Validation Accuracy : 0.8165491909385113\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20368831090294875\n",
            "                    \t     Validation Loss : 0.562550271306896\n",
            "                    \t     Training Accuracy : 0.9133891129032258\n",
            "                    \t     Validation Accuracy : 0.8165512903225807\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20327897736742057\n",
            "                    \t     Validation Loss : 0.5630769644647613\n",
            "                    \t     Training Accuracy : 0.913581189710611\n",
            "                    \t     Validation Accuracy : 0.8165498392282958\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20283731326430243\n",
            "                    \t     Validation Loss : 0.5639896722517953\n",
            "                    \t     Training Accuracy : 0.9137920673076924\n",
            "                    \t     Validation Accuracy : 0.8165490384615385\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20244970471308843\n",
            "                    \t     Validation Loss : 0.5647213905360426\n",
            "                    \t     Training Accuracy : 0.9139796325878594\n",
            "                    \t     Validation Accuracy : 0.816532268370607\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2020668462895904\n",
            "                    \t     Validation Loss : 0.5654195849406194\n",
            "                    \t     Training Accuracy : 0.9141620222929936\n",
            "                    \t     Validation Accuracy : 0.8165410828025478\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20165950981590394\n",
            "                    \t     Validation Loss : 0.5661460770989669\n",
            "                    \t     Training Accuracy : 0.914345238095238\n",
            "                    \t     Validation Accuracy : 0.8165393650793651\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20125597812669335\n",
            "                    \t     Validation Loss : 0.5666044567939501\n",
            "                    \t     Training Accuracy : 0.9145332278481013\n",
            "                    \t     Validation Accuracy : 0.8165503164556962\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20084824888654823\n",
            "                    \t     Validation Loss : 0.5669283381267075\n",
            "                    \t     Training Accuracy : 0.9147279179810726\n",
            "                    \t     Validation Accuracy : 0.8165372239747634\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20044962575248407\n",
            "                    \t     Validation Loss : 0.567472015332163\n",
            "                    \t     Training Accuracy : 0.9149095911949685\n",
            "                    \t     Validation Accuracy : 0.8165459119496855\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.20004890221725058\n",
            "                    \t     Validation Loss : 0.5678529474843959\n",
            "                    \t     Training Accuracy : 0.9150920846394984\n",
            "                    \t     Validation Accuracy : 0.8165539184952978\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.19964298460075952\n",
            "                    \t     Validation Loss : 0.5686538366279473\n",
            "                    \t     Training Accuracy : 0.91527734375\n",
            "                    \t     Validation Accuracy : 0.81656375\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.19924100482824036\n",
            "                    \t     Validation Loss : 0.5697768579831738\n",
            "                    \t     Training Accuracy : 0.9154614485981308\n",
            "                    \t     Validation Accuracy : 0.8165545171339564\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.19884463879738945\n",
            "                    \t     Validation Loss : 0.5701692021967044\n",
            "                    \t     Training Accuracy : 0.9156327639751553\n",
            "                    \t     Validation Accuracy : 0.8165624223602485\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.19846306180290954\n",
            "                    \t     Validation Loss : 0.5710188926827577\n",
            "                    \t     Training Accuracy : 0.9158184984520124\n",
            "                    \t     Validation Accuracy : 0.8165727554179567\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.19806675489653436\n",
            "                    \t     Validation Loss : 0.5713999088374647\n",
            "                    \t     Training Accuracy : 0.9160011574074074\n",
            "                    \t     Validation Accuracy : 0.8165629629629629\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.19768087246504684\n",
            "                    \t     Validation Loss : 0.5719180524114242\n",
            "                    \t     Training Accuracy : 0.9161730769230769\n",
            "                    \t     Validation Accuracy : 0.8165738461538462\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19718679059996053\n",
            "                    \t     Validation Loss : 0.5730817921237984\n",
            "                    \t     Training Accuracy : 0.9163784509202454\n",
            "                    \t     Validation Accuracy : 0.8165674846625767\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19674432635116845\n",
            "                    \t     Validation Loss : 0.5738761615296482\n",
            "                    \t     Training Accuracy : 0.9165863914373089\n",
            "                    \t     Validation Accuracy : 0.8165899082568807\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19628551895941376\n",
            "                    \t     Validation Loss : 0.5748328251069723\n",
            "                    \t     Training Accuracy : 0.9168006859756097\n",
            "                    \t     Validation Accuracy : 0.8165954268292683\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19584993705458834\n",
            "                    \t     Validation Loss : 0.5757103475318386\n",
            "                    \t     Training Accuracy : 0.9169984802431611\n",
            "                    \t     Validation Accuracy : 0.8165927051671733\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19543274930329416\n",
            "                    \t     Validation Loss : 0.5768080927834579\n",
            "                    \t     Training Accuracy : 0.9171761363636364\n",
            "                    \t     Validation Accuracy : 0.8165712121212121\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19509479495025314\n",
            "                    \t     Validation Loss : 0.577558749996482\n",
            "                    \t     Training Accuracy : 0.9173432779456193\n",
            "                    \t     Validation Accuracy : 0.8165839879154079\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1946503415651597\n",
            "                    \t     Validation Loss : 0.578389878629972\n",
            "                    \t     Training Accuracy : 0.9175357680722892\n",
            "                    \t     Validation Accuracy : 0.8165933734939759\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19422754081038132\n",
            "                    \t     Validation Loss : 0.5790591241308415\n",
            "                    \t     Training Accuracy : 0.9177252252252253\n",
            "                    \t     Validation Accuracy : 0.816606006006006\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19389645528963567\n",
            "                    \t     Validation Loss : 0.5794162627810393\n",
            "                    \t     Training Accuracy : 0.9178798652694611\n",
            "                    \t     Validation Accuracy : 0.8166266467065868\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19344810429232112\n",
            "                    \t     Validation Loss : 0.5802754071785918\n",
            "                    \t     Training Accuracy : 0.9180839552238806\n",
            "                    \t     Validation Accuracy : 0.8166388059701493\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1930677318062503\n",
            "                    \t     Validation Loss : 0.5808129950366115\n",
            "                    \t     Training Accuracy : 0.9182700892857143\n",
            "                    \t     Validation Accuracy : 0.81665\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19266611650025814\n",
            "                    \t     Validation Loss : 0.5815331800768219\n",
            "                    \t     Training Accuracy : 0.9184421364985164\n",
            "                    \t     Validation Accuracy : 0.8166596439169139\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19225642524431624\n",
            "                    \t     Validation Loss : 0.5826728746623769\n",
            "                    \t     Training Accuracy : 0.9186131656804734\n",
            "                    \t     Validation Accuracy : 0.8166781065088757\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1918409363106841\n",
            "                    \t     Validation Loss : 0.5831415835280898\n",
            "                    \t     Training Accuracy : 0.9187905604719764\n",
            "                    \t     Validation Accuracy : 0.8166873156342183\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19143798194378478\n",
            "                    \t     Validation Loss : 0.5834796628591475\n",
            "                    \t     Training Accuracy : 0.9189724264705882\n",
            "                    \t     Validation Accuracy : 0.816679705882353\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1910540824081193\n",
            "                    \t     Validation Loss : 0.5841788579201053\n",
            "                    \t     Training Accuracy : 0.9191477272727273\n",
            "                    \t     Validation Accuracy : 0.8166941348973608\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1907737336104922\n",
            "                    \t     Validation Loss : 0.5845048736645381\n",
            "                    \t     Training Accuracy : 0.9192964181286549\n",
            "                    \t     Validation Accuracy : 0.8166991228070175\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1904127533070549\n",
            "                    \t     Validation Loss : 0.5853359770824169\n",
            "                    \t     Training Accuracy : 0.9194569970845481\n",
            "                    \t     Validation Accuracy : 0.8167113702623907\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.19009211214979757\n",
            "                    \t     Validation Loss : 0.5855043077005584\n",
            "                    \t     Training Accuracy : 0.9196166424418605\n",
            "                    \t     Validation Accuracy : 0.8167171511627906\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1897422259447023\n",
            "                    \t     Validation Loss : 0.5862409137799468\n",
            "                    \t     Training Accuracy : 0.9197789855072463\n",
            "                    \t     Validation Accuracy : 0.8167147826086957\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.18939718520004004\n",
            "                    \t     Validation Loss : 0.5866285878267283\n",
            "                    \t     Training Accuracy : 0.9199295520231214\n",
            "                    \t     Validation Accuracy : 0.8167254335260116\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.18904487145019586\n",
            "                    \t     Validation Loss : 0.5872954514193232\n",
            "                    \t     Training Accuracy : 0.9200972622478386\n",
            "                    \t     Validation Accuracy : 0.8167432276657061\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.18870282599201021\n",
            "                    \t     Validation Loss : 0.5874746260680549\n",
            "                    \t     Training Accuracy : 0.9202568247126437\n",
            "                    \t     Validation Accuracy : 0.8167620689655173\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.18836255335925817\n",
            "                    \t     Validation Loss : 0.5878944564548632\n",
            "                    \t     Training Accuracy : 0.9204065186246418\n",
            "                    \t     Validation Accuracy : 0.8167845272206303\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.18796490626682727\n",
            "                    \t     Validation Loss : 0.5887255928480474\n",
            "                    \t     Training Accuracy : 0.920575\n",
            "                    \t     Validation Accuracy : 0.8167808571428572\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18752594253932195\n",
            "                    \t     Validation Loss : 0.5903448976410782\n",
            "                    \t     Training Accuracy : 0.9207674501424501\n",
            "                    \t     Validation Accuracy : 0.8167925925925926\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18714129081560466\n",
            "                    \t     Validation Loss : 0.5910326298220824\n",
            "                    \t     Training Accuracy : 0.920946377840909\n",
            "                    \t     Validation Accuracy : 0.8168096590909091\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1867309536532896\n",
            "                    \t     Validation Loss : 0.5917677922236317\n",
            "                    \t     Training Accuracy : 0.9211207507082153\n",
            "                    \t     Validation Accuracy : 0.8168206798866856\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18634093658767092\n",
            "                    \t     Validation Loss : 0.5925979588274108\n",
            "                    \t     Training Accuracy : 0.9212906073446328\n",
            "                    \t     Validation Accuracy : 0.8168299435028249\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18593617184605107\n",
            "                    \t     Validation Loss : 0.5935159853521127\n",
            "                    \t     Training Accuracy : 0.9214612676056338\n",
            "                    \t     Validation Accuracy : 0.8168476056338028\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1855452827421351\n",
            "                    \t     Validation Loss : 0.5945293246912403\n",
            "                    \t     Training Accuracy : 0.9216379915730337\n",
            "                    \t     Validation Accuracy : 0.8168662921348314\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18515467202525354\n",
            "                    \t     Validation Loss : 0.5952469877057089\n",
            "                    \t     Training Accuracy : 0.9218084733893558\n",
            "                    \t     Validation Accuracy : 0.8168742296918767\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18478495178550064\n",
            "                    \t     Validation Loss : 0.5962020773347242\n",
            "                    \t     Training Accuracy : 0.9219640363128492\n",
            "                    \t     Validation Accuracy : 0.8168807262569833\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18443417225587233\n",
            "                    \t     Validation Loss : 0.5968889710498794\n",
            "                    \t     Training Accuracy : 0.9221117688022284\n",
            "                    \t     Validation Accuracy : 0.8168788300835654\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18408052532587316\n",
            "                    \t     Validation Loss : 0.5977720211826083\n",
            "                    \t     Training Accuracy : 0.9222586805555556\n",
            "                    \t     Validation Accuracy : 0.8168569444444445\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18375038995749673\n",
            "                    \t     Validation Loss : 0.5983922668263011\n",
            "                    \t     Training Accuracy : 0.9223961218836565\n",
            "                    \t     Validation Accuracy : 0.8168573407202216\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1833978338252775\n",
            "                    \t     Validation Loss : 0.5990618345251345\n",
            "                    \t     Training Accuracy : 0.9225483425414365\n",
            "                    \t     Validation Accuracy : 0.8168798342541437\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18307744396625011\n",
            "                    \t     Validation Loss : 0.5993546062749845\n",
            "                    \t     Training Accuracy : 0.9226721763085399\n",
            "                    \t     Validation Accuracy : 0.8168895316804408\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1827836590408569\n",
            "                    \t     Validation Loss : 0.6002463901113436\n",
            "                    \t     Training Accuracy : 0.9228228021978022\n",
            "                    \t     Validation Accuracy : 0.8168431318681318\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18254489336269014\n",
            "                    \t     Validation Loss : 0.6006497421949352\n",
            "                    \t     Training Accuracy : 0.9229434931506849\n",
            "                    \t     Validation Accuracy : 0.8168460273972603\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18222854199105826\n",
            "                    \t     Validation Loss : 0.6012288206177885\n",
            "                    \t     Training Accuracy : 0.9230908469945355\n",
            "                    \t     Validation Accuracy : 0.8168650273224044\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18186733706053967\n",
            "                    \t     Validation Loss : 0.6021060700928824\n",
            "                    \t     Training Accuracy : 0.9232510217983652\n",
            "                    \t     Validation Accuracy : 0.816882833787466\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18156725227098555\n",
            "                    \t     Validation Loss : 0.6028549361298985\n",
            "                    \t     Training Accuracy : 0.9233984375\n",
            "                    \t     Validation Accuracy : 0.8168660326086956\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1812122981155892\n",
            "                    \t     Validation Loss : 0.6038513282763615\n",
            "                    \t     Training Accuracy : 0.9235518292682927\n",
            "                    \t     Validation Accuracy : 0.816879132791328\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18091986712317512\n",
            "                    \t     Validation Loss : 0.6045252338651455\n",
            "                    \t     Training Accuracy : 0.9236773648648648\n",
            "                    \t     Validation Accuracy : 0.8168905405405406\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.18061288298604097\n",
            "                    \t     Validation Loss : 0.605020513272097\n",
            "                    \t     Training Accuracy : 0.9238224393530997\n",
            "                    \t     Validation Accuracy : 0.8169150943396226\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1803379069111668\n",
            "                    \t     Validation Loss : 0.6054080155766426\n",
            "                    \t     Training Accuracy : 0.9239532930107527\n",
            "                    \t     Validation Accuracy : 0.8169301075268817\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1800508090919483\n",
            "                    \t     Validation Loss : 0.6059155591745324\n",
            "                    \t     Training Accuracy : 0.9240951742627346\n",
            "                    \t     Validation Accuracy : 0.8169391420911528\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.17981064636867872\n",
            "                    \t     Validation Loss : 0.6060664878396\n",
            "                    \t     Training Accuracy : 0.9242078877005347\n",
            "                    \t     Validation Accuracy : 0.8169323529411765\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.17959475763107338\n",
            "                    \t     Validation Loss : 0.6067370107027983\n",
            "                    \t     Training Accuracy : 0.9243016666666667\n",
            "                    \t     Validation Accuracy : 0.8169490666666667\n",
            "                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ShuffleNet"
      ],
      "metadata": {
        "id": "y1cdrkMr_3Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.86 was the accuracy of ShuffleNet in the paper but here we have 0.81:"
      ],
      "metadata": {
        "id": "etdBpF4ancaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('shufflenet')\n",
        "\n",
        "optimizer = optim.Adam([{'params': model.feature_extractor.parameters()},\n",
        "    {'params': model.conv_auto_encoder.parameters(), 'lr' : learning_rates[str(model.name)]['CAE LR']},\n",
        "    {'params': model.classifier.parameters(), 'lr' : learning_rates[str(model.name)]['LC LR']}],\n",
        "    lr=0.0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_and_evaluate()"
      ],
      "metadata": {
        "id": "cdd0GJuR_56k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6721572-e9dd-476f-f71f-9b4b43b61ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.8882088911533356\n",
            "                    \t     Validation Loss : 0.6747247121585443\n",
            "                    \t     Training Accuracy : 0.5425\n",
            "                    \t     Validation Accuracy : 0.5384\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7437540575861931\n",
            "                    \t     Validation Loss : 0.6080252870012777\n",
            "                    \t     Training Accuracy : 0.6115625\n",
            "                    \t     Validation Accuracy : 0.631\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6849273810784022\n",
            "                    \t     Validation Loss : 0.57348513301696\n",
            "                    \t     Training Accuracy : 0.6435416666666667\n",
            "                    \t     Validation Accuracy : 0.6717\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6462773324549198\n",
            "                    \t     Validation Loss : 0.5476663155963246\n",
            "                    \t     Training Accuracy : 0.66875\n",
            "                    \t     Validation Accuracy : 0.697175\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6136723376512527\n",
            "                    \t     Validation Loss : 0.5350040378566748\n",
            "                    \t     Training Accuracy : 0.688625\n",
            "                    \t     Validation Accuracy : 0.71198\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5927678335706393\n",
            "                    \t     Validation Loss : 0.5253028789410195\n",
            "                    \t     Training Accuracy : 0.6998958333333334\n",
            "                    \t     Validation Accuracy : 0.7221\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5767278643165316\n",
            "                    \t     Validation Loss : 0.5143146935947297\n",
            "                    \t     Training Accuracy : 0.71\n",
            "                    \t     Validation Accuracy : 0.7322428571428572\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5599449375271797\n",
            "                    \t     Validation Loss : 0.5044288316283363\n",
            "                    \t     Training Accuracy : 0.721484375\n",
            "                    \t     Validation Accuracy : 0.740875\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5463201515542137\n",
            "                    \t     Validation Loss : 0.4988066601200987\n",
            "                    \t     Training Accuracy : 0.729375\n",
            "                    \t     Validation Accuracy : 0.7466777777777778\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5357506990730763\n",
            "                    \t     Validation Loss : 0.49480944061146\n",
            "                    \t     Training Accuracy : 0.7350625\n",
            "                    \t     Validation Accuracy : 0.75129\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5280738180333918\n",
            "                    \t     Validation Loss : 0.49081172944067386\n",
            "                    \t     Training Accuracy : 0.7408522727272727\n",
            "                    \t     Validation Accuracy : 0.7550181818181818\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.522068136036396\n",
            "                    \t     Validation Loss : 0.4857763022589036\n",
            "                    \t     Training Accuracy : 0.7455208333333333\n",
            "                    \t     Validation Accuracy : 0.7589\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5179953568256819\n",
            "                    \t     Validation Loss : 0.4809539576080983\n",
            "                    \t     Training Accuracy : 0.7479326923076923\n",
            "                    \t     Validation Accuracy : 0.7627384615384616\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5131427012171064\n",
            "                    \t     Validation Loss : 0.4775389078366925\n",
            "                    \t     Training Accuracy : 0.7507589285714286\n",
            "                    \t     Validation Accuracy : 0.7655214285714286\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5067401693662008\n",
            "                    \t     Validation Loss : 0.475165226719123\n",
            "                    \t     Training Accuracy : 0.7550416666666667\n",
            "                    \t     Validation Accuracy : 0.7676133333333334\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.502257562186569\n",
            "                    \t     Validation Loss : 0.4716949181381268\n",
            "                    \t     Training Accuracy : 0.7578515625\n",
            "                    \t     Validation Accuracy : 0.7701625\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.49763725811944287\n",
            "                    \t     Validation Loss : 0.4679547891796498\n",
            "                    \t     Training Accuracy : 0.7617647058823529\n",
            "                    \t     Validation Accuracy : 0.7726235294117647\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4939538323382537\n",
            "                    \t     Validation Loss : 0.46544219892806604\n",
            "                    \t     Training Accuracy : 0.7643402777777778\n",
            "                    \t     Validation Accuracy : 0.7750277777777778\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.49077611852633324\n",
            "                    \t     Validation Loss : 0.46322291550244205\n",
            "                    \t     Training Accuracy : 0.7666118421052631\n",
            "                    \t     Validation Accuracy : 0.7766947368421052\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4879790064245462\n",
            "                    \t     Validation Loss : 0.4610923325696502\n",
            "                    \t     Training Accuracy : 0.7683125\n",
            "                    \t     Validation Accuracy : 0.778435\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4855699954572178\n",
            "                    \t     Validation Loss : 0.45995488884141417\n",
            "                    \t     Training Accuracy : 0.7700297619047619\n",
            "                    \t     Validation Accuracy : 0.7793857142857142\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4834905902499502\n",
            "                    \t     Validation Loss : 0.45832082651059985\n",
            "                    \t     Training Accuracy : 0.771875\n",
            "                    \t     Validation Accuracy : 0.7803909090909091\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.48007913183906803\n",
            "                    \t     Validation Loss : 0.4561675905535529\n",
            "                    \t     Training Accuracy : 0.7742934782608696\n",
            "                    \t     Validation Accuracy : 0.7819173913043478\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4763296848659714\n",
            "                    \t     Validation Loss : 0.45501494421936073\n",
            "                    \t     Training Accuracy : 0.776640625\n",
            "                    \t     Validation Accuracy : 0.7831\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4733790867209435\n",
            "                    \t     Validation Loss : 0.4533184857928334\n",
            "                    \t     Training Accuracy : 0.77855\n",
            "                    \t     Validation Accuracy : 0.78426\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.46911937796152553\n",
            "                    \t     Validation Loss : 0.452024688626074\n",
            "                    \t     Training Accuracy : 0.7812259615384616\n",
            "                    \t     Validation Accuracy : 0.7853461538461538\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.46622417080733514\n",
            "                    \t     Validation Loss : 0.45161374546292127\n",
            "                    \t     Training Accuracy : 0.7828703703703703\n",
            "                    \t     Validation Accuracy : 0.7857888888888889\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.463476811312139\n",
            "                    \t     Validation Loss : 0.4506549772006064\n",
            "                    \t     Training Accuracy : 0.78453125\n",
            "                    \t     Validation Accuracy : 0.7867571428571428\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.45964522569343963\n",
            "                    \t     Validation Loss : 0.4492386049658004\n",
            "                    \t     Training Accuracy : 0.7868534482758621\n",
            "                    \t     Validation Accuracy : 0.7877241379310345\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4581673754751682\n",
            "                    \t     Validation Loss : 0.44819256281351255\n",
            "                    \t     Training Accuracy : 0.7877291666666667\n",
            "                    \t     Validation Accuracy : 0.78844\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4559561454096148\n",
            "                    \t     Validation Loss : 0.4469756674553996\n",
            "                    \t     Training Accuracy : 0.7889112903225807\n",
            "                    \t     Validation Accuracy : 0.7891774193548388\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.45352032927796243\n",
            "                    \t     Validation Loss : 0.4470135395551999\n",
            "                    \t     Training Accuracy : 0.79015625\n",
            "                    \t     Validation Accuracy : 0.789653125\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4515300728154905\n",
            "                    \t     Validation Loss : 0.44682140469908865\n",
            "                    \t     Training Accuracy : 0.7914583333333334\n",
            "                    \t     Validation Accuracy : 0.7900575757575757\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.45018911543137885\n",
            "                    \t     Validation Loss : 0.4456230424382346\n",
            "                    \t     Training Accuracy : 0.7922058823529412\n",
            "                    \t     Validation Accuracy : 0.7907323529411765\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4488434103982789\n",
            "                    \t     Validation Loss : 0.4447789649830622\n",
            "                    \t     Training Accuracy : 0.7928571428571428\n",
            "                    \t     Validation Accuracy : 0.79122\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4469975847005844\n",
            "                    \t     Validation Loss : 0.4434919296758878\n",
            "                    \t     Training Accuracy : 0.7936979166666667\n",
            "                    \t     Validation Accuracy : 0.7920722222222222\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44544495162931647\n",
            "                    \t     Validation Loss : 0.44247688483532077\n",
            "                    \t     Training Accuracy : 0.7944425675675676\n",
            "                    \t     Validation Accuracy : 0.7927243243243243\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4442510264013943\n",
            "                    \t     Validation Loss : 0.4412953148865191\n",
            "                    \t     Training Accuracy : 0.7950986842105263\n",
            "                    \t     Validation Accuracy : 0.7932684210526316\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.442554869781702\n",
            "                    \t     Validation Loss : 0.4399980634897691\n",
            "                    \t     Training Accuracy : 0.7961057692307693\n",
            "                    \t     Validation Accuracy : 0.7940666666666667\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44170401769131423\n",
            "                    \t     Validation Loss : 0.43909874118793124\n",
            "                    \t     Training Accuracy : 0.796578125\n",
            "                    \t     Validation Accuracy : 0.7946475\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44003648787736893\n",
            "                    \t     Validation Loss : 0.4382054492196076\n",
            "                    \t     Training Accuracy : 0.7975609756097561\n",
            "                    \t     Validation Accuracy : 0.7953658536585366\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4387659392541363\n",
            "                    \t     Validation Loss : 0.4375987952586706\n",
            "                    \t     Training Accuracy : 0.7984375\n",
            "                    \t     Validation Accuracy : 0.7960047619047619\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43728475528400995\n",
            "                    \t     Validation Loss : 0.4377827283892609\n",
            "                    \t     Training Accuracy : 0.7995639534883721\n",
            "                    \t     Validation Accuracy : 0.7963116279069767\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43693765027956527\n",
            "                    \t     Validation Loss : 0.4370341571894559\n",
            "                    \t     Training Accuracy : 0.8000284090909091\n",
            "                    \t     Validation Accuracy : 0.7966613636363636\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43594783091545103\n",
            "                    \t     Validation Loss : 0.43609590492838446\n",
            "                    \t     Training Accuracy : 0.8007916666666667\n",
            "                    \t     Validation Accuracy : 0.7972488888888889\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4344835946287798\n",
            "                    \t     Validation Loss : 0.43552812038279026\n",
            "                    \t     Training Accuracy : 0.8016032608695652\n",
            "                    \t     Validation Accuracy : 0.7976347826086957\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43330919265112977\n",
            "                    \t     Validation Loss : 0.4347109954983217\n",
            "                    \t     Training Accuracy : 0.802220744680851\n",
            "                    \t     Validation Accuracy : 0.7981914893617021\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43231516835590206\n",
            "                    \t     Validation Loss : 0.4346044598260341\n",
            "                    \t     Training Accuracy : 0.8025651041666667\n",
            "                    \t     Validation Accuracy : 0.7983875\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4316069603331235\n",
            "                    \t     Validation Loss : 0.43374788565947986\n",
            "                    \t     Training Accuracy : 0.8031122448979592\n",
            "                    \t     Validation Accuracy : 0.7989224489795919\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4309111106336117\n",
            "                    \t     Validation Loss : 0.4332927436512499\n",
            "                    \t     Training Accuracy : 0.80335\n",
            "                    \t     Validation Accuracy : 0.7993\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4289596602320671\n",
            "                    \t     Validation Loss : 0.4329082581816644\n",
            "                    \t     Training Accuracy : 0.8045098039215687\n",
            "                    \t     Validation Accuracy : 0.7996529411764706\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4270860534849075\n",
            "                    \t     Validation Loss : 0.43265153069949086\n",
            "                    \t     Training Accuracy : 0.8053365384615384\n",
            "                    \t     Validation Accuracy : 0.8000442307692308\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.42551015278078475\n",
            "                    \t     Validation Loss : 0.4321675050613627\n",
            "                    \t     Training Accuracy : 0.8061556603773585\n",
            "                    \t     Validation Accuracy : 0.8004415094339623\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4246689016675508\n",
            "                    \t     Validation Loss : 0.43199499301350536\n",
            "                    \t     Training Accuracy : 0.8067592592592593\n",
            "                    \t     Validation Accuracy : 0.8005148148148148\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.42329825234142215\n",
            "                    \t     Validation Loss : 0.43152390167424404\n",
            "                    \t     Training Accuracy : 0.8077613636363636\n",
            "                    \t     Validation Accuracy : 0.8008690909090909\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.42177744897614633\n",
            "                    \t     Validation Loss : 0.4310831936923868\n",
            "                    \t     Training Accuracy : 0.8085491071428571\n",
            "                    \t     Validation Accuracy : 0.8011482142857143\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.42097652255704526\n",
            "                    \t     Validation Loss : 0.43028561650059644\n",
            "                    \t     Training Accuracy : 0.8090131578947368\n",
            "                    \t     Validation Accuracy : 0.8016543859649122\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41980660878635684\n",
            "                    \t     Validation Loss : 0.42985113128696334\n",
            "                    \t     Training Accuracy : 0.809676724137931\n",
            "                    \t     Validation Accuracy : 0.8019706896551724\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4189106866540545\n",
            "                    \t     Validation Loss : 0.42956996524205493\n",
            "                    \t     Training Accuracy : 0.8102330508474577\n",
            "                    \t     Validation Accuracy : 0.8023949152542373\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4178425562630097\n",
            "                    \t     Validation Loss : 0.4291540683482211\n",
            "                    \t     Training Accuracy : 0.8107916666666667\n",
            "                    \t     Validation Accuracy : 0.8026883333333333\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41728138418959787\n",
            "                    \t     Validation Loss : 0.42875662656821995\n",
            "                    \t     Training Accuracy : 0.8111065573770492\n",
            "                    \t     Validation Accuracy : 0.8029475409836065\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4164453763154245\n",
            "                    \t     Validation Loss : 0.4283001671811944\n",
            "                    \t     Training Accuracy : 0.8117137096774194\n",
            "                    \t     Validation Accuracy : 0.8033387096774194\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4160399014467285\n",
            "                    \t     Validation Loss : 0.42787169106578576\n",
            "                    \t     Training Accuracy : 0.8120734126984127\n",
            "                    \t     Validation Accuracy : 0.8035523809523809\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4150766004435718\n",
            "                    \t     Validation Loss : 0.4273837341145187\n",
            "                    \t     Training Accuracy : 0.812509765625\n",
            "                    \t     Validation Accuracy : 0.8038546875\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41450998164598757\n",
            "                    \t     Validation Loss : 0.4268170468485393\n",
            "                    \t     Training Accuracy : 0.812923076923077\n",
            "                    \t     Validation Accuracy : 0.8042261538461538\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41355149502103977\n",
            "                    \t     Validation Loss : 0.4263275956078788\n",
            "                    \t     Training Accuracy : 0.8134185606060607\n",
            "                    \t     Validation Accuracy : 0.8045333333333333\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4128186751257128\n",
            "                    \t     Validation Loss : 0.4260922173934941\n",
            "                    \t     Training Accuracy : 0.8138339552238806\n",
            "                    \t     Validation Accuracy : 0.8047626865671642\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41196906056474236\n",
            "                    \t     Validation Loss : 0.42575804293232683\n",
            "                    \t     Training Accuracy : 0.8143106617647059\n",
            "                    \t     Validation Accuracy : 0.8049220588235294\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4115445725814156\n",
            "                    \t     Validation Loss : 0.4253563102644014\n",
            "                    \t     Training Accuracy : 0.8145380434782609\n",
            "                    \t     Validation Accuracy : 0.8051478260869566\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4109498855982508\n",
            "                    \t     Validation Loss : 0.4248627568256333\n",
            "                    \t     Training Accuracy : 0.8150267857142857\n",
            "                    \t     Validation Accuracy : 0.8054228571428571\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40986792434689023\n",
            "                    \t     Validation Loss : 0.4244644592669466\n",
            "                    \t     Training Accuracy : 0.8156073943661972\n",
            "                    \t     Validation Accuracy : 0.8056690140845071\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40906714556945695\n",
            "                    \t     Validation Loss : 0.4240690350633698\n",
            "                    \t     Training Accuracy : 0.816015625\n",
            "                    \t     Validation Accuracy : 0.8058944444444445\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4081741650259658\n",
            "                    \t     Validation Loss : 0.4239177201646747\n",
            "                    \t     Training Accuracy : 0.8165410958904109\n",
            "                    \t     Validation Accuracy : 0.8061123287671232\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.408053434567677\n",
            "                    \t     Validation Loss : 0.42374427209133547\n",
            "                    \t     Training Accuracy : 0.8166131756756757\n",
            "                    \t     Validation Accuracy : 0.8062405405405405\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40768902503649396\n",
            "                    \t     Validation Loss : 0.4234802515346148\n",
            "                    \t     Training Accuracy : 0.816725\n",
            "                    \t     Validation Accuracy : 0.8062306666666667\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.40686519475751803\n",
            "                    \t     Validation Loss : 0.4232021733158167\n",
            "                    \t     Training Accuracy : 0.8171381578947369\n",
            "                    \t     Validation Accuracy : 0.806396052631579\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4059793068894318\n",
            "                    \t     Validation Loss : 0.4231831797642345\n",
            "                    \t     Training Accuracy : 0.8176461038961039\n",
            "                    \t     Validation Accuracy : 0.8064883116883117\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.40469641260420663\n",
            "                    \t     Validation Loss : 0.4232205099517687\n",
            "                    \t     Training Accuracy : 0.8183173076923077\n",
            "                    \t     Validation Accuracy : 0.8065076923076923\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4034903551864473\n",
            "                    \t     Validation Loss : 0.42330613723147886\n",
            "                    \t     Training Accuracy : 0.8190189873417721\n",
            "                    \t     Validation Accuracy : 0.8066316455696203\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.402919612115249\n",
            "                    \t     Validation Loss : 0.42329289340042175\n",
            "                    \t     Training Accuracy : 0.8193671875\n",
            "                    \t     Validation Accuracy : 0.8067825\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.40194367973340883\n",
            "                    \t     Validation Loss : 0.42298050210028576\n",
            "                    \t     Training Accuracy : 0.8200771604938272\n",
            "                    \t     Validation Accuracy : 0.8069814814814815\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.4007612510806904\n",
            "                    \t     Validation Loss : 0.4228460283651408\n",
            "                    \t     Training Accuracy : 0.8206021341463414\n",
            "                    \t     Validation Accuracy : 0.8071073170731707\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39984073203909826\n",
            "                    \t     Validation Loss : 0.42263472231370325\n",
            "                    \t     Training Accuracy : 0.8210993975903614\n",
            "                    \t     Validation Accuracy : 0.8072409638554217\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3989871844738012\n",
            "                    \t     Validation Loss : 0.4224193854753093\n",
            "                    \t     Training Accuracy : 0.8215401785714286\n",
            "                    \t     Validation Accuracy : 0.8074178571428572\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3979996581673622\n",
            "                    \t     Validation Loss : 0.42210396056537275\n",
            "                    \t     Training Accuracy : 0.8221029411764705\n",
            "                    \t     Validation Accuracy : 0.8075658823529411\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3974196050437384\n",
            "                    \t     Validation Loss : 0.4218643082543688\n",
            "                    \t     Training Accuracy : 0.8225\n",
            "                    \t     Validation Accuracy : 0.8077860465116279\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39700541873430384\n",
            "                    \t     Validation Loss : 0.4216758501484932\n",
            "                    \t     Training Accuracy : 0.8228232758620689\n",
            "                    \t     Validation Accuracy : 0.8078977011494253\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39641681454737077\n",
            "                    \t     Validation Loss : 0.42139996884424796\n",
            "                    \t     Training Accuracy : 0.8231107954545455\n",
            "                    \t     Validation Accuracy : 0.8080795454545454\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39577586527955666\n",
            "                    \t     Validation Loss : 0.4213867214759331\n",
            "                    \t     Training Accuracy : 0.8234620786516854\n",
            "                    \t     Validation Accuracy : 0.8082\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39512378924091657\n",
            "                    \t     Validation Loss : 0.4212155701866969\n",
            "                    \t     Training Accuracy : 0.8237847222222222\n",
            "                    \t     Validation Accuracy : 0.8083777777777778\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39451766840049196\n",
            "                    \t     Validation Loss : 0.4209238271288577\n",
            "                    \t     Training Accuracy : 0.8240453296703296\n",
            "                    \t     Validation Accuracy : 0.808565934065934\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.394012267343376\n",
            "                    \t     Validation Loss : 0.4206617901574938\n",
            "                    \t     Training Accuracy : 0.8242730978260869\n",
            "                    \t     Validation Accuracy : 0.8087521739130434\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39329424112073835\n",
            "                    \t     Validation Loss : 0.42057608158085347\n",
            "                    \t     Training Accuracy : 0.8247177419354839\n",
            "                    \t     Validation Accuracy : 0.8088763440860215\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3928003623891384\n",
            "                    \t     Validation Loss : 0.4204200076714313\n",
            "                    \t     Training Accuracy : 0.8249335106382979\n",
            "                    \t     Validation Accuracy : 0.8090010638297872\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3925047127479001\n",
            "                    \t     Validation Loss : 0.42013078015532557\n",
            "                    \t     Training Accuracy : 0.8250657894736843\n",
            "                    \t     Validation Accuracy : 0.8091168421052631\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3922120537577818\n",
            "                    \t     Validation Loss : 0.41994500759675607\n",
            "                    \t     Training Accuracy : 0.8253645833333333\n",
            "                    \t     Validation Accuracy : 0.80926875\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3915832014366524\n",
            "                    \t     Validation Loss : 0.41978188619944723\n",
            "                    \t     Training Accuracy : 0.8257280927835051\n",
            "                    \t     Validation Accuracy : 0.8093546391752577\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3913127912428914\n",
            "                    \t     Validation Loss : 0.4194785631800083\n",
            "                    \t     Training Accuracy : 0.8257397959183673\n",
            "                    \t     Validation Accuracy : 0.809480612244898\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39123147738401337\n",
            "                    \t     Validation Loss : 0.41921235657330347\n",
            "                    \t     Training Accuracy : 0.8258207070707071\n",
            "                    \t     Validation Accuracy : 0.8096222222222222\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.39082341074943544\n",
            "                    \t     Validation Loss : 0.4192989089613715\n",
            "                    \t     Training Accuracy : 0.826025\n",
            "                    \t     Validation Accuracy : 0.809658\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.38983024331455185\n",
            "                    \t     Validation Loss : 0.41976507125751195\n",
            "                    \t     Training Accuracy : 0.8264789603960396\n",
            "                    \t     Validation Accuracy : 0.8097188118811881\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.38872063772058957\n",
            "                    \t     Validation Loss : 0.4199281123403838\n",
            "                    \t     Training Accuracy : 0.8269852941176471\n",
            "                    \t     Validation Accuracy : 0.8096911764705882\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3877463983303135\n",
            "                    \t     Validation Loss : 0.42005487520191886\n",
            "                    \t     Training Accuracy : 0.8275060679611651\n",
            "                    \t     Validation Accuracy : 0.8097504854368932\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3869920245156838\n",
            "                    \t     Validation Loss : 0.42081749673477775\n",
            "                    \t     Training Accuracy : 0.8279146634615384\n",
            "                    \t     Validation Accuracy : 0.8098403846153847\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.38618543377092907\n",
            "                    \t     Validation Loss : 0.42104106213714404\n",
            "                    \t     Training Accuracy : 0.8283154761904762\n",
            "                    \t     Validation Accuracy : 0.8098552380952381\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3853530696245297\n",
            "                    \t     Validation Loss : 0.4211913408684942\n",
            "                    \t     Training Accuracy : 0.8288089622641509\n",
            "                    \t     Validation Accuracy : 0.8099066037735849\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3846575893795936\n",
            "                    \t     Validation Loss : 0.42153688895024644\n",
            "                    \t     Training Accuracy : 0.8291063084112149\n",
            "                    \t     Validation Accuracy : 0.8099373831775701\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3839678153961345\n",
            "                    \t     Validation Loss : 0.422281641580994\n",
            "                    \t     Training Accuracy : 0.8294675925925926\n",
            "                    \t     Validation Accuracy : 0.8098074074074074\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3831778318769888\n",
            "                    \t     Validation Loss : 0.42218809521709816\n",
            "                    \t     Training Accuracy : 0.8298337155963302\n",
            "                    \t     Validation Accuracy : 0.8098761467889908\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.38255126168646597\n",
            "                    \t     Validation Loss : 0.42233254905100864\n",
            "                    \t     Training Accuracy : 0.8302386363636364\n",
            "                    \t     Validation Accuracy : 0.8097990909090909\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3819666022585856\n",
            "                    \t     Validation Loss : 0.4222559527716852\n",
            "                    \t     Training Accuracy : 0.830563063063063\n",
            "                    \t     Validation Accuracy : 0.8097954954954955\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3813763491716236\n",
            "                    \t     Validation Loss : 0.4221762958072408\n",
            "                    \t     Training Accuracy : 0.8309933035714285\n",
            "                    \t     Validation Accuracy : 0.8099258928571429\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.38066495685187063\n",
            "                    \t     Validation Loss : 0.42226743755628343\n",
            "                    \t     Training Accuracy : 0.8314214601769911\n",
            "                    \t     Validation Accuracy : 0.8100070796460177\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3800568476580737\n",
            "                    \t     Validation Loss : 0.42209289430382607\n",
            "                    \t     Training Accuracy : 0.8317763157894736\n",
            "                    \t     Validation Accuracy : 0.8100570175438596\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3795430126371591\n",
            "                    \t     Validation Loss : 0.4222251941313974\n",
            "                    \t     Training Accuracy : 0.8318913043478261\n",
            "                    \t     Validation Accuracy : 0.8101513043478261\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3789680542694084\n",
            "                    \t     Validation Loss : 0.4222742131153704\n",
            "                    \t     Training Accuracy : 0.8321605603448275\n",
            "                    \t     Validation Accuracy : 0.8102689655172414\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3786742023907156\n",
            "                    \t     Validation Loss : 0.4221005468601555\n",
            "                    \t     Training Accuracy : 0.8323076923076923\n",
            "                    \t     Validation Accuracy : 0.8102803418803419\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3781753425502171\n",
            "                    \t     Validation Loss : 0.4219701508453566\n",
            "                    \t     Training Accuracy : 0.8325158898305085\n",
            "                    \t     Validation Accuracy : 0.8104008474576271\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3777389487899652\n",
            "                    \t     Validation Loss : 0.42202865014354646\n",
            "                    \t     Training Accuracy : 0.8327153361344538\n",
            "                    \t     Validation Accuracy : 0.810309243697479\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.37725488203018903\n",
            "                    \t     Validation Loss : 0.42205698290488686\n",
            "                    \t     Training Accuracy : 0.8329947916666667\n",
            "                    \t     Validation Accuracy : 0.8104016666666667\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.37694123974516375\n",
            "                    \t     Validation Loss : 0.4218987910809237\n",
            "                    \t     Training Accuracy : 0.8331663223140496\n",
            "                    \t     Validation Accuracy : 0.8105148760330578\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3764764761094187\n",
            "                    \t     Validation Loss : 0.42174486170203324\n",
            "                    \t     Training Accuracy : 0.8334375\n",
            "                    \t     Validation Accuracy : 0.810588524590164\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3760199191778656\n",
            "                    \t     Validation Loss : 0.42167588527370464\n",
            "                    \t     Training Accuracy : 0.833780487804878\n",
            "                    \t     Validation Accuracy : 0.8106967479674797\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.37557779295069554\n",
            "                    \t     Validation Loss : 0.4219130457400136\n",
            "                    \t     Training Accuracy : 0.833991935483871\n",
            "                    \t     Validation Accuracy : 0.8106733870967742\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3751786886262894\n",
            "                    \t     Validation Loss : 0.4217570617928292\n",
            "                    \t     Training Accuracy : 0.83423\n",
            "                    \t     Validation Accuracy : 0.8107728\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.37424553622033385\n",
            "                    \t     Validation Loss : 0.42204381585762724\n",
            "                    \t     Training Accuracy : 0.8346279761904762\n",
            "                    \t     Validation Accuracy : 0.8108539682539683\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3733144740226466\n",
            "                    \t     Validation Loss : 0.42259982584154876\n",
            "                    \t     Training Accuracy : 0.8350836614173228\n",
            "                    \t     Validation Accuracy : 0.8108834645669292\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3725404229882406\n",
            "                    \t     Validation Loss : 0.4226488472052148\n",
            "                    \t     Training Accuracy : 0.83548828125\n",
            "                    \t     Validation Accuracy : 0.81092265625\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.37193110186982065\n",
            "                    \t     Validation Loss : 0.4228632822666004\n",
            "                    \t     Training Accuracy : 0.8358187984496124\n",
            "                    \t     Validation Accuracy : 0.8109620155038759\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.37092023721738504\n",
            "                    \t     Validation Loss : 0.42329180847169523\n",
            "                    \t     Training Accuracy : 0.83625\n",
            "                    \t     Validation Accuracy : 0.8110215384615385\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3699015391140266\n",
            "                    \t     Validation Loss : 0.42435423758473206\n",
            "                    \t     Training Accuracy : 0.836793893129771\n",
            "                    \t     Validation Accuracy : 0.8110526717557252\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.36932847272322483\n",
            "                    \t     Validation Loss : 0.4246991666709026\n",
            "                    \t     Training Accuracy : 0.8370833333333333\n",
            "                    \t     Validation Accuracy : 0.8110469696969697\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3685546941119701\n",
            "                    \t     Validation Loss : 0.4248753802287024\n",
            "                    \t     Training Accuracy : 0.8374812030075188\n",
            "                    \t     Validation Accuracy : 0.8110458646616542\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3680106769051792\n",
            "                    \t     Validation Loss : 0.42506291714439753\n",
            "                    \t     Training Accuracy : 0.8377938432835821\n",
            "                    \t     Validation Accuracy : 0.8111\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3675917151686218\n",
            "                    \t     Validation Loss : 0.42507844755745416\n",
            "                    \t     Training Accuracy : 0.8380046296296296\n",
            "                    \t     Validation Accuracy : 0.8111029629629629\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.36724046667216015\n",
            "                    \t     Validation Loss : 0.4253391146578813\n",
            "                    \t     Training Accuracy : 0.83828125\n",
            "                    \t     Validation Accuracy : 0.8111786764705883\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3666503014665668\n",
            "                    \t     Validation Loss : 0.42525634304174115\n",
            "                    \t     Training Accuracy : 0.8385675182481752\n",
            "                    \t     Validation Accuracy : 0.811236496350365\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.36597639625865047\n",
            "                    \t     Validation Loss : 0.42540421726279304\n",
            "                    \t     Training Accuracy : 0.8389538043478261\n",
            "                    \t     Validation Accuracy : 0.8113072463768116\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.365428971349657\n",
            "                    \t     Validation Loss : 0.4255472593979433\n",
            "                    \t     Training Accuracy : 0.8392670863309353\n",
            "                    \t     Validation Accuracy : 0.8113\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3648865768265511\n",
            "                    \t     Validation Loss : 0.42544902356350833\n",
            "                    \t     Training Accuracy : 0.8394642857142857\n",
            "                    \t     Validation Accuracy : 0.8113471428571428\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.36425228750610605\n",
            "                    \t     Validation Loss : 0.4256832610392951\n",
            "                    \t     Training Accuracy : 0.8397429078014185\n",
            "                    \t     Validation Accuracy : 0.8113709219858156\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3636675176292028\n",
            "                    \t     Validation Loss : 0.4259088030346893\n",
            "                    \t     Training Accuracy : 0.8400660211267605\n",
            "                    \t     Validation Accuracy : 0.8114246478873239\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.36333936545346585\n",
            "                    \t     Validation Loss : 0.4260098649757628\n",
            "                    \t     Training Accuracy : 0.8401748251748252\n",
            "                    \t     Validation Accuracy : 0.811465034965035\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.362710067701733\n",
            "                    \t     Validation Loss : 0.4260526171223058\n",
            "                    \t     Training Accuracy : 0.8404557291666667\n",
            "                    \t     Validation Accuracy : 0.8114979166666667\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3622424498935198\n",
            "                    \t     Validation Loss : 0.4260576374305132\n",
            "                    \t     Training Accuracy : 0.8407241379310345\n",
            "                    \t     Validation Accuracy : 0.8115034482758621\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3616836799216801\n",
            "                    \t     Validation Loss : 0.42616207197465383\n",
            "                    \t     Training Accuracy : 0.8409631849315069\n",
            "                    \t     Validation Accuracy : 0.811527397260274\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3612114219676678\n",
            "                    \t     Validation Loss : 0.4263177000867721\n",
            "                    \t     Training Accuracy : 0.841232993197279\n",
            "                    \t     Validation Accuracy : 0.8115904761904762\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3606362869937879\n",
            "                    \t     Validation Loss : 0.4267159986888959\n",
            "                    \t     Training Accuracy : 0.8415076013513514\n",
            "                    \t     Validation Accuracy : 0.8116229729729729\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.36012911557001154\n",
            "                    \t     Validation Loss : 0.4266398181441821\n",
            "                    \t     Training Accuracy : 0.841744966442953\n",
            "                    \t     Validation Accuracy : 0.8116805369127517\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.35955283807466426\n",
            "                    \t     Validation Loss : 0.42659818738262556\n",
            "                    \t     Training Accuracy : 0.8420208333333333\n",
            "                    \t     Validation Accuracy : 0.811736\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3585234372135227\n",
            "                    \t     Validation Loss : 0.42722814702096745\n",
            "                    \t     Training Accuracy : 0.8424751655629139\n",
            "                    \t     Validation Accuracy : 0.811771523178808\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3574523573569757\n",
            "                    \t     Validation Loss : 0.427929351292253\n",
            "                    \t     Training Accuracy : 0.8429317434210526\n",
            "                    \t     Validation Accuracy : 0.8118092105263158\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3564035138706951\n",
            "                    \t     Validation Loss : 0.42886126353140636\n",
            "                    \t     Training Accuracy : 0.8434232026143791\n",
            "                    \t     Validation Accuracy : 0.8118058823529412\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.35557465412254846\n",
            "                    \t     Validation Loss : 0.42940713021497556\n",
            "                    \t     Training Accuracy : 0.8438676948051949\n",
            "                    \t     Validation Accuracy : 0.811801948051948\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3548750759723686\n",
            "                    \t     Validation Loss : 0.42990250375417843\n",
            "                    \t     Training Accuracy : 0.8441774193548387\n",
            "                    \t     Validation Accuracy : 0.8118348387096774\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.35400338385731744\n",
            "                    \t     Validation Loss : 0.43012410565819204\n",
            "                    \t     Training Accuracy : 0.8445833333333334\n",
            "                    \t     Validation Accuracy : 0.8118487179487179\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.35322484893214173\n",
            "                    \t     Validation Loss : 0.43030770516077965\n",
            "                    \t     Training Accuracy : 0.844968152866242\n",
            "                    \t     Validation Accuracy : 0.8118859872611465\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3527375235785789\n",
            "                    \t     Validation Loss : 0.4305781460797532\n",
            "                    \t     Training Accuracy : 0.8452294303797468\n",
            "                    \t     Validation Accuracy : 0.8118981012658227\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.35198542679630734\n",
            "                    \t     Validation Loss : 0.430957342230605\n",
            "                    \t     Training Accuracy : 0.8456053459119497\n",
            "                    \t     Validation Accuracy : 0.8119075471698113\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3513295348854735\n",
            "                    \t     Validation Loss : 0.4312043436080628\n",
            "                    \t     Training Accuracy : 0.84590625\n",
            "                    \t     Validation Accuracy : 0.8118825\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3507013077626687\n",
            "                    \t     Validation Loss : 0.4314191713919566\n",
            "                    \t     Training Accuracy : 0.8462150621118012\n",
            "                    \t     Validation Accuracy : 0.8119068322981366\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.35015168714118594\n",
            "                    \t     Validation Loss : 0.43185263275369884\n",
            "                    \t     Training Accuracy : 0.8464583333333333\n",
            "                    \t     Validation Accuracy : 0.8119185185185185\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3495327393299231\n",
            "                    \t     Validation Loss : 0.43240046427462897\n",
            "                    \t     Training Accuracy : 0.8467407975460123\n",
            "                    \t     Validation Accuracy : 0.8119104294478527\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3488108292867134\n",
            "                    \t     Validation Loss : 0.4325953898142954\n",
            "                    \t     Training Accuracy : 0.8471379573170732\n",
            "                    \t     Validation Accuracy : 0.8118914634146341\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34819157923532257\n",
            "                    \t     Validation Loss : 0.4326873781435608\n",
            "                    \t     Training Accuracy : 0.8474356060606061\n",
            "                    \t     Validation Accuracy : 0.8119145454545454\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34772514590118303\n",
            "                    \t     Validation Loss : 0.4327532731080782\n",
            "                    \t     Training Accuracy : 0.8477409638554216\n",
            "                    \t     Validation Accuracy : 0.8119132530120482\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34723998371355547\n",
            "                    \t     Validation Loss : 0.432811347584443\n",
            "                    \t     Training Accuracy : 0.8480276946107784\n",
            "                    \t     Validation Accuracy : 0.8119574850299401\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.346803654764912\n",
            "                    \t     Validation Loss : 0.4329532516896232\n",
            "                    \t     Training Accuracy : 0.8481845238095238\n",
            "                    \t     Validation Accuracy : 0.8119958333333334\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34633148106333067\n",
            "                    \t     Validation Loss : 0.43306735669233604\n",
            "                    \t     Training Accuracy : 0.8484023668639054\n",
            "                    \t     Validation Accuracy : 0.8120023668639054\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3457408391780713\n",
            "                    \t     Validation Loss : 0.43328355995427453\n",
            "                    \t     Training Accuracy : 0.8486838235294117\n",
            "                    \t     Validation Accuracy : 0.8120117647058823\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34515282582121287\n",
            "                    \t     Validation Loss : 0.43371972422080407\n",
            "                    \t     Training Accuracy : 0.8490168128654971\n",
            "                    \t     Validation Accuracy : 0.8120345029239766\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.3450064540862344\n",
            "                    \t     Validation Loss : 0.43365357275050265\n",
            "                    \t     Training Accuracy : 0.8492005813953488\n",
            "                    \t     Validation Accuracy : 0.8120203488372093\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.344502706426072\n",
            "                    \t     Validation Loss : 0.433841715288272\n",
            "                    \t     Training Accuracy : 0.8494617052023121\n",
            "                    \t     Validation Accuracy : 0.8120433526011561\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34391881368454846\n",
            "                    \t     Validation Loss : 0.4342721973137389\n",
            "                    \t     Training Accuracy : 0.8497234195402299\n",
            "                    \t     Validation Accuracy : 0.8120632183908046\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.34350657026341985\n",
            "                    \t     Validation Loss : 0.4343806773218076\n",
            "                    \t     Training Accuracy : 0.8499285714285715\n",
            "                    \t     Validation Accuracy : 0.8121057142857143\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.34252271233507514\n",
            "                    \t     Validation Loss : 0.43527166939688394\n",
            "                    \t     Training Accuracy : 0.8503622159090909\n",
            "                    \t     Validation Accuracy : 0.8121130681818182\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3415689657528564\n",
            "                    \t     Validation Loss : 0.43639237055427327\n",
            "                    \t     Training Accuracy : 0.8508121468926554\n",
            "                    \t     Validation Accuracy : 0.8121265536723163\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3407450540645278\n",
            "                    \t     Validation Loss : 0.43657439709779283\n",
            "                    \t     Training Accuracy : 0.8512008426966292\n",
            "                    \t     Validation Accuracy : 0.8121151685393259\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3399730364604744\n",
            "                    \t     Validation Loss : 0.43664111124486366\n",
            "                    \t     Training Accuracy : 0.8516131284916201\n",
            "                    \t     Validation Accuracy : 0.8121251396648045\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3391857692707951\n",
            "                    \t     Validation Loss : 0.4370583831702574\n",
            "                    \t     Training Accuracy : 0.8519618055555556\n",
            "                    \t     Validation Accuracy : 0.8121272222222222\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3383855280289375\n",
            "                    \t     Validation Loss : 0.43769535389716596\n",
            "                    \t     Training Accuracy : 0.8522997237569061\n",
            "                    \t     Validation Accuracy : 0.8121232044198895\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3375248768038352\n",
            "                    \t     Validation Loss : 0.43859987457268484\n",
            "                    \t     Training Accuracy : 0.8526785714285714\n",
            "                    \t     Validation Accuracy : 0.8120868131868132\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3367659730009246\n",
            "                    \t     Validation Loss : 0.4391879133297922\n",
            "                    \t     Training Accuracy : 0.8530088797814208\n",
            "                    \t     Validation Accuracy : 0.8120650273224044\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.335976788479855\n",
            "                    \t     Validation Loss : 0.43978925213738573\n",
            "                    \t     Training Accuracy : 0.8533627717391304\n",
            "                    \t     Validation Accuracy : 0.8120809782608696\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.33506817600926436\n",
            "                    \t     Validation Loss : 0.44055337259894456\n",
            "                    \t     Training Accuracy : 0.8537736486486487\n",
            "                    \t     Validation Accuracy : 0.8120313513513514\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.334546871655871\n",
            "                    \t     Validation Loss : 0.4408308778056953\n",
            "                    \t     Training Accuracy : 0.8540288978494623\n",
            "                    \t     Validation Accuracy : 0.811960752688172\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3339013644653487\n",
            "                    \t     Validation Loss : 0.4412647179064711\n",
            "                    \t     Training Accuracy : 0.8543282085561498\n",
            "                    \t     Validation Accuracy : 0.8119443850267379\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.33339386408464944\n",
            "                    \t     Validation Loss : 0.44169193490483505\n",
            "                    \t     Training Accuracy : 0.8546110372340425\n",
            "                    \t     Validation Accuracy : 0.8119579787234043\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.33275472673700834\n",
            "                    \t     Validation Loss : 0.44239798016299703\n",
            "                    \t     Training Accuracy : 0.8549041005291005\n",
            "                    \t     Validation Accuracy : 0.8119206349206349\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.33230443249162483\n",
            "                    \t     Validation Loss : 0.44264418209569534\n",
            "                    \t     Training Accuracy : 0.8551151315789474\n",
            "                    \t     Validation Accuracy : 0.8119047368421053\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3318330733024598\n",
            "                    \t     Validation Loss : 0.4430918066020841\n",
            "                    \t     Training Accuracy : 0.8553403141361257\n",
            "                    \t     Validation Accuracy : 0.8119062827225131\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.33132950822036944\n",
            "                    \t     Validation Loss : 0.4436147536388033\n",
            "                    \t     Training Accuracy : 0.8556217447916666\n",
            "                    \t     Validation Accuracy : 0.8119020833333334\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3307580860297876\n",
            "                    \t     Validation Loss : 0.44403515666483734\n",
            "                    \t     Training Accuracy : 0.8559229274611398\n",
            "                    \t     Validation Accuracy : 0.8119015544041451\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3301624227296945\n",
            "                    \t     Validation Loss : 0.44469318855107853\n",
            "                    \t     Training Accuracy : 0.8561726804123712\n",
            "                    \t     Validation Accuracy : 0.811891237113402\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.329562184259391\n",
            "                    \t     Validation Loss : 0.4450164550849595\n",
            "                    \t     Training Accuracy : 0.8564711538461538\n",
            "                    \t     Validation Accuracy : 0.8119076923076923\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3289616958448207\n",
            "                    \t     Validation Loss : 0.4456881133104972\n",
            "                    \t     Training Accuracy : 0.8567793367346939\n",
            "                    \t     Validation Accuracy : 0.8119015306122449\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3286134919093988\n",
            "                    \t     Validation Loss : 0.44588085411001116\n",
            "                    \t     Training Accuracy : 0.8569257614213198\n",
            "                    \t     Validation Accuracy : 0.8118817258883249\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.32812984752393504\n",
            "                    \t     Validation Loss : 0.44594052294024256\n",
            "                    \t     Training Accuracy : 0.8571685606060606\n",
            "                    \t     Validation Accuracy : 0.8118848484848484\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.327572715368646\n",
            "                    \t     Validation Loss : 0.44617707995395195\n",
            "                    \t     Training Accuracy : 0.857446608040201\n",
            "                    \t     Validation Accuracy : 0.8118994974874372\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.3271131191262044\n",
            "                    \t     Validation Loss : 0.4466182919613684\n",
            "                    \t     Training Accuracy : 0.857659375\n",
            "                    \t     Validation Accuracy : 0.811912\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3262332181711287\n",
            "                    \t     Validation Loss : 0.44740666505441096\n",
            "                    \t     Training Accuracy : 0.858047263681592\n",
            "                    \t     Validation Accuracy : 0.811944776119403\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.32521714810291213\n",
            "                    \t     Validation Loss : 0.44895570191744716\n",
            "                    \t     Training Accuracy : 0.858490099009901\n",
            "                    \t     Validation Accuracy : 0.8119529702970297\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.32421907747476336\n",
            "                    \t     Validation Loss : 0.4506215795585667\n",
            "                    \t     Training Accuracy : 0.8589470443349754\n",
            "                    \t     Validation Accuracy : 0.8119655172413793\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.32332985316759305\n",
            "                    \t     Validation Loss : 0.45191779576071844\n",
            "                    \t     Training Accuracy : 0.8593443627450981\n",
            "                    \t     Validation Accuracy : 0.811956862745098\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3226292609513351\n",
            "                    \t     Validation Loss : 0.4528715633781336\n",
            "                    \t     Training Accuracy : 0.8596707317073171\n",
            "                    \t     Validation Accuracy : 0.8119497560975609\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3218809603222474\n",
            "                    \t     Validation Loss : 0.4533895863687909\n",
            "                    \t     Training Accuracy : 0.8600091019417476\n",
            "                    \t     Validation Accuracy : 0.8119441747572815\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.32112751666861383\n",
            "                    \t     Validation Loss : 0.45459677260625214\n",
            "                    \t     Training Accuracy : 0.8603592995169083\n",
            "                    \t     Validation Accuracy : 0.8119227053140097\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.320447745927108\n",
            "                    \t     Validation Loss : 0.45486756847729837\n",
            "                    \t     Training Accuracy : 0.860694110576923\n",
            "                    \t     Validation Accuracy : 0.8119129807692308\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3197707431756281\n",
            "                    \t     Validation Loss : 0.4550729327158714\n",
            "                    \t     Training Accuracy : 0.8610287081339713\n",
            "                    \t     Validation Accuracy : 0.8118937799043062\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3190079580694437\n",
            "                    \t     Validation Loss : 0.45597951423008976\n",
            "                    \t     Training Accuracy : 0.8613720238095238\n",
            "                    \t     Validation Accuracy : 0.8118833333333333\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31847391243335477\n",
            "                    \t     Validation Loss : 0.4564259533873734\n",
            "                    \t     Training Accuracy : 0.8616558056872038\n",
            "                    \t     Validation Accuracy : 0.811878672985782\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31778587344647297\n",
            "                    \t     Validation Loss : 0.4573493146434861\n",
            "                    \t     Training Accuracy : 0.8619929245283019\n",
            "                    \t     Validation Accuracy : 0.8118688679245283\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3171649143610482\n",
            "                    \t     Validation Loss : 0.45731723962736703\n",
            "                    \t     Training Accuracy : 0.8622593896713615\n",
            "                    \t     Validation Accuracy : 0.8118704225352112\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31648234691679755\n",
            "                    \t     Validation Loss : 0.4577990158878351\n",
            "                    \t     Training Accuracy : 0.862578855140187\n",
            "                    \t     Validation Accuracy : 0.8118724299065421\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31601986228588014\n",
            "                    \t     Validation Loss : 0.4578973130679842\n",
            "                    \t     Training Accuracy : 0.8628052325581396\n",
            "                    \t     Validation Accuracy : 0.8118511627906977\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3154244787784086\n",
            "                    \t     Validation Loss : 0.4585031238640215\n",
            "                    \t     Training Accuracy : 0.8630787037037037\n",
            "                    \t     Validation Accuracy : 0.8118462962962963\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3147652462596924\n",
            "                    \t     Validation Loss : 0.4594438732693503\n",
            "                    \t     Training Accuracy : 0.8633928571428572\n",
            "                    \t     Validation Accuracy : 0.8118308755760368\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31419119954673114\n",
            "                    \t     Validation Loss : 0.46004069575842654\n",
            "                    \t     Training Accuracy : 0.8636525229357798\n",
            "                    \t     Validation Accuracy : 0.8118252293577982\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3136765699032439\n",
            "                    \t     Validation Loss : 0.4604929429326569\n",
            "                    \t     Training Accuracy : 0.8639012557077625\n",
            "                    \t     Validation Accuracy : 0.8118310502283105\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31310018756223673\n",
            "                    \t     Validation Loss : 0.461145293783324\n",
            "                    \t     Training Accuracy : 0.8641505681818182\n",
            "                    \t     Validation Accuracy : 0.8118172727272728\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3125588333254419\n",
            "                    \t     Validation Loss : 0.461649334513103\n",
            "                    \t     Training Accuracy : 0.8643976244343892\n",
            "                    \t     Validation Accuracy : 0.8118099547511313\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31192741362747173\n",
            "                    \t     Validation Loss : 0.46211347860923124\n",
            "                    \t     Training Accuracy : 0.8646931306306306\n",
            "                    \t     Validation Accuracy : 0.8117981981981982\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31135304139283876\n",
            "                    \t     Validation Loss : 0.46275893786375066\n",
            "                    \t     Training Accuracy : 0.8649691704035875\n",
            "                    \t     Validation Accuracy : 0.8117986547085202\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.31086772280894887\n",
            "                    \t     Validation Loss : 0.46391070806852786\n",
            "                    \t     Training Accuracy : 0.8652064732142857\n",
            "                    \t     Validation Accuracy : 0.8117633928571428\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.3104045924651954\n",
            "                    \t     Validation Loss : 0.4644374996851131\n",
            "                    \t     Training Accuracy : 0.8654\n",
            "                    \t     Validation Accuracy : 0.8117248888888889\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.30961706613528384\n",
            "                    \t     Validation Loss : 0.46552285272899285\n",
            "                    \t     Training Accuracy : 0.8657826327433629\n",
            "                    \t     Validation Accuracy : 0.8117181415929203\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3087108156989259\n",
            "                    \t     Validation Loss : 0.46679184661373574\n",
            "                    \t     Training Accuracy : 0.866181167400881\n",
            "                    \t     Validation Accuracy : 0.8116775330396476\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.30787428180744314\n",
            "                    \t     Validation Loss : 0.46783200424498833\n",
            "                    \t     Training Accuracy : 0.8665679824561403\n",
            "                    \t     Validation Accuracy : 0.8116706140350877\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3070366913371406\n",
            "                    \t     Validation Loss : 0.4690887921083071\n",
            "                    \t     Training Accuracy : 0.8669514192139738\n",
            "                    \t     Validation Accuracy : 0.8116502183406114\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3062539178147588\n",
            "                    \t     Validation Loss : 0.4704433119712869\n",
            "                    \t     Training Accuracy : 0.8672989130434783\n",
            "                    \t     Validation Accuracy : 0.8116152173913044\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3055925571455648\n",
            "                    \t     Validation Loss : 0.47167697939990066\n",
            "                    \t     Training Accuracy : 0.8676136363636363\n",
            "                    \t     Validation Accuracy : 0.811603896103896\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.30482559328950976\n",
            "                    \t     Validation Loss : 0.4727790629882331\n",
            "                    \t     Training Accuracy : 0.8679741379310345\n",
            "                    \t     Validation Accuracy : 0.8115965517241379\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.304176569785563\n",
            "                    \t     Validation Loss : 0.4734269441330374\n",
            "                    \t     Training Accuracy : 0.868299356223176\n",
            "                    \t     Validation Accuracy : 0.8115858369098713\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.30344113517158594\n",
            "                    \t     Validation Loss : 0.4739494901188612\n",
            "                    \t     Training Accuracy : 0.8686404914529915\n",
            "                    \t     Validation Accuracy : 0.8115858974358975\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3026727300129752\n",
            "                    \t     Validation Loss : 0.47501369627169443\n",
            "                    \t     Training Accuracy : 0.8689787234042553\n",
            "                    \t     Validation Accuracy : 0.8115897872340425\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3020011963724096\n",
            "                    \t     Validation Loss : 0.47567462758540624\n",
            "                    \t     Training Accuracy : 0.8692558262711865\n",
            "                    \t     Validation Accuracy : 0.8115927966101695\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.30135315019523384\n",
            "                    \t     Validation Loss : 0.47682189463452623\n",
            "                    \t     Training Accuracy : 0.8695727848101266\n",
            "                    \t     Validation Accuracy : 0.8115949367088607\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3007737692845829\n",
            "                    \t     Validation Loss : 0.47725773950449174\n",
            "                    \t     Training Accuracy : 0.8698660714285714\n",
            "                    \t     Validation Accuracy : 0.811590756302521\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.3001005999261911\n",
            "                    \t     Validation Loss : 0.4780643291833461\n",
            "                    \t     Training Accuracy : 0.8701359832635983\n",
            "                    \t     Validation Accuracy : 0.811581589958159\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.29951359339349437\n",
            "                    \t     Validation Loss : 0.47911081205764877\n",
            "                    \t     Training Accuracy : 0.870375\n",
            "                    \t     Validation Accuracy : 0.8115775\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2988977094570801\n",
            "                    \t     Validation Loss : 0.48009943175668945\n",
            "                    \t     Training Accuracy : 0.870643153526971\n",
            "                    \t     Validation Accuracy : 0.8115336099585062\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.29833390593663445\n",
            "                    \t     Validation Loss : 0.4809135348618379\n",
            "                    \t     Training Accuracy : 0.8709090909090909\n",
            "                    \t     Validation Accuracy : 0.8115115702479339\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.29781141066053735\n",
            "                    \t     Validation Loss : 0.48139845620569005\n",
            "                    \t     Training Accuracy : 0.8711805555555555\n",
            "                    \t     Validation Accuracy : 0.81150329218107\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2972852539180656\n",
            "                    \t     Validation Loss : 0.4815713526322643\n",
            "                    \t     Training Accuracy : 0.8714293032786885\n",
            "                    \t     Validation Accuracy : 0.8114717213114754\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.296713179193095\n",
            "                    \t     Validation Loss : 0.4825862459327338\n",
            "                    \t     Training Accuracy : 0.8716709183673469\n",
            "                    \t     Validation Accuracy : 0.8114636734693877\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2960611153922112\n",
            "                    \t     Validation Loss : 0.4832554202389984\n",
            "                    \t     Training Accuracy : 0.8719512195121951\n",
            "                    \t     Validation Accuracy : 0.8114243902439024\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.29556075397392484\n",
            "                    \t     Validation Loss : 0.4836065074053621\n",
            "                    \t     Training Accuracy : 0.8721963562753037\n",
            "                    \t     Validation Accuracy : 0.8114064777327935\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2950011033208425\n",
            "                    \t     Validation Loss : 0.4840408441015348\n",
            "                    \t     Training Accuracy : 0.8724495967741935\n",
            "                    \t     Validation Accuracy : 0.811375\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2944996573705316\n",
            "                    \t     Validation Loss : 0.4845882963330796\n",
            "                    \t     Training Accuracy : 0.8726807228915663\n",
            "                    \t     Validation Accuracy : 0.8113349397590361\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2939581102572009\n",
            "                    \t     Validation Loss : 0.48535185776479517\n",
            "                    \t     Training Accuracy : 0.872925\n",
            "                    \t     Validation Accuracy : 0.8112944\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.29345635224159705\n",
            "                    \t     Validation Loss : 0.48639265012070526\n",
            "                    \t     Training Accuracy : 0.8732121513944223\n",
            "                    \t     Validation Accuracy : 0.8112585657370518\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2927740456680915\n",
            "                    \t     Validation Loss : 0.48725570749353164\n",
            "                    \t     Training Accuracy : 0.8735267857142858\n",
            "                    \t     Validation Accuracy : 0.8112392857142857\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.29220988823693583\n",
            "                    \t     Validation Loss : 0.48764444985417027\n",
            "                    \t     Training Accuracy : 0.8738092885375494\n",
            "                    \t     Validation Accuracy : 0.8112110671936759\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2915067925784869\n",
            "                    \t     Validation Loss : 0.48843976056989474\n",
            "                    \t     Training Accuracy : 0.8741166338582678\n",
            "                    \t     Validation Accuracy : 0.8111685039370079\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2908519462018694\n",
            "                    \t     Validation Loss : 0.4895582953663529\n",
            "                    \t     Training Accuracy : 0.8744289215686275\n",
            "                    \t     Validation Accuracy : 0.811163137254902\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.29031106347949387\n",
            "                    \t     Validation Loss : 0.48969907575950966\n",
            "                    \t     Training Accuracy : 0.87470947265625\n",
            "                    \t     Validation Accuracy : 0.811105859375\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2898425853638348\n",
            "                    \t     Validation Loss : 0.49031281913839353\n",
            "                    \t     Training Accuracy : 0.8749270428015564\n",
            "                    \t     Validation Accuracy : 0.8111035019455253\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28927642144511867\n",
            "                    \t     Validation Loss : 0.4906350561301342\n",
            "                    \t     Training Accuracy : 0.8751841085271318\n",
            "                    \t     Validation Accuracy : 0.811084496124031\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28865512219653194\n",
            "                    \t     Validation Loss : 0.49164336901866235\n",
            "                    \t     Training Accuracy : 0.8754512548262549\n",
            "                    \t     Validation Accuracy : 0.8110799227799228\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28804090740735855\n",
            "                    \t     Validation Loss : 0.49259328820807213\n",
            "                    \t     Training Accuracy : 0.8757307692307692\n",
            "                    \t     Validation Accuracy : 0.8110642307692307\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2875445131177147\n",
            "                    \t     Validation Loss : 0.49274116077477575\n",
            "                    \t     Training Accuracy : 0.8759722222222223\n",
            "                    \t     Validation Accuracy : 0.8110383141762452\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28699976002118543\n",
            "                    \t     Validation Loss : 0.49334139830789187\n",
            "                    \t     Training Accuracy : 0.8762189885496183\n",
            "                    \t     Validation Accuracy : 0.8110110687022901\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2864416022038179\n",
            "                    \t     Validation Loss : 0.49358053481819425\n",
            "                    \t     Training Accuracy : 0.8764591254752852\n",
            "                    \t     Validation Accuracy : 0.810987072243346\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28586098174546903\n",
            "                    \t     Validation Loss : 0.4941995293502835\n",
            "                    \t     Training Accuracy : 0.8767424242424242\n",
            "                    \t     Validation Accuracy : 0.8109746212121212\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2852515001790071\n",
            "                    \t     Validation Loss : 0.4948069683436624\n",
            "                    \t     Training Accuracy : 0.8770165094339623\n",
            "                    \t     Validation Accuracy : 0.8109494339622642\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2846903165846825\n",
            "                    \t     Validation Loss : 0.4956055959590907\n",
            "                    \t     Training Accuracy : 0.8772791353383459\n",
            "                    \t     Validation Accuracy : 0.8109266917293233\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2840986466669732\n",
            "                    \t     Validation Loss : 0.4963410486806754\n",
            "                    \t     Training Accuracy : 0.8775538389513109\n",
            "                    \t     Validation Accuracy : 0.8108861423220973\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2835681893680342\n",
            "                    \t     Validation Loss : 0.49729544722818314\n",
            "                    \t     Training Accuracy : 0.8778171641791045\n",
            "                    \t     Validation Accuracy : 0.8108794776119403\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2830208614725813\n",
            "                    \t     Validation Loss : 0.49794227674263264\n",
            "                    \t     Training Accuracy : 0.87807156133829\n",
            "                    \t     Validation Accuracy : 0.8108702602230483\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2824822885055716\n",
            "                    \t     Validation Loss : 0.4981622040383174\n",
            "                    \t     Training Accuracy : 0.8783472222222222\n",
            "                    \t     Validation Accuracy : 0.8108659259259259\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2819869799154202\n",
            "                    \t     Validation Loss : 0.4984680895491345\n",
            "                    \t     Training Accuracy : 0.8785908671586716\n",
            "                    \t     Validation Accuracy : 0.8108446494464945\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28149808738253984\n",
            "                    \t     Validation Loss : 0.4993999761391673\n",
            "                    \t     Training Accuracy : 0.878821231617647\n",
            "                    \t     Validation Accuracy : 0.8108297794117647\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28096804555324706\n",
            "                    \t     Validation Loss : 0.4998211422511587\n",
            "                    \t     Training Accuracy : 0.8790636446886447\n",
            "                    \t     Validation Accuracy : 0.8108054945054946\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.28040515889519024\n",
            "                    \t     Validation Loss : 0.5006680157693473\n",
            "                    \t     Training Accuracy : 0.8793225364963504\n",
            "                    \t     Validation Accuracy : 0.8108175182481752\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.27992280620976606\n",
            "                    \t     Validation Loss : 0.5013626192851929\n",
            "                    \t     Training Accuracy : 0.8795636363636363\n",
            "                    \t     Validation Accuracy : 0.8108185454545455\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27921198118117\n",
            "                    \t     Validation Loss : 0.5027003694764481\n",
            "                    \t     Training Accuracy : 0.8799048913043478\n",
            "                    \t     Validation Accuracy : 0.810831884057971\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27850235308083415\n",
            "                    \t     Validation Loss : 0.5036497526091543\n",
            "                    \t     Training Accuracy : 0.8802278880866427\n",
            "                    \t     Validation Accuracy : 0.8108314079422383\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.277760041842083\n",
            "                    \t     Validation Loss : 0.5052260172830443\n",
            "                    \t     Training Accuracy : 0.880564298561151\n",
            "                    \t     Validation Accuracy : 0.8108291366906475\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2770389694931139\n",
            "                    \t     Validation Loss : 0.506602479657789\n",
            "                    \t     Training Accuracy : 0.8808781362007169\n",
            "                    \t     Validation Accuracy : 0.8108225806451613\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27640932374244687\n",
            "                    \t     Validation Loss : 0.5074448849760494\n",
            "                    \t     Training Accuracy : 0.8811495535714285\n",
            "                    \t     Validation Accuracy : 0.8108257142857143\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27574667775198103\n",
            "                    \t     Validation Loss : 0.5085170328336681\n",
            "                    \t     Training Accuracy : 0.8814524021352313\n",
            "                    \t     Validation Accuracy : 0.8108298932384341\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27511127829944704\n",
            "                    \t     Validation Loss : 0.5101317976655403\n",
            "                    \t     Training Accuracy : 0.8817420212765957\n",
            "                    \t     Validation Accuracy : 0.8108248226950354\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2744945933414103\n",
            "                    \t     Validation Loss : 0.5110606415256594\n",
            "                    \t     Training Accuracy : 0.8820163427561838\n",
            "                    \t     Validation Accuracy : 0.8108187279151944\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2738878624035951\n",
            "                    \t     Validation Loss : 0.5121867276463358\n",
            "                    \t     Training Accuracy : 0.8822975352112676\n",
            "                    \t     Validation Accuracy : 0.8108\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2733067046897649\n",
            "                    \t     Validation Loss : 0.513163274205527\n",
            "                    \t     Training Accuracy : 0.8825614035087719\n",
            "                    \t     Validation Accuracy : 0.8107775438596492\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2726454796151981\n",
            "                    \t     Validation Loss : 0.5147661586175066\n",
            "                    \t     Training Accuracy : 0.882854020979021\n",
            "                    \t     Validation Accuracy : 0.8107776223776224\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27203130354828975\n",
            "                    \t     Validation Loss : 0.5163196055646341\n",
            "                    \t     Training Accuracy : 0.8831315331010453\n",
            "                    \t     Validation Accuracy : 0.8107620209059233\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2715003988734194\n",
            "                    \t     Validation Loss : 0.516815315591127\n",
            "                    \t     Training Accuracy : 0.8833875868055555\n",
            "                    \t     Validation Accuracy : 0.8107614583333334\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.27094849147832273\n",
            "                    \t     Validation Loss : 0.5180561552684319\n",
            "                    \t     Training Accuracy : 0.883628892733564\n",
            "                    \t     Validation Accuracy : 0.8107653979238755\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2703965071588915\n",
            "                    \t     Validation Loss : 0.5188173564144055\n",
            "                    \t     Training Accuracy : 0.8838987068965517\n",
            "                    \t     Validation Accuracy : 0.810753448275862\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2698807553972735\n",
            "                    \t     Validation Loss : 0.5193302266634756\n",
            "                    \t     Training Accuracy : 0.8841215635738832\n",
            "                    \t     Validation Accuracy : 0.8107546391752577\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2693378211485305\n",
            "                    \t     Validation Loss : 0.5200568358895759\n",
            "                    \t     Training Accuracy : 0.8843578767123288\n",
            "                    \t     Validation Accuracy : 0.8107719178082192\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2687528619716427\n",
            "                    \t     Validation Loss : 0.5208141791192785\n",
            "                    \t     Training Accuracy : 0.8846181740614334\n",
            "                    \t     Validation Accuracy : 0.8107843003412969\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.26822669908843083\n",
            "                    \t     Validation Loss : 0.5216698985564457\n",
            "                    \t     Training Accuracy : 0.8848490646258503\n",
            "                    \t     Validation Accuracy : 0.8107928571428571\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.26770205052116475\n",
            "                    \t     Validation Loss : 0.5226698089430633\n",
            "                    \t     Training Accuracy : 0.8850953389830508\n",
            "                    \t     Validation Accuracy : 0.8107898305084745\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.26722538088418457\n",
            "                    \t     Validation Loss : 0.5233736481855531\n",
            "                    \t     Training Accuracy : 0.8852913851351352\n",
            "                    \t     Validation Accuracy : 0.8107932432432432\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.26664824400792486\n",
            "                    \t     Validation Loss : 0.5241645653400963\n",
            "                    \t     Training Accuracy : 0.8855492424242424\n",
            "                    \t     Validation Accuracy : 0.8107986531986532\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.2661345334984159\n",
            "                    \t     Validation Loss : 0.5259005904318529\n",
            "                    \t     Training Accuracy : 0.8857948825503356\n",
            "                    \t     Validation Accuracy : 0.8108083892617449\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.26573909249567085\n",
            "                    \t     Validation Loss : 0.5265361035695426\n",
            "                    \t     Training Accuracy : 0.8860054347826087\n",
            "                    \t     Validation Accuracy : 0.8108183946488294\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.26527129188961507\n",
            "                    \t     Validation Loss : 0.527073449471418\n",
            "                    \t     Training Accuracy : 0.8862145833333334\n",
            "                    \t     Validation Accuracy : 0.8108133333333334\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2646257619043438\n",
            "                    \t     Validation Loss : 0.527928518445856\n",
            "                    \t     Training Accuracy : 0.8865095514950166\n",
            "                    \t     Validation Accuracy : 0.8108003322259136\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2640067788956622\n",
            "                    \t     Validation Loss : 0.5292346221723913\n",
            "                    \t     Training Accuracy : 0.8867984271523179\n",
            "                    \t     Validation Accuracy : 0.8108039735099338\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.26343514798358914\n",
            "                    \t     Validation Loss : 0.5305041265821187\n",
            "                    \t     Training Accuracy : 0.8870730198019802\n",
            "                    \t     Validation Accuracy : 0.8108112211221122\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.26291731069583635\n",
            "                    \t     Validation Loss : 0.5310691033376131\n",
            "                    \t     Training Accuracy : 0.8873067434210526\n",
            "                    \t     Validation Accuracy : 0.8108131578947368\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2623499807191509\n",
            "                    \t     Validation Loss : 0.532189913422409\n",
            "                    \t     Training Accuracy : 0.8875737704918033\n",
            "                    \t     Validation Accuracy : 0.8108134426229509\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2617174865158193\n",
            "                    \t     Validation Loss : 0.5335636128628177\n",
            "                    \t     Training Accuracy : 0.8878533496732026\n",
            "                    \t     Validation Accuracy : 0.8108199346405228\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.26119010919608715\n",
            "                    \t     Validation Loss : 0.5345406270970546\n",
            "                    \t     Training Accuracy : 0.8881005700325733\n",
            "                    \t     Validation Accuracy : 0.8108234527687297\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2606419288030865\n",
            "                    \t     Validation Loss : 0.5355863373143086\n",
            "                    \t     Training Accuracy : 0.8883603896103897\n",
            "                    \t     Validation Accuracy : 0.8108262987012987\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2600584949296899\n",
            "                    \t     Validation Loss : 0.536657457553323\n",
            "                    \t     Training Accuracy : 0.8886306634304207\n",
            "                    \t     Validation Accuracy : 0.8108385113268608\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2595578471509995\n",
            "                    \t     Validation Loss : 0.5378674348991637\n",
            "                    \t     Training Accuracy : 0.8888568548387097\n",
            "                    \t     Validation Accuracy : 0.8108535483870968\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2590243251316947\n",
            "                    \t     Validation Loss : 0.5387555178755009\n",
            "                    \t     Training Accuracy : 0.8891117363344051\n",
            "                    \t     Validation Accuracy : 0.8108295819935691\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2585332473377975\n",
            "                    \t     Validation Loss : 0.5389641087466936\n",
            "                    \t     Training Accuracy : 0.8893289262820513\n",
            "                    \t     Validation Accuracy : 0.8108407051282052\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.25803776410682805\n",
            "                    \t     Validation Loss : 0.5398683864132688\n",
            "                    \t     Training Accuracy : 0.8895527156549521\n",
            "                    \t     Validation Accuracy : 0.8108463258785943\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.25754647967608046\n",
            "                    \t     Validation Loss : 0.5405447883336151\n",
            "                    \t     Training Accuracy : 0.8897830414012738\n",
            "                    \t     Validation Accuracy : 0.8108544585987261\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.25706554645578567\n",
            "                    \t     Validation Loss : 0.5414695380490595\n",
            "                    \t     Training Accuracy : 0.8899900793650793\n",
            "                    \t     Validation Accuracy : 0.8108355555555555\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.25662120215088585\n",
            "                    \t     Validation Loss : 0.5422602358899142\n",
            "                    \t     Training Accuracy : 0.890223496835443\n",
            "                    \t     Validation Accuracy : 0.8108398734177216\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2561174612883728\n",
            "                    \t     Validation Loss : 0.5429589867323428\n",
            "                    \t     Training Accuracy : 0.8904593848580442\n",
            "                    \t     Validation Accuracy : 0.8108476340694006\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2556742087278424\n",
            "                    \t     Validation Loss : 0.5434300332912686\n",
            "                    \t     Training Accuracy : 0.8906564465408805\n",
            "                    \t     Validation Accuracy : 0.8108512578616353\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2552037639332115\n",
            "                    \t     Validation Loss : 0.5440100102654434\n",
            "                    \t     Training Accuracy : 0.8908718652037617\n",
            "                    \t     Validation Accuracy : 0.8108648902821317\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2546836431521879\n",
            "                    \t     Validation Loss : 0.5453913318189013\n",
            "                    \t     Training Accuracy : 0.891107421875\n",
            "                    \t     Validation Accuracy : 0.810875625\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2541843842075357\n",
            "                    \t     Validation Loss : 0.5461251003862999\n",
            "                    \t     Training Accuracy : 0.8913278816199377\n",
            "                    \t     Validation Accuracy : 0.8108654205607476\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2536923279503132\n",
            "                    \t     Validation Loss : 0.5468191054766156\n",
            "                    \t     Training Accuracy : 0.8915508540372671\n",
            "                    \t     Validation Accuracy : 0.8108608695652174\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.25326111698249965\n",
            "                    \t     Validation Loss : 0.5473033823561606\n",
            "                    \t     Training Accuracy : 0.8917434210526316\n",
            "                    \t     Validation Accuracy : 0.8108684210526316\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2528130473788428\n",
            "                    \t     Validation Loss : 0.5480883438167061\n",
            "                    \t     Training Accuracy : 0.8919502314814814\n",
            "                    \t     Validation Accuracy : 0.8108583333333333\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.2523910543306301\n",
            "                    \t     Validation Loss : 0.5485647855138117\n",
            "                    \t     Training Accuracy : 0.8921365384615385\n",
            "                    \t     Validation Accuracy : 0.8108538461538461\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2518139165934058\n",
            "                    \t     Validation Loss : 0.5492429521865011\n",
            "                    \t     Training Accuracy : 0.8924060582822085\n",
            "                    \t     Validation Accuracy : 0.8108463190184049\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2512239996038323\n",
            "                    \t     Validation Loss : 0.5516390118479538\n",
            "                    \t     Training Accuracy : 0.8926681957186544\n",
            "                    \t     Validation Accuracy : 0.8108030581039756\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.25073187522190515\n",
            "                    \t     Validation Loss : 0.5526086831811843\n",
            "                    \t     Training Accuracy : 0.8929039634146342\n",
            "                    \t     Validation Accuracy : 0.8107890243902439\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.25019659065838906\n",
            "                    \t     Validation Loss : 0.5534194615157053\n",
            "                    \t     Training Accuracy : 0.8931534954407295\n",
            "                    \t     Validation Accuracy : 0.8107817629179331\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.249645910716411\n",
            "                    \t     Validation Loss : 0.5544011589196054\n",
            "                    \t     Training Accuracy : 0.8933977272727273\n",
            "                    \t     Validation Accuracy : 0.810780303030303\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24916454724865483\n",
            "                    \t     Validation Loss : 0.5549519303453205\n",
            "                    \t     Training Accuracy : 0.8936234894259819\n",
            "                    \t     Validation Accuracy : 0.8107870090634441\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24866123120989847\n",
            "                    \t     Validation Loss : 0.5560294217273305\n",
            "                    \t     Training Accuracy : 0.8938384789156627\n",
            "                    \t     Validation Accuracy : 0.810787951807229\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24809570471517736\n",
            "                    \t     Validation Loss : 0.5573758202294526\n",
            "                    \t     Training Accuracy : 0.8940840840840841\n",
            "                    \t     Validation Accuracy : 0.8107951951951952\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24770503552646578\n",
            "                    \t     Validation Loss : 0.5583916711950961\n",
            "                    \t     Training Accuracy : 0.8942945359281437\n",
            "                    \t     Validation Accuracy : 0.8107535928143712\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24721809824408073\n",
            "                    \t     Validation Loss : 0.5594099516228266\n",
            "                    \t     Training Accuracy : 0.894518656716418\n",
            "                    \t     Validation Accuracy : 0.8107597014925373\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24672178497129824\n",
            "                    \t     Validation Loss : 0.560944231455877\n",
            "                    \t     Training Accuracy : 0.8947377232142857\n",
            "                    \t     Validation Accuracy : 0.8107589285714286\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2462791921559221\n",
            "                    \t     Validation Loss : 0.5618159511515852\n",
            "                    \t     Training Accuracy : 0.8949536350148368\n",
            "                    \t     Validation Accuracy : 0.8107477744807121\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2458552109999458\n",
            "                    \t     Validation Loss : 0.5626775042248898\n",
            "                    \t     Training Accuracy : 0.8951368343195266\n",
            "                    \t     Validation Accuracy : 0.8107381656804734\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24542480598689417\n",
            "                    \t     Validation Loss : 0.5631918355975234\n",
            "                    \t     Training Accuracy : 0.8953392330383481\n",
            "                    \t     Validation Accuracy : 0.8107410029498525\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24495096693806323\n",
            "                    \t     Validation Loss : 0.5643693166877619\n",
            "                    \t     Training Accuracy : 0.8955404411764706\n",
            "                    \t     Validation Accuracy : 0.8107464705882353\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2444555505412587\n",
            "                    \t     Validation Loss : 0.565275393126297\n",
            "                    \t     Training Accuracy : 0.8957642961876833\n",
            "                    \t     Validation Accuracy : 0.8107527859237537\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24400336427420066\n",
            "                    \t     Validation Loss : 0.5660788205027449\n",
            "                    \t     Training Accuracy : 0.895968567251462\n",
            "                    \t     Validation Accuracy : 0.8107608187134503\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24353584372793508\n",
            "                    \t     Validation Loss : 0.5667634696760637\n",
            "                    \t     Training Accuracy : 0.8961844023323615\n",
            "                    \t     Validation Accuracy : 0.8107478134110787\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24317137915337173\n",
            "                    \t     Validation Loss : 0.5670203675804726\n",
            "                    \t     Training Accuracy : 0.8963553779069767\n",
            "                    \t     Validation Accuracy : 0.8107398255813953\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2428286326034332\n",
            "                    \t     Validation Loss : 0.5677582084536901\n",
            "                    \t     Training Accuracy : 0.8965326086956522\n",
            "                    \t     Validation Accuracy : 0.8107055072463768\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2425204595279775\n",
            "                    \t     Validation Loss : 0.5683733195901871\n",
            "                    \t     Training Accuracy : 0.8966744942196532\n",
            "                    \t     Validation Accuracy : 0.8106997109826589\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2420995420617352\n",
            "                    \t     Validation Loss : 0.5692919454075156\n",
            "                    \t     Training Accuracy : 0.8968695965417868\n",
            "                    \t     Validation Accuracy : 0.8106864553314121\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24175212070013358\n",
            "                    \t     Validation Loss : 0.5698260293035443\n",
            "                    \t     Training Accuracy : 0.8970384339080459\n",
            "                    \t     Validation Accuracy : 0.8106718390804598\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.2414657113345588\n",
            "                    \t     Validation Loss : 0.5704023794365423\n",
            "                    \t     Training Accuracy : 0.8971740687679083\n",
            "                    \t     Validation Accuracy : 0.8106687679083094\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.24110651607645808\n",
            "                    \t     Validation Loss : 0.5710871192771858\n",
            "                    \t     Training Accuracy : 0.8973446428571429\n",
            "                    \t     Validation Accuracy : 0.8106628571428571\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.24060392437986314\n",
            "                    \t     Validation Loss : 0.5722703265325997\n",
            "                    \t     Training Accuracy : 0.8975730056980057\n",
            "                    \t     Validation Accuracy : 0.8106629629629629\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.24014653380426434\n",
            "                    \t     Validation Loss : 0.5731227108166697\n",
            "                    \t     Training Accuracy : 0.8977876420454546\n",
            "                    \t     Validation Accuracy : 0.8106568181818182\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23966920379287412\n",
            "                    \t     Validation Loss : 0.5741003371219184\n",
            "                    \t     Training Accuracy : 0.8980046033994334\n",
            "                    \t     Validation Accuracy : 0.8106322946175637\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.2392236023615338\n",
            "                    \t     Validation Loss : 0.5746709461943992\n",
            "                    \t     Training Accuracy : 0.8982062146892655\n",
            "                    \t     Validation Accuracy : 0.8106214689265536\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.2387687558790236\n",
            "                    \t     Validation Loss : 0.5753898181627456\n",
            "                    \t     Training Accuracy : 0.8984084507042254\n",
            "                    \t     Validation Accuracy : 0.8106129577464789\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23829305677055354\n",
            "                    \t     Validation Loss : 0.5763160267576218\n",
            "                    \t     Training Accuracy : 0.898623595505618\n",
            "                    \t     Validation Accuracy : 0.8106081460674157\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23782201678633652\n",
            "                    \t     Validation Loss : 0.5771193379143409\n",
            "                    \t     Training Accuracy : 0.8988357843137255\n",
            "                    \t     Validation Accuracy : 0.8106008403361344\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23742455687991074\n",
            "                    \t     Validation Loss : 0.5778104937988762\n",
            "                    \t     Training Accuracy : 0.8990101256983241\n",
            "                    \t     Validation Accuracy : 0.810590782122905\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23696238097688702\n",
            "                    \t     Validation Loss : 0.5786376809924443\n",
            "                    \t     Training Accuracy : 0.8992217966573817\n",
            "                    \t     Validation Accuracy : 0.8105520891364902\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.2364913107042408\n",
            "                    \t     Validation Loss : 0.5794743632160231\n",
            "                    \t     Training Accuracy : 0.8994305555555555\n",
            "                    \t     Validation Accuracy : 0.8105441666666666\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23606258404957145\n",
            "                    \t     Validation Loss : 0.5801647285298652\n",
            "                    \t     Training Accuracy : 0.8996191135734072\n",
            "                    \t     Validation Accuracy : 0.8105365650969529\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23561033789410632\n",
            "                    \t     Validation Loss : 0.581363238117599\n",
            "                    \t     Training Accuracy : 0.8998135359116022\n",
            "                    \t     Validation Accuracy : 0.8105162983425415\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23528576573151735\n",
            "                    \t     Validation Loss : 0.5821900067662157\n",
            "                    \t     Training Accuracy : 0.8999793388429752\n",
            "                    \t     Validation Accuracy : 0.8104881542699724\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.2349101194832474\n",
            "                    \t     Validation Loss : 0.5833959276284314\n",
            "                    \t     Training Accuracy : 0.9001407967032967\n",
            "                    \t     Validation Accuracy : 0.8104648351648351\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23460037622457905\n",
            "                    \t     Validation Loss : 0.5840891071921698\n",
            "                    \t     Training Accuracy : 0.9002996575342466\n",
            "                    \t     Validation Accuracy : 0.8104402739726028\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23418481977226446\n",
            "                    \t     Validation Loss : 0.5850678760344864\n",
            "                    \t     Training Accuracy : 0.9004815573770492\n",
            "                    \t     Validation Accuracy : 0.8104322404371584\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23382257432227685\n",
            "                    \t     Validation Loss : 0.5861528495970799\n",
            "                    \t     Training Accuracy : 0.9006318119891008\n",
            "                    \t     Validation Accuracy : 0.8104190735694823\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23352835152050197\n",
            "                    \t     Validation Loss : 0.5865368491989553\n",
            "                    \t     Training Accuracy : 0.9007846467391304\n",
            "                    \t     Validation Accuracy : 0.8103975543478261\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23312282477412122\n",
            "                    \t     Validation Loss : 0.5871499137280354\n",
            "                    \t     Training Accuracy : 0.9009485094850949\n",
            "                    \t     Validation Accuracy : 0.8103845528455285\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23274489079631008\n",
            "                    \t     Validation Loss : 0.5880873854399933\n",
            "                    \t     Training Accuracy : 0.9011216216216216\n",
            "                    \t     Validation Accuracy : 0.8103502702702703\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.2324371185674234\n",
            "                    \t     Validation Loss : 0.5887583530845253\n",
            "                    \t     Training Accuracy : 0.9012533692722372\n",
            "                    \t     Validation Accuracy : 0.8103288409703504\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23205113435402558\n",
            "                    \t     Validation Loss : 0.5892539111832928\n",
            "                    \t     Training Accuracy : 0.9014314516129033\n",
            "                    \t     Validation Accuracy : 0.8103225806451613\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23175390159085157\n",
            "                    \t     Validation Loss : 0.5895736326063523\n",
            "                    \t     Training Accuracy : 0.9015650134048258\n",
            "                    \t     Validation Accuracy : 0.8103160857908848\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.2314199992553966\n",
            "                    \t     Validation Loss : 0.5896921187230515\n",
            "                    \t     Training Accuracy : 0.9017179144385027\n",
            "                    \t     Validation Accuracy : 0.8103144385026738\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.23102737918322905\n",
            "                    \t     Validation Loss : 0.5904758605648296\n",
            "                    \t     Training Accuracy : 0.9018766666666667\n",
            "                    \t     Validation Accuracy : 0.8103114666666666\n",
            "                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16"
      ],
      "metadata": {
        "id": "oqDMhDP7ALEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the paper, VGG16 achieved 0.86 accuracy on teh validation set but here we achieved 0.81:"
      ],
      "metadata": {
        "id": "2fUFFK8bnmZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('vgg16')\n",
        "\n",
        "optimizer = optim.Adam([{'params': model.feature_extractor.parameters()},\n",
        "    {'params': model.conv_auto_encoder.parameters(), 'lr' : learning_rates[str(model.name)]['CAE LR']},\n",
        "    {'params': model.classifier.parameters(), 'lr' : learning_rates[str(model.name)]['LC LR']}],\n",
        "    lr=0.0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_and_evaluate()"
      ],
      "metadata": {
        "id": "XdFQ-zCGASEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512aaa38-f379-403c-e823-69765d1c5f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.8304985892772675\n",
            "                    \t     Validation Loss : 0.6213187615330608\n",
            "                    \t     Training Accuracy : 0.556875\n",
            "                    \t     Validation Accuracy : 0.6699\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.7149149578809738\n",
            "                    \t     Validation Loss : 0.5874904777866583\n",
            "                    \t     Training Accuracy : 0.625\n",
            "                    \t     Validation Accuracy : 0.6916\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6679607278108597\n",
            "                    \t     Validation Loss : 0.5716650282866912\n",
            "                    \t     Training Accuracy : 0.649375\n",
            "                    \t     Validation Accuracy : 0.7015\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.633828731328249\n",
            "                    \t     Validation Loss : 0.5781076107971584\n",
            "                    \t     Training Accuracy : 0.67140625\n",
            "                    \t     Validation Accuracy : 0.701825\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.6064934066534042\n",
            "                    \t     Validation Loss : 0.5631413034737681\n",
            "                    \t     Training Accuracy : 0.690625\n",
            "                    \t     Validation Accuracy : 0.7136\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.58940544039011\n",
            "                    \t     Validation Loss : 0.5469579768542665\n",
            "                    \t     Training Accuracy : 0.7005208333333334\n",
            "                    \t     Validation Accuracy : 0.72525\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5727184253931046\n",
            "                    \t     Validation Loss : 0.5335133611435\n",
            "                    \t     Training Accuracy : 0.7103571428571429\n",
            "                    \t     Validation Accuracy : 0.7341571428571428\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5584000900015235\n",
            "                    \t     Validation Loss : 0.5224805984872217\n",
            "                    \t     Training Accuracy : 0.720390625\n",
            "                    \t     Validation Accuracy : 0.7413625\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5472973332471318\n",
            "                    \t     Validation Loss : 0.5186571397011611\n",
            "                    \t     Training Accuracy : 0.7272222222222222\n",
            "                    \t     Validation Accuracy : 0.7434555555555555\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5377191301882267\n",
            "                    \t     Validation Loss : 0.5123337913816348\n",
            "                    \t     Training Accuracy : 0.733875\n",
            "                    \t     Validation Accuracy : 0.74737\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5299094362963329\n",
            "                    \t     Validation Loss : 0.504752130978266\n",
            "                    \t     Training Accuracy : 0.7394318181818181\n",
            "                    \t     Validation Accuracy : 0.7522\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5256291680286328\n",
            "                    \t     Validation Loss : 0.49956220183303307\n",
            "                    \t     Training Accuracy : 0.7426041666666666\n",
            "                    \t     Validation Accuracy : 0.7555583333333333\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5199887295411183\n",
            "                    \t     Validation Loss : 0.49445015056533465\n",
            "                    \t     Training Accuracy : 0.7459134615384615\n",
            "                    \t     Validation Accuracy : 0.7589230769230769\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.513726023967777\n",
            "                    \t     Validation Loss : 0.49054758226229467\n",
            "                    \t     Training Accuracy : 0.7502678571428572\n",
            "                    \t     Validation Accuracy : 0.7616285714285714\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5084452065030733\n",
            "                    \t     Validation Loss : 0.4861739762230549\n",
            "                    \t     Training Accuracy : 0.753375\n",
            "                    \t     Validation Accuracy : 0.7643866666666667\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5048748438619077\n",
            "                    \t     Validation Loss : 0.4851386126952049\n",
            "                    \t     Training Accuracy : 0.7556640625\n",
            "                    \t     Validation Accuracy : 0.765675\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.5028951191726853\n",
            "                    \t     Validation Loss : 0.48228731187992674\n",
            "                    \t     Training Accuracy : 0.7565073529411764\n",
            "                    \t     Validation Accuracy : 0.7675823529411765\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.49995137110352517\n",
            "                    \t     Validation Loss : 0.47851906246831327\n",
            "                    \t     Training Accuracy : 0.7586805555555556\n",
            "                    \t     Validation Accuracy : 0.7697444444444445\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.49678917867572686\n",
            "                    \t     Validation Loss : 0.4752684779301078\n",
            "                    \t     Training Accuracy : 0.7602302631578948\n",
            "                    \t     Validation Accuracy : 0.7716473684210526\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.49320111678540707\n",
            "                    \t     Validation Loss : 0.47199115327562385\n",
            "                    \t     Training Accuracy : 0.7626875\n",
            "                    \t     Validation Accuracy : 0.773835\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4898420648915427\n",
            "                    \t     Validation Loss : 0.46898042390095523\n",
            "                    \t     Training Accuracy : 0.7648809523809523\n",
            "                    \t     Validation Accuracy : 0.775752380952381\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.48625650176947766\n",
            "                    \t     Validation Loss : 0.46620665643187825\n",
            "                    \t     Training Accuracy : 0.7672443181818182\n",
            "                    \t     Validation Accuracy : 0.7775545454545455\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4847071627559869\n",
            "                    \t     Validation Loss : 0.46580653605874767\n",
            "                    \t     Training Accuracy : 0.7685326086956522\n",
            "                    \t     Validation Accuracy : 0.7779\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4808423203478257\n",
            "                    \t     Validation Loss : 0.4636108986775493\n",
            "                    \t     Training Accuracy : 0.7710416666666666\n",
            "                    \t     Validation Accuracy : 0.7795458333333334\n",
            "                    \n",
            "    epoch: 1\n",
            "                    \t     Train Loss : 0.4780847423791885\n",
            "                    \t     Validation Loss : 0.4613597257087787\n",
            "                    \t     Training Accuracy : 0.772625\n",
            "                    \t     Validation Accuracy : 0.7811\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4731165604522595\n",
            "                    \t     Validation Loss : 0.45997588348186524\n",
            "                    \t     Training Accuracy : 0.7754567307692307\n",
            "                    \t     Validation Accuracy : 0.7822384615384615\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.46924280914995403\n",
            "                    \t     Validation Loss : 0.45828082524006386\n",
            "                    \t     Training Accuracy : 0.7776620370370371\n",
            "                    \t     Validation Accuracy : 0.7834333333333333\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4653791568534715\n",
            "                    \t     Validation Loss : 0.4563768752283127\n",
            "                    \t     Training Accuracy : 0.7803125\n",
            "                    \t     Validation Accuracy : 0.784525\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4614808479054221\n",
            "                    \t     Validation Loss : 0.4547457157255493\n",
            "                    \t     Training Accuracy : 0.7826939655172414\n",
            "                    \t     Validation Accuracy : 0.7854068965517241\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.45838940211137136\n",
            "                    \t     Validation Loss : 0.4531031485658865\n",
            "                    \t     Training Accuracy : 0.7848958333333333\n",
            "                    \t     Validation Accuracy : 0.7864366666666667\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4550537489306542\n",
            "                    \t     Validation Loss : 0.45136726674106725\n",
            "                    \t     Training Accuracy : 0.7869354838709678\n",
            "                    \t     Validation Accuracy : 0.7875129032258065\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4516466537863016\n",
            "                    \t     Validation Loss : 0.4524984000066218\n",
            "                    \t     Training Accuracy : 0.788984375\n",
            "                    \t     Validation Accuracy : 0.788509375\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4490041690522974\n",
            "                    \t     Validation Loss : 0.45140279548473333\n",
            "                    \t     Training Accuracy : 0.7906818181818182\n",
            "                    \t     Validation Accuracy : 0.7890151515151516\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4475160486557904\n",
            "                    \t     Validation Loss : 0.4499424138064224\n",
            "                    \t     Training Accuracy : 0.7916544117647059\n",
            "                    \t     Validation Accuracy : 0.7898735294117647\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4455122231245041\n",
            "                    \t     Validation Loss : 0.4486534801426134\n",
            "                    \t     Training Accuracy : 0.7928035714285714\n",
            "                    \t     Validation Accuracy : 0.7907171428571429\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44368777006864546\n",
            "                    \t     Validation Loss : 0.4473276101594958\n",
            "                    \t     Training Accuracy : 0.7938194444444444\n",
            "                    \t     Validation Accuracy : 0.7914055555555556\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44217950893414987\n",
            "                    \t     Validation Loss : 0.44632480085261506\n",
            "                    \t     Training Accuracy : 0.7951351351351351\n",
            "                    \t     Validation Accuracy : 0.792018918918919\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.44075029784127284\n",
            "                    \t     Validation Loss : 0.44489719250386794\n",
            "                    \t     Training Accuracy : 0.7961348684210526\n",
            "                    \t     Validation Accuracy : 0.7928026315789474\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4383662526882612\n",
            "                    \t     Validation Loss : 0.44438791455200655\n",
            "                    \t     Training Accuracy : 0.7974038461538462\n",
            "                    \t     Validation Accuracy : 0.7933025641025641\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4372478192448616\n",
            "                    \t     Validation Loss : 0.44326927763894913\n",
            "                    \t     Training Accuracy : 0.797921875\n",
            "                    \t     Validation Accuracy : 0.79399\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.434706260721858\n",
            "                    \t     Validation Loss : 0.4423880482377419\n",
            "                    \t     Training Accuracy : 0.7992987804878049\n",
            "                    \t     Validation Accuracy : 0.7946146341463415\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43333256378769874\n",
            "                    \t     Validation Loss : 0.4417639922497435\n",
            "                    \t     Training Accuracy : 0.7997916666666667\n",
            "                    \t     Validation Accuracy : 0.7950119047619048\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4318298218901767\n",
            "                    \t     Validation Loss : 0.4407660390187208\n",
            "                    \t     Training Accuracy : 0.8007267441860465\n",
            "                    \t     Validation Accuracy : 0.795746511627907\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.43008975228802726\n",
            "                    \t     Validation Loss : 0.44000657901520596\n",
            "                    \t     Training Accuracy : 0.8014914772727273\n",
            "                    \t     Validation Accuracy : 0.7962159090909091\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4292108963595496\n",
            "                    \t     Validation Loss : 0.43927581009339645\n",
            "                    \t     Training Accuracy : 0.8018611111111111\n",
            "                    \t     Validation Accuracy : 0.7967222222222222\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.42762746658662093\n",
            "                    \t     Validation Loss : 0.4388042825795136\n",
            "                    \t     Training Accuracy : 0.8027309782608696\n",
            "                    \t     Validation Accuracy : 0.7970369565217391\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.42571603926572393\n",
            "                    \t     Validation Loss : 0.43820866039483053\n",
            "                    \t     Training Accuracy : 0.8037765957446809\n",
            "                    \t     Validation Accuracy : 0.7974702127659574\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4247163539441923\n",
            "                    \t     Validation Loss : 0.4373331664207454\n",
            "                    \t     Training Accuracy : 0.8044661458333333\n",
            "                    \t     Validation Accuracy : 0.7979166666666667\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.4236609482035345\n",
            "                    \t     Validation Loss : 0.43674693917729923\n",
            "                    \t     Training Accuracy : 0.8049107142857143\n",
            "                    \t     Validation Accuracy : 0.798265306122449\n",
            "                    \n",
            "    epoch: 2\n",
            "                    \t     Train Loss : 0.42230028378367424\n",
            "                    \t     Validation Loss : 0.43604342881197367\n",
            "                    \t     Training Accuracy : 0.8057875\n",
            "                    \t     Validation Accuracy : 0.798722\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4199726083173471\n",
            "                    \t     Validation Loss : 0.4355193661528296\n",
            "                    \t     Training Accuracy : 0.807156862745098\n",
            "                    \t     Validation Accuracy : 0.7992019607843137\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.417391092771521\n",
            "                    \t     Validation Loss : 0.4354339366099866\n",
            "                    \t     Training Accuracy : 0.808641826923077\n",
            "                    \t     Validation Accuracy : 0.7995980769230769\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4149449524170947\n",
            "                    \t     Validation Loss : 0.4353286358668472\n",
            "                    \t     Training Accuracy : 0.8098938679245283\n",
            "                    \t     Validation Accuracy : 0.7999754716981132\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41240451846961623\n",
            "                    \t     Validation Loss : 0.4349381991529511\n",
            "                    \t     Training Accuracy : 0.8111921296296296\n",
            "                    \t     Validation Accuracy : 0.8001277777777778\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.41054223797538064\n",
            "                    \t     Validation Loss : 0.4346376278651097\n",
            "                    \t     Training Accuracy : 0.8121931818181818\n",
            "                    \t     Validation Accuracy : 0.8004309090909091\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4083103691839746\n",
            "                    \t     Validation Loss : 0.43428293693026876\n",
            "                    \t     Training Accuracy : 0.813359375\n",
            "                    \t     Validation Accuracy : 0.8007214285714286\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.40597325962102204\n",
            "                    \t     Validation Loss : 0.4348984489636159\n",
            "                    \t     Training Accuracy : 0.8145614035087719\n",
            "                    \t     Validation Accuracy : 0.8006438596491228\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4044846064545985\n",
            "                    \t     Validation Loss : 0.4345928138706591\n",
            "                    \t     Training Accuracy : 0.815334051724138\n",
            "                    \t     Validation Accuracy : 0.8007689655172414\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4027625749954733\n",
            "                    \t     Validation Loss : 0.4348011542279674\n",
            "                    \t     Training Accuracy : 0.8161334745762712\n",
            "                    \t     Validation Accuracy : 0.8009847457627118\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.4011345617895325\n",
            "                    \t     Validation Loss : 0.43484135488557996\n",
            "                    \t     Training Accuracy : 0.8172395833333334\n",
            "                    \t     Validation Accuracy : 0.80125\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3995690368604465\n",
            "                    \t     Validation Loss : 0.43457224566596964\n",
            "                    \t     Training Accuracy : 0.8180737704918033\n",
            "                    \t     Validation Accuracy : 0.801488524590164\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3981590718968261\n",
            "                    \t     Validation Loss : 0.43492087359892134\n",
            "                    \t     Training Accuracy : 0.8189717741935484\n",
            "                    \t     Validation Accuracy : 0.8016483870967742\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3967598229055367\n",
            "                    \t     Validation Loss : 0.43468923008074967\n",
            "                    \t     Training Accuracy : 0.8198809523809524\n",
            "                    \t     Validation Accuracy : 0.801884126984127\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3952573452447541\n",
            "                    \t     Validation Loss : 0.43430446443436577\n",
            "                    \t     Training Accuracy : 0.820869140625\n",
            "                    \t     Validation Accuracy : 0.802125\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39378676335628215\n",
            "                    \t     Validation Loss : 0.4341038712454856\n",
            "                    \t     Training Accuracy : 0.8216057692307692\n",
            "                    \t     Validation Accuracy : 0.80244\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3926718783559221\n",
            "                    \t     Validation Loss : 0.43363649929525694\n",
            "                    \t     Training Accuracy : 0.8221117424242425\n",
            "                    \t     Validation Accuracy : 0.8027575757575758\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.39131758248628074\n",
            "                    \t     Validation Loss : 0.4335814058701798\n",
            "                    \t     Training Accuracy : 0.8227891791044776\n",
            "                    \t     Validation Accuracy : 0.8030268656716418\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3903626740570454\n",
            "                    \t     Validation Loss : 0.433147148331573\n",
            "                    \t     Training Accuracy : 0.8232444852941176\n",
            "                    \t     Validation Accuracy : 0.803225\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.38919739547199095\n",
            "                    \t     Validation Loss : 0.43321556744462014\n",
            "                    \t     Training Accuracy : 0.8237952898550724\n",
            "                    \t     Validation Accuracy : 0.8034449275362319\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.38786141516694\n",
            "                    \t     Validation Loss : 0.43376658381371397\n",
            "                    \t     Training Accuracy : 0.8245446428571429\n",
            "                    \t     Validation Accuracy : 0.8036028571428572\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3871741593324802\n",
            "                    \t     Validation Loss : 0.4337861818093687\n",
            "                    \t     Training Accuracy : 0.8249647887323943\n",
            "                    \t     Validation Accuracy : 0.8037887323943662\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.38628045714770753\n",
            "                    \t     Validation Loss : 0.43385031463377993\n",
            "                    \t     Training Accuracy : 0.8254079861111111\n",
            "                    \t     Validation Accuracy : 0.8040305555555556\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3850269281292615\n",
            "                    \t     Validation Loss : 0.4334541339621413\n",
            "                    \t     Training Accuracy : 0.8260702054794521\n",
            "                    \t     Validation Accuracy : 0.8042821917808219\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.38396131120018057\n",
            "                    \t     Validation Loss : 0.4341326749761115\n",
            "                    \t     Training Accuracy : 0.8266554054054054\n",
            "                    \t     Validation Accuracy : 0.8043486486486486\n",
            "                    \n",
            "    epoch: 3\n",
            "                    \t     Train Loss : 0.3830585653980573\n",
            "                    \t     Validation Loss : 0.43419045689800423\n",
            "                    \t     Training Accuracy : 0.8271833333333334\n",
            "                    \t     Validation Accuracy : 0.8045333333333333\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3809706608862861\n",
            "                    \t     Validation Loss : 0.4341736252479003\n",
            "                    \t     Training Accuracy : 0.828264802631579\n",
            "                    \t     Validation Accuracy : 0.8046855263157895\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3789037287496514\n",
            "                    \t     Validation Loss : 0.43560003811441506\n",
            "                    \t     Training Accuracy : 0.8292775974025974\n",
            "                    \t     Validation Accuracy : 0.8046597402597403\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3769406280733454\n",
            "                    \t     Validation Loss : 0.4356258216611489\n",
            "                    \t     Training Accuracy : 0.8301442307692307\n",
            "                    \t     Validation Accuracy : 0.804876923076923\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.37507763768958896\n",
            "                    \t     Validation Loss : 0.43655209051601884\n",
            "                    \t     Training Accuracy : 0.8311471518987342\n",
            "                    \t     Validation Accuracy : 0.8049569620253164\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.373016334480606\n",
            "                    \t     Validation Loss : 0.43732325761778335\n",
            "                    \t     Training Accuracy : 0.83221875\n",
            "                    \t     Validation Accuracy : 0.80506\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3715376655380299\n",
            "                    \t     Validation Loss : 0.4380592701253757\n",
            "                    \t     Training Accuracy : 0.833070987654321\n",
            "                    \t     Validation Accuracy : 0.8050345679012346\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3696564874579994\n",
            "                    \t     Validation Loss : 0.4387283690545473\n",
            "                    \t     Training Accuracy : 0.8339100609756097\n",
            "                    \t     Validation Accuracy : 0.8051658536585365\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36785206056592695\n",
            "                    \t     Validation Loss : 0.4390927335613273\n",
            "                    \t     Training Accuracy : 0.8349472891566265\n",
            "                    \t     Validation Accuracy : 0.8052313253012048\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3664022183693236\n",
            "                    \t     Validation Loss : 0.4394530296248038\n",
            "                    \t     Training Accuracy : 0.8355952380952381\n",
            "                    \t     Validation Accuracy : 0.805222619047619\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36498237336646105\n",
            "                    \t     Validation Loss : 0.44027214254921393\n",
            "                    \t     Training Accuracy : 0.8362573529411764\n",
            "                    \t     Validation Accuracy : 0.8051129411764706\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36355794749894116\n",
            "                    \t     Validation Loss : 0.4405354968539181\n",
            "                    \t     Training Accuracy : 0.8370639534883721\n",
            "                    \t     Validation Accuracy : 0.805103488372093\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36221816238229987\n",
            "                    \t     Validation Loss : 0.44072353332717124\n",
            "                    \t     Training Accuracy : 0.8377442528735632\n",
            "                    \t     Validation Accuracy : 0.805235632183908\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.36055730412290854\n",
            "                    \t     Validation Loss : 0.44093819975884346\n",
            "                    \t     Training Accuracy : 0.8385582386363636\n",
            "                    \t     Validation Accuracy : 0.8053613636363637\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3591573116015852\n",
            "                    \t     Validation Loss : 0.4413658583070498\n",
            "                    \t     Training Accuracy : 0.8392556179775281\n",
            "                    \t     Validation Accuracy : 0.805443820224719\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.35772389871047605\n",
            "                    \t     Validation Loss : 0.44161029707932664\n",
            "                    \t     Training Accuracy : 0.84\n",
            "                    \t     Validation Accuracy : 0.8055633333333333\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3565165815657967\n",
            "                    \t     Validation Loss : 0.4417981380910718\n",
            "                    \t     Training Accuracy : 0.840679945054945\n",
            "                    \t     Validation Accuracy : 0.805656043956044\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3552858155042581\n",
            "                    \t     Validation Loss : 0.44259735397479116\n",
            "                    \t     Training Accuracy : 0.8412364130434783\n",
            "                    \t     Validation Accuracy : 0.8054195652173913\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3541928164965363\n",
            "                    \t     Validation Loss : 0.4429143194186372\n",
            "                    \t     Training Accuracy : 0.8418212365591398\n",
            "                    \t     Validation Accuracy : 0.8054881720430107\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.352990111004799\n",
            "                    \t     Validation Loss : 0.44310810371785675\n",
            "                    \t     Training Accuracy : 0.8424069148936171\n",
            "                    \t     Validation Accuracy : 0.8056414893617021\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3519367270783374\n",
            "                    \t     Validation Loss : 0.44349274096698227\n",
            "                    \t     Training Accuracy : 0.8429276315789473\n",
            "                    \t     Validation Accuracy : 0.8057252631578947\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.3509560127804677\n",
            "                    \t     Validation Loss : 0.44347328210648257\n",
            "                    \t     Training Accuracy : 0.8434244791666666\n",
            "                    \t     Validation Accuracy : 0.8058354166666667\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.34996872225833925\n",
            "                    \t     Validation Loss : 0.4437189024921023\n",
            "                    \t     Training Accuracy : 0.843930412371134\n",
            "                    \t     Validation Accuracy : 0.805939175257732\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.34881156768877897\n",
            "                    \t     Validation Loss : 0.4436969515627247\n",
            "                    \t     Training Accuracy : 0.8444961734693878\n",
            "                    \t     Validation Accuracy : 0.8060622448979592\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.34754686403455154\n",
            "                    \t     Validation Loss : 0.44458345531038124\n",
            "                    \t     Training Accuracy : 0.8451767676767676\n",
            "                    \t     Validation Accuracy : 0.8061676767676768\n",
            "                    \n",
            "    epoch: 4\n",
            "                    \t     Train Loss : 0.34678701097518205\n",
            "                    \t     Validation Loss : 0.4444344472204344\n",
            "                    \t     Training Accuracy : 0.8455875\n",
            "                    \t     Validation Accuracy : 0.806305\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3447126976717817\n",
            "                    \t     Validation Loss : 0.4456607507493402\n",
            "                    \t     Training Accuracy : 0.846615099009901\n",
            "                    \t     Validation Accuracy : 0.8064118811881188\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3427401831647491\n",
            "                    \t     Validation Loss : 0.44624423797563867\n",
            "                    \t     Training Accuracy : 0.8475551470588235\n",
            "                    \t     Validation Accuracy : 0.8064725490196079\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.341016476464286\n",
            "                    \t     Validation Loss : 0.44664043570711837\n",
            "                    \t     Training Accuracy : 0.848379854368932\n",
            "                    \t     Validation Accuracy : 0.8065669902912621\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3391941668218575\n",
            "                    \t     Validation Loss : 0.44780001951471743\n",
            "                    \t     Training Accuracy : 0.8492848557692307\n",
            "                    \t     Validation Accuracy : 0.8065788461538461\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3373664371644457\n",
            "                    \t     Validation Loss : 0.4494110686431623\n",
            "                    \t     Training Accuracy : 0.8501190476190477\n",
            "                    \t     Validation Accuracy : 0.8066714285714286\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.335705770258001\n",
            "                    \t     Validation Loss : 0.4507040772572464\n",
            "                    \t     Training Accuracy : 0.8508431603773585\n",
            "                    \t     Validation Accuracy : 0.8067471698113208\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.33430282974946446\n",
            "                    \t     Validation Loss : 0.4511370790760756\n",
            "                    \t     Training Accuracy : 0.8516530373831775\n",
            "                    \t     Validation Accuracy : 0.8068327102803738\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3329134439763234\n",
            "                    \t     Validation Loss : 0.4520485253098511\n",
            "                    \t     Training Accuracy : 0.8523032407407407\n",
            "                    \t     Validation Accuracy : 0.8068851851851851\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3313690709729397\n",
            "                    \t     Validation Loss : 0.45300099342318073\n",
            "                    \t     Training Accuracy : 0.8529816513761468\n",
            "                    \t     Validation Accuracy : 0.8068990825688074\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.32998596379397943\n",
            "                    \t     Validation Loss : 0.4536902147165364\n",
            "                    \t     Training Accuracy : 0.8536420454545455\n",
            "                    \t     Validation Accuracy : 0.8069963636363636\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3284488737197207\n",
            "                    \t     Validation Loss : 0.45445026656660953\n",
            "                    \t     Training Accuracy : 0.8543918918918919\n",
            "                    \t     Validation Accuracy : 0.8070720720720721\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3269111634281996\n",
            "                    \t     Validation Loss : 0.4553919507151054\n",
            "                    \t     Training Accuracy : 0.8551395089285714\n",
            "                    \t     Validation Accuracy : 0.8071848214285714\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.32578204648519776\n",
            "                    \t     Validation Loss : 0.45651926084813205\n",
            "                    \t     Training Accuracy : 0.8556471238938053\n",
            "                    \t     Validation Accuracy : 0.8072619469026548\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3244346059724819\n",
            "                    \t     Validation Loss : 0.4577593900404044\n",
            "                    \t     Training Accuracy : 0.8563541666666666\n",
            "                    \t     Validation Accuracy : 0.8073228070175439\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.323062777073487\n",
            "                    \t     Validation Loss : 0.45909304155262165\n",
            "                    \t     Training Accuracy : 0.857\n",
            "                    \t     Validation Accuracy : 0.8073913043478261\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.32207796958885315\n",
            "                    \t     Validation Loss : 0.4600284650566407\n",
            "                    \t     Training Accuracy : 0.8575269396551725\n",
            "                    \t     Validation Accuracy : 0.807478448275862\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3209898262935826\n",
            "                    \t     Validation Loss : 0.46043319518236836\n",
            "                    \t     Training Accuracy : 0.8581196581196581\n",
            "                    \t     Validation Accuracy : 0.8075666666666667\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3201415488389084\n",
            "                    \t     Validation Loss : 0.4606962968548576\n",
            "                    \t     Training Accuracy : 0.8585963983050847\n",
            "                    \t     Validation Accuracy : 0.8076033898305085\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.3188871688827747\n",
            "                    \t     Validation Loss : 0.4614256055647614\n",
            "                    \t     Training Accuracy : 0.8592121848739496\n",
            "                    \t     Validation Accuracy : 0.8076899159663865\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.31784235274791717\n",
            "                    \t     Validation Loss : 0.4614043235969239\n",
            "                    \t     Training Accuracy : 0.859734375\n",
            "                    \t     Validation Accuracy : 0.80776\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.31700221726840194\n",
            "                    \t     Validation Loss : 0.4614805689680234\n",
            "                    \t     Training Accuracy : 0.8601756198347107\n",
            "                    \t     Validation Accuracy : 0.8078272727272727\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.31620682427262675\n",
            "                    \t     Validation Loss : 0.4620812784829475\n",
            "                    \t     Training Accuracy : 0.8606045081967213\n",
            "                    \t     Validation Accuracy : 0.8078483606557377\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.31522425848718094\n",
            "                    \t     Validation Loss : 0.4626921226152857\n",
            "                    \t     Training Accuracy : 0.8610772357723577\n",
            "                    \t     Validation Accuracy : 0.8079406504065041\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.31410931313891083\n",
            "                    \t     Validation Loss : 0.4637334948509477\n",
            "                    \t     Training Accuracy : 0.8616381048387097\n",
            "                    \t     Validation Accuracy : 0.8079540322580645\n",
            "                    \n",
            "    epoch: 5\n",
            "                    \t     Train Loss : 0.31309879854261874\n",
            "                    \t     Validation Loss : 0.46401272774142577\n",
            "                    \t     Training Accuracy : 0.862185\n",
            "                    \t     Validation Accuracy : 0.8079776\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3113797397710501\n",
            "                    \t     Validation Loss : 0.4672043759877768\n",
            "                    \t     Training Accuracy : 0.8629613095238096\n",
            "                    \t     Validation Accuracy : 0.8079873015873016\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.309855802632047\n",
            "                    \t     Validation Loss : 0.4687434247393871\n",
            "                    \t     Training Accuracy : 0.8636860236220473\n",
            "                    \t     Validation Accuracy : 0.8080629921259842\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.30835972711633075\n",
            "                    \t     Validation Loss : 0.4703164968489723\n",
            "                    \t     Training Accuracy : 0.864404296875\n",
            "                    \t     Validation Accuracy : 0.80809921875\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.30697648697857594\n",
            "                    \t     Validation Loss : 0.47109143267815534\n",
            "                    \t     Training Accuracy : 0.8650339147286822\n",
            "                    \t     Validation Accuracy : 0.8081705426356589\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.30544740909782164\n",
            "                    \t     Validation Loss : 0.4722510839151674\n",
            "                    \t     Training Accuracy : 0.8657355769230769\n",
            "                    \t     Validation Accuracy : 0.8081592307692308\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3041144226046407\n",
            "                    \t     Validation Loss : 0.4740204884407266\n",
            "                    \t     Training Accuracy : 0.8663454198473283\n",
            "                    \t     Validation Accuracy : 0.8082229007633588\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.30280815961192165\n",
            "                    \t     Validation Loss : 0.4753084107455321\n",
            "                    \t     Training Accuracy : 0.8670217803030303\n",
            "                    \t     Validation Accuracy : 0.808219696969697\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.3014500010982016\n",
            "                    \t     Validation Loss : 0.47680846402640975\n",
            "                    \t     Training Accuracy : 0.8677114661654135\n",
            "                    \t     Validation Accuracy : 0.8083105263157895\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.30009051616115967\n",
            "                    \t     Validation Loss : 0.4789358715963177\n",
            "                    \t     Training Accuracy : 0.8683908582089552\n",
            "                    \t     Validation Accuracy : 0.8082694029850747\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2988988960456379\n",
            "                    \t     Validation Loss : 0.4799392446655167\n",
            "                    \t     Training Accuracy : 0.8689722222222223\n",
            "                    \t     Validation Accuracy : 0.8083229629629629\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2978147428345127\n",
            "                    \t     Validation Loss : 0.4808398601822198\n",
            "                    \t     Training Accuracy : 0.8694715073529412\n",
            "                    \t     Validation Accuracy : 0.8083426470588235\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.29669625333782257\n",
            "                    \t     Validation Loss : 0.4817100125058399\n",
            "                    \t     Training Accuracy : 0.8700410583941606\n",
            "                    \t     Validation Accuracy : 0.8084525547445256\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2956105058447903\n",
            "                    \t     Validation Loss : 0.48226903451056125\n",
            "                    \t     Training Accuracy : 0.8705434782608695\n",
            "                    \t     Validation Accuracy : 0.8085050724637681\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2944808959150888\n",
            "                    \t     Validation Loss : 0.483771618822295\n",
            "                    \t     Training Accuracy : 0.8710611510791367\n",
            "                    \t     Validation Accuracy : 0.8085928057553957\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2933868240926282\n",
            "                    \t     Validation Loss : 0.4843262708300851\n",
            "                    \t     Training Accuracy : 0.8715848214285714\n",
            "                    \t     Validation Accuracy : 0.8085957142857143\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.29218344119932266\n",
            "                    \t     Validation Loss : 0.4850556160441349\n",
            "                    \t     Training Accuracy : 0.8721631205673759\n",
            "                    \t     Validation Accuracy : 0.8086446808510638\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2909043878453954\n",
            "                    \t     Validation Loss : 0.48633987483481866\n",
            "                    \t     Training Accuracy : 0.8727508802816901\n",
            "                    \t     Validation Accuracy : 0.8086345070422535\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2898145820330047\n",
            "                    \t     Validation Loss : 0.4874795884607747\n",
            "                    \t     Training Accuracy : 0.8732211538461538\n",
            "                    \t     Validation Accuracy : 0.8086454545454546\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2888216671194338\n",
            "                    \t     Validation Loss : 0.48804082487393097\n",
            "                    \t     Training Accuracy : 0.8736545138888889\n",
            "                    \t     Validation Accuracy : 0.8086305555555555\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.287862534039686\n",
            "                    \t     Validation Loss : 0.48875857259352995\n",
            "                    \t     Training Accuracy : 0.8741379310344828\n",
            "                    \t     Validation Accuracy : 0.8086551724137931\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.28692881764327366\n",
            "                    \t     Validation Loss : 0.4893256847116645\n",
            "                    \t     Training Accuracy : 0.8746104452054795\n",
            "                    \t     Validation Accuracy : 0.8086808219178082\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.2858972702635972\n",
            "                    \t     Validation Loss : 0.4897589412920263\n",
            "                    \t     Training Accuracy : 0.875093537414966\n",
            "                    \t     Validation Accuracy : 0.8086952380952381\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.28494194289059\n",
            "                    \t     Validation Loss : 0.49040139376367337\n",
            "                    \t     Training Accuracy : 0.8755489864864865\n",
            "                    \t     Validation Accuracy : 0.8087168918918919\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.28385899547181226\n",
            "                    \t     Validation Loss : 0.49172684138328315\n",
            "                    \t     Training Accuracy : 0.8760360738255033\n",
            "                    \t     Validation Accuracy : 0.8087053691275168\n",
            "                    \n",
            "    epoch: 6\n",
            "                    \t     Train Loss : 0.28294958390314134\n",
            "                    \t     Validation Loss : 0.49233388203472944\n",
            "                    \t     Training Accuracy : 0.876425\n",
            "                    \t     Validation Accuracy : 0.808744\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2815785386102484\n",
            "                    \t     Validation Loss : 0.4941436880274324\n",
            "                    \t     Training Accuracy : 0.8770405629139073\n",
            "                    \t     Validation Accuracy : 0.8087635761589403\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.28034597651726617\n",
            "                    \t     Validation Loss : 0.4958334428862574\n",
            "                    \t     Training Accuracy : 0.8776274671052632\n",
            "                    \t     Validation Accuracy : 0.8088111842105263\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.27895727955742305\n",
            "                    \t     Validation Loss : 0.497908378752984\n",
            "                    \t     Training Accuracy : 0.8782434640522876\n",
            "                    \t     Validation Accuracy : 0.8088398692810458\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2777546351261485\n",
            "                    \t     Validation Loss : 0.4999429834046329\n",
            "                    \t     Training Accuracy : 0.8787905844155844\n",
            "                    \t     Validation Accuracy : 0.8088603896103896\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2764983067620666\n",
            "                    \t     Validation Loss : 0.5012255250938459\n",
            "                    \t     Training Accuracy : 0.879391129032258\n",
            "                    \t     Validation Accuracy : 0.8089032258064516\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2755242849837463\n",
            "                    \t     Validation Loss : 0.501293380566227\n",
            "                    \t     Training Accuracy : 0.8798838141025641\n",
            "                    \t     Validation Accuracy : 0.8089551282051282\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.27440771342474657\n",
            "                    \t     Validation Loss : 0.5028508001724797\n",
            "                    \t     Training Accuracy : 0.8804259554140127\n",
            "                    \t     Validation Accuracy : 0.8089675159235669\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2733209230499696\n",
            "                    \t     Validation Loss : 0.5043902241277967\n",
            "                    \t     Training Accuracy : 0.8809375\n",
            "                    \t     Validation Accuracy : 0.808909493670886\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2721998153829584\n",
            "                    \t     Validation Loss : 0.5057100411197978\n",
            "                    \t     Training Accuracy : 0.8814622641509434\n",
            "                    \t     Validation Accuracy : 0.8089377358490566\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2711526839835569\n",
            "                    \t     Validation Loss : 0.5075082533794214\n",
            "                    \t     Training Accuracy : 0.8819609375\n",
            "                    \t     Validation Accuracy : 0.808973125\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2701553181370269\n",
            "                    \t     Validation Loss : 0.5096973203195949\n",
            "                    \t     Training Accuracy : 0.882402950310559\n",
            "                    \t     Validation Accuracy : 0.8089975155279503\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2692378407653513\n",
            "                    \t     Validation Loss : 0.5105156290834524\n",
            "                    \t     Training Accuracy : 0.8828395061728395\n",
            "                    \t     Validation Accuracy : 0.8089543209876543\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2684433197827747\n",
            "                    \t     Validation Loss : 0.5116041100869525\n",
            "                    \t     Training Accuracy : 0.883194018404908\n",
            "                    \t     Validation Accuracy : 0.8089723926380368\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.26738393833145224\n",
            "                    \t     Validation Loss : 0.5127565862441407\n",
            "                    \t     Training Accuracy : 0.8836928353658536\n",
            "                    \t     Validation Accuracy : 0.8089408536585366\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.26647274466208887\n",
            "                    \t     Validation Loss : 0.5136087370826685\n",
            "                    \t     Training Accuracy : 0.8840984848484849\n",
            "                    \t     Validation Accuracy : 0.808960606060606\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.26547372434176053\n",
            "                    \t     Validation Loss : 0.5142687136416555\n",
            "                    \t     Training Accuracy : 0.8845632530120482\n",
            "                    \t     Validation Accuracy : 0.8089686746987952\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.26448262894994573\n",
            "                    \t     Validation Loss : 0.5151853173125501\n",
            "                    \t     Training Accuracy : 0.88500374251497\n",
            "                    \t     Validation Accuracy : 0.8089574850299401\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2636189007642679\n",
            "                    \t     Validation Loss : 0.518826739634796\n",
            "                    \t     Training Accuracy : 0.8853943452380952\n",
            "                    \t     Validation Accuracy : 0.8089744047619047\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.26276631643235154\n",
            "                    \t     Validation Loss : 0.5200684791429457\n",
            "                    \t     Training Accuracy : 0.8857729289940829\n",
            "                    \t     Validation Accuracy : 0.8089887573964497\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2618436170843813\n",
            "                    \t     Validation Loss : 0.5207556414343886\n",
            "                    \t     Training Accuracy : 0.8861838235294117\n",
            "                    \t     Validation Accuracy : 0.8089888235294118\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2609128783804457\n",
            "                    \t     Validation Loss : 0.5222344010904223\n",
            "                    \t     Training Accuracy : 0.8866191520467837\n",
            "                    \t     Validation Accuracy : 0.808959649122807\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2600270847774782\n",
            "                    \t     Validation Loss : 0.5233077478948467\n",
            "                    \t     Training Accuracy : 0.8870421511627907\n",
            "                    \t     Validation Accuracy : 0.8089936046511628\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.259295350054785\n",
            "                    \t     Validation Loss : 0.5236672288984571\n",
            "                    \t     Training Accuracy : 0.8873843930635839\n",
            "                    \t     Validation Accuracy : 0.8090034682080924\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.25855655214396017\n",
            "                    \t     Validation Loss : 0.5243963799772999\n",
            "                    \t     Training Accuracy : 0.8877298850574713\n",
            "                    \t     Validation Accuracy : 0.809016091954023\n",
            "                    \n",
            "    epoch: 7\n",
            "                    \t     Train Loss : 0.2576713368114616\n",
            "                    \t     Validation Loss : 0.5253364485645746\n",
            "                    \t     Training Accuracy : 0.8881357142857143\n",
            "                    \t     Validation Accuracy : 0.8090451428571429\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2565595499009545\n",
            "                    \t     Validation Loss : 0.5277624493970657\n",
            "                    \t     Training Accuracy : 0.8886150568181819\n",
            "                    \t     Validation Accuracy : 0.8090852272727272\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.25550688383373366\n",
            "                    \t     Validation Loss : 0.5292746739560562\n",
            "                    \t     Training Accuracy : 0.8890960451977401\n",
            "                    \t     Validation Accuracy : 0.8090864406779661\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.25451916745077724\n",
            "                    \t     Validation Loss : 0.5309162092422776\n",
            "                    \t     Training Accuracy : 0.8895435393258427\n",
            "                    \t     Validation Accuracy : 0.8090865168539326\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.25346079942994026\n",
            "                    \t     Validation Loss : 0.5322448693378484\n",
            "                    \t     Training Accuracy : 0.890038407821229\n",
            "                    \t     Validation Accuracy : 0.8090614525139664\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.25254830908754633\n",
            "                    \t     Validation Loss : 0.533356149741017\n",
            "                    \t     Training Accuracy : 0.8904583333333334\n",
            "                    \t     Validation Accuracy : 0.8090583333333333\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.25156751582687154\n",
            "                    \t     Validation Loss : 0.5345241599002051\n",
            "                    \t     Training Accuracy : 0.8909254143646409\n",
            "                    \t     Validation Accuracy : 0.8090806629834254\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2505977113674405\n",
            "                    \t     Validation Loss : 0.5367506868277736\n",
            "                    \t     Training Accuracy : 0.8913770604395604\n",
            "                    \t     Validation Accuracy : 0.8091021978021978\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24960242426994925\n",
            "                    \t     Validation Loss : 0.5383621248359678\n",
            "                    \t     Training Accuracy : 0.8918408469945355\n",
            "                    \t     Validation Accuracy : 0.809112568306011\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2487429043020466\n",
            "                    \t     Validation Loss : 0.5390113519635588\n",
            "                    \t     Training Accuracy : 0.8922452445652174\n",
            "                    \t     Validation Accuracy : 0.8091\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24785298182709595\n",
            "                    \t     Validation Loss : 0.5411575297027853\n",
            "                    \t     Training Accuracy : 0.8926486486486487\n",
            "                    \t     Validation Accuracy : 0.8091064864864865\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24698352024590056\n",
            "                    \t     Validation Loss : 0.5423381865308389\n",
            "                    \t     Training Accuracy : 0.8930577956989247\n",
            "                    \t     Validation Accuracy : 0.8091064516129032\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24612804233340577\n",
            "                    \t     Validation Loss : 0.5433191799398103\n",
            "                    \t     Training Accuracy : 0.8934525401069519\n",
            "                    \t     Validation Accuracy : 0.8091272727272727\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24525058578645334\n",
            "                    \t     Validation Loss : 0.5445903032518707\n",
            "                    \t     Training Accuracy : 0.8938364361702128\n",
            "                    \t     Validation Accuracy : 0.8091563829787234\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24446495137768723\n",
            "                    \t     Validation Loss : 0.5455174825099002\n",
            "                    \t     Training Accuracy : 0.8942162698412699\n",
            "                    \t     Validation Accuracy : 0.809174074074074\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2436274528416658\n",
            "                    \t     Validation Loss : 0.5464503109925389\n",
            "                    \t     Training Accuracy : 0.8945921052631579\n",
            "                    \t     Validation Accuracy : 0.8091963157894737\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2428911062970231\n",
            "                    \t     Validation Loss : 0.5473790516303975\n",
            "                    \t     Training Accuracy : 0.8949443717277487\n",
            "                    \t     Validation Accuracy : 0.809213612565445\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24214223699105786\n",
            "                    \t     Validation Loss : 0.5481563656797396\n",
            "                    \t     Training Accuracy : 0.8952799479166667\n",
            "                    \t     Validation Accuracy : 0.8092229166666667\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24131142914869433\n",
            "                    \t     Validation Loss : 0.5498551042284208\n",
            "                    \t     Training Accuracy : 0.8956832901554405\n",
            "                    \t     Validation Accuracy : 0.8092476683937824\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.24065475517307822\n",
            "                    \t     Validation Loss : 0.5506720592786893\n",
            "                    \t     Training Accuracy : 0.8960212628865979\n",
            "                    \t     Validation Accuracy : 0.8092675257731958\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.23992917263603364\n",
            "                    \t     Validation Loss : 0.5511891434430567\n",
            "                    \t     Training Accuracy : 0.8963685897435898\n",
            "                    \t     Validation Accuracy : 0.8092794871794872\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.23923599106202625\n",
            "                    \t     Validation Loss : 0.552022260706389\n",
            "                    \t     Training Accuracy : 0.8967091836734694\n",
            "                    \t     Validation Accuracy : 0.8092617346938775\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2384896897215415\n",
            "                    \t     Validation Loss : 0.5528575062041856\n",
            "                    \t     Training Accuracy : 0.8970780456852792\n",
            "                    \t     Validation Accuracy : 0.809284771573604\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.23778771958436176\n",
            "                    \t     Validation Loss : 0.5537367394305602\n",
            "                    \t     Training Accuracy : 0.8973989898989899\n",
            "                    \t     Validation Accuracy : 0.8093227272727272\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.2370591055840984\n",
            "                    \t     Validation Loss : 0.5546532613438723\n",
            "                    \t     Training Accuracy : 0.8977386934673367\n",
            "                    \t     Validation Accuracy : 0.8093226130653266\n",
            "                    \n",
            "    epoch: 8\n",
            "                    \t     Train Loss : 0.23632971146074125\n",
            "                    \t     Validation Loss : 0.5552014501071342\n",
            "                    \t     Training Accuracy : 0.898084375\n",
            "                    \t     Validation Accuracy : 0.8093555\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.23540314703466214\n",
            "                    \t     Validation Loss : 0.5570521946535207\n",
            "                    \t     Training Accuracy : 0.8984950248756219\n",
            "                    \t     Validation Accuracy : 0.8093751243781094\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2345157509701474\n",
            "                    \t     Validation Loss : 0.558623411950234\n",
            "                    \t     Training Accuracy : 0.898904702970297\n",
            "                    \t     Validation Accuracy : 0.809340099009901\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.23358612968741224\n",
            "                    \t     Validation Loss : 0.5602148374819386\n",
            "                    \t     Training Accuracy : 0.8993318965517242\n",
            "                    \t     Validation Accuracy : 0.8093536945812808\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.23267945716965616\n",
            "                    \t     Validation Loss : 0.5618996131477889\n",
            "                    \t     Training Accuracy : 0.8997426470588236\n",
            "                    \t     Validation Accuracy : 0.8093593137254902\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.23187269569130434\n",
            "                    \t     Validation Loss : 0.5625473890860128\n",
            "                    \t     Training Accuracy : 0.9001371951219512\n",
            "                    \t     Validation Accuracy : 0.8093570731707317\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2310568157389186\n",
            "                    \t     Validation Loss : 0.5635151594416392\n",
            "                    \t     Training Accuracy : 0.900503640776699\n",
            "                    \t     Validation Accuracy : 0.8093757281553398\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.23025109655040446\n",
            "                    \t     Validation Loss : 0.5652242560764619\n",
            "                    \t     Training Accuracy : 0.9008816425120773\n",
            "                    \t     Validation Accuracy : 0.8093792270531401\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22949939083161344\n",
            "                    \t     Validation Loss : 0.5665182838230357\n",
            "                    \t     Training Accuracy : 0.9011929086538462\n",
            "                    \t     Validation Accuracy : 0.8093725961538462\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2287552481155027\n",
            "                    \t     Validation Loss : 0.5673179022013473\n",
            "                    \t     Training Accuracy : 0.9015340909090909\n",
            "                    \t     Validation Accuracy : 0.8093602870813397\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22803992259670935\n",
            "                    \t     Validation Loss : 0.5683511412490534\n",
            "                    \t     Training Accuracy : 0.9018630952380953\n",
            "                    \t     Validation Accuracy : 0.8093833333333333\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2272622288528265\n",
            "                    \t     Validation Loss : 0.5694930821239289\n",
            "                    \t     Training Accuracy : 0.9022156398104265\n",
            "                    \t     Validation Accuracy : 0.8093985781990521\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22641137515976673\n",
            "                    \t     Validation Loss : 0.5714593992616525\n",
            "                    \t     Training Accuracy : 0.9025766509433962\n",
            "                    \t     Validation Accuracy : 0.8093721698113208\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22572326604871543\n",
            "                    \t     Validation Loss : 0.5731948910459982\n",
            "                    \t     Training Accuracy : 0.9028931924882629\n",
            "                    \t     Validation Accuracy : 0.8093638497652582\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22502325739720228\n",
            "                    \t     Validation Loss : 0.5741194522710094\n",
            "                    \t     Training Accuracy : 0.9032096962616822\n",
            "                    \t     Validation Accuracy : 0.809357476635514\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22431143325012784\n",
            "                    \t     Validation Loss : 0.575256453052529\n",
            "                    \t     Training Accuracy : 0.903546511627907\n",
            "                    \t     Validation Accuracy : 0.8093613953488372\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2236760020437133\n",
            "                    \t     Validation Loss : 0.5762531362729387\n",
            "                    \t     Training Accuracy : 0.9038483796296296\n",
            "                    \t     Validation Accuracy : 0.8093064814814814\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22298469758974518\n",
            "                    \t     Validation Loss : 0.5773391818730937\n",
            "                    \t     Training Accuracy : 0.9041733870967742\n",
            "                    \t     Validation Accuracy : 0.809315668202765\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22227059670318122\n",
            "                    \t     Validation Loss : 0.5786558081843118\n",
            "                    \t     Training Accuracy : 0.9045183486238532\n",
            "                    \t     Validation Accuracy : 0.8093454128440367\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22168709518636692\n",
            "                    \t     Validation Loss : 0.5793863690496838\n",
            "                    \t     Training Accuracy : 0.9048059360730594\n",
            "                    \t     Validation Accuracy : 0.8093502283105023\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22111883778127164\n",
            "                    \t     Validation Loss : 0.5807699076383803\n",
            "                    \t     Training Accuracy : 0.9050738636363637\n",
            "                    \t     Validation Accuracy : 0.809315\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.22053896023266067\n",
            "                    \t     Validation Loss : 0.581729559643542\n",
            "                    \t     Training Accuracy : 0.9053393665158371\n",
            "                    \t     Validation Accuracy : 0.8093425339366516\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2199110251746711\n",
            "                    \t     Validation Loss : 0.58303794050987\n",
            "                    \t     Training Accuracy : 0.9056193693693694\n",
            "                    \t     Validation Accuracy : 0.8093698198198198\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.2192957121772157\n",
            "                    \t     Validation Loss : 0.5838492440649965\n",
            "                    \t     Training Accuracy : 0.9059136771300449\n",
            "                    \t     Validation Accuracy : 0.8093627802690583\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.21873236331101256\n",
            "                    \t     Validation Loss : 0.5839067478438801\n",
            "                    \t     Training Accuracy : 0.9061746651785715\n",
            "                    \t     Validation Accuracy : 0.8093763392857143\n",
            "                    \n",
            "    epoch: 9\n",
            "                    \t     Train Loss : 0.21818991865695764\n",
            "                    \t     Validation Loss : 0.5845136023715487\n",
            "                    \t     Training Accuracy : 0.9064138888888889\n",
            "                    \t     Validation Accuracy : 0.8093728888888889\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21742683217432185\n",
            "                    \t     Validation Loss : 0.5860471738995021\n",
            "                    \t     Training Accuracy : 0.9067643805309734\n",
            "                    \t     Validation Accuracy : 0.8093986725663717\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21670362336852378\n",
            "                    \t     Validation Loss : 0.5879108352847262\n",
            "                    \t     Training Accuracy : 0.9071007709251101\n",
            "                    \t     Validation Accuracy : 0.8094414096916299\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21599680806220134\n",
            "                    \t     Validation Loss : 0.5897713534890486\n",
            "                    \t     Training Accuracy : 0.907406798245614\n",
            "                    \t     Validation Accuracy : 0.8094289473684211\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21537003290689016\n",
            "                    \t     Validation Loss : 0.590740295438835\n",
            "                    \t     Training Accuracy : 0.9076992358078603\n",
            "                    \t     Validation Accuracy : 0.8094737991266375\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21463147092789775\n",
            "                    \t     Validation Loss : 0.5928155130710608\n",
            "                    \t     Training Accuracy : 0.9080380434782609\n",
            "                    \t     Validation Accuracy : 0.8095017391304348\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21397909688990105\n",
            "                    \t     Validation Loss : 0.5938568374663931\n",
            "                    \t     Training Accuracy : 0.9083414502164502\n",
            "                    \t     Validation Accuracy : 0.8095125541125541\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2133275597804158\n",
            "                    \t     Validation Loss : 0.5947887966136993\n",
            "                    \t     Training Accuracy : 0.9086206896551724\n",
            "                    \t     Validation Accuracy : 0.8095435344827586\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21268389367477972\n",
            "                    \t     Validation Loss : 0.5955955303047691\n",
            "                    \t     Training Accuracy : 0.9089136266094421\n",
            "                    \t     Validation Accuracy : 0.809562660944206\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21202739068310464\n",
            "                    \t     Validation Loss : 0.5966266541894784\n",
            "                    \t     Training Accuracy : 0.9092120726495726\n",
            "                    \t     Validation Accuracy : 0.8095829059829059\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21136172742958853\n",
            "                    \t     Validation Loss : 0.5980341111085653\n",
            "                    \t     Training Accuracy : 0.9094973404255319\n",
            "                    \t     Validation Accuracy : 0.8095714893617021\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21074811486320638\n",
            "                    \t     Validation Loss : 0.5994019025592955\n",
            "                    \t     Training Accuracy : 0.9097960805084746\n",
            "                    \t     Validation Accuracy : 0.8095974576271187\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.21011674080404083\n",
            "                    \t     Validation Loss : 0.6000783563414782\n",
            "                    \t     Training Accuracy : 0.910076476793249\n",
            "                    \t     Validation Accuracy : 0.8096303797468355\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20956247204672565\n",
            "                    \t     Validation Loss : 0.6004602010597637\n",
            "                    \t     Training Accuracy : 0.9103335084033614\n",
            "                    \t     Validation Accuracy : 0.8096495798319328\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20895182691195446\n",
            "                    \t     Validation Loss : 0.600682654647424\n",
            "                    \t     Training Accuracy : 0.9106119246861925\n",
            "                    \t     Validation Accuracy : 0.8096564853556485\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2084263377679017\n",
            "                    \t     Validation Loss : 0.6010499258359415\n",
            "                    \t     Training Accuracy : 0.9108645833333333\n",
            "                    \t     Validation Accuracy : 0.8096408333333334\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20790691200006634\n",
            "                    \t     Validation Loss : 0.6018926092608163\n",
            "                    \t     Training Accuracy : 0.9111021784232365\n",
            "                    \t     Validation Accuracy : 0.8096261410788381\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20741362992031903\n",
            "                    \t     Validation Loss : 0.602764625934762\n",
            "                    \t     Training Accuracy : 0.9113326446280992\n",
            "                    \t     Validation Accuracy : 0.8096537190082644\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2068237504414465\n",
            "                    \t     Validation Loss : 0.6039461332787647\n",
            "                    \t     Training Accuracy : 0.911602366255144\n",
            "                    \t     Validation Accuracy : 0.8096580246913581\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20633490771872515\n",
            "                    \t     Validation Loss : 0.6052053327288811\n",
            "                    \t     Training Accuracy : 0.9118570696721311\n",
            "                    \t     Validation Accuracy : 0.809655737704918\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20578904728521594\n",
            "                    \t     Validation Loss : 0.6055560185315494\n",
            "                    \t     Training Accuracy : 0.9121020408163265\n",
            "                    \t     Validation Accuracy : 0.8096775510204082\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2052503245466103\n",
            "                    \t     Validation Loss : 0.6061594126893356\n",
            "                    \t     Training Accuracy : 0.9123399390243903\n",
            "                    \t     Validation Accuracy : 0.8096983739837398\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20473097349516575\n",
            "                    \t     Validation Loss : 0.6074972655951935\n",
            "                    \t     Training Accuracy : 0.9125936234817814\n",
            "                    \t     Validation Accuracy : 0.8097161943319838\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20416823308092014\n",
            "                    \t     Validation Loss : 0.6084290834465277\n",
            "                    \t     Training Accuracy : 0.9128377016129032\n",
            "                    \t     Validation Accuracy : 0.8097334677419354\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.2036225692865188\n",
            "                    \t     Validation Loss : 0.6091543468753237\n",
            "                    \t     Training Accuracy : 0.9130873493975904\n",
            "                    \t     Validation Accuracy : 0.8097196787148594\n",
            "                    \n",
            "    epoch: 10\n",
            "                    \t     Train Loss : 0.20312102581577376\n",
            "                    \t     Validation Loss : 0.6101268489145504\n",
            "                    \t     Training Accuracy : 0.9133125\n",
            "                    \t     Validation Accuracy : 0.809732\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.20252809263578433\n",
            "                    \t     Validation Loss : 0.6112849311963814\n",
            "                    \t     Training Accuracy : 0.913578187250996\n",
            "                    \t     Validation Accuracy : 0.8097366533864542\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.20192820541594142\n",
            "                    \t     Validation Loss : 0.611825029905306\n",
            "                    \t     Training Accuracy : 0.9138541666666666\n",
            "                    \t     Validation Accuracy : 0.8097345238095238\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.20135896083074503\n",
            "                    \t     Validation Loss : 0.6130106243741926\n",
            "                    \t     Training Accuracy : 0.9141180830039526\n",
            "                    \t     Validation Accuracy : 0.809690513833992\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.2008083560827805\n",
            "                    \t     Validation Loss : 0.6141156119905772\n",
            "                    \t     Training Accuracy : 0.9143700787401575\n",
            "                    \t     Validation Accuracy : 0.809692125984252\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.20026269183955017\n",
            "                    \t     Validation Loss : 0.614795557980057\n",
            "                    \t     Training Accuracy : 0.9146200980392157\n",
            "                    \t     Validation Accuracy : 0.8096819607843138\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19968759148575146\n",
            "                    \t     Validation Loss : 0.6157501134617319\n",
            "                    \t     Training Accuracy : 0.9148828125\n",
            "                    \t     Validation Accuracy : 0.809674609375\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19932244670210209\n",
            "                    \t     Validation Loss : 0.6161489716753045\n",
            "                    \t     Training Accuracy : 0.915102140077821\n",
            "                    \t     Validation Accuracy : 0.8096910505836575\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19878263855294112\n",
            "                    \t     Validation Loss : 0.6173880438392396\n",
            "                    \t     Training Accuracy : 0.9153512596899225\n",
            "                    \t     Validation Accuracy : 0.8096914728682171\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19831600251444662\n",
            "                    \t     Validation Loss : 0.6179187621056852\n",
            "                    \t     Training Accuracy : 0.9155598455598456\n",
            "                    \t     Validation Accuracy : 0.8096907335907336\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.1977859509385867\n",
            "                    \t     Validation Loss : 0.6187488435198246\n",
            "                    \t     Training Accuracy : 0.9158052884615384\n",
            "                    \t     Validation Accuracy : 0.8096834615384615\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19729979349782653\n",
            "                    \t     Validation Loss : 0.619314525220641\n",
            "                    \t     Training Accuracy : 0.9160320881226054\n",
            "                    \t     Validation Accuracy : 0.8097111111111112\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19675812254636504\n",
            "                    \t     Validation Loss : 0.6203830229690325\n",
            "                    \t     Training Accuracy : 0.9162595419847328\n",
            "                    \t     Validation Accuracy : 0.8097202290076336\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19625222719378704\n",
            "                    \t     Validation Loss : 0.6214646523054526\n",
            "                    \t     Training Accuracy : 0.9164686311787072\n",
            "                    \t     Validation Accuracy : 0.8097330798479088\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19573492379733634\n",
            "                    \t     Validation Loss : 0.6222393150152344\n",
            "                    \t     Training Accuracy : 0.916690340909091\n",
            "                    \t     Validation Accuracy : 0.8097583333333334\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19518549588610384\n",
            "                    \t     Validation Loss : 0.6232042945952299\n",
            "                    \t     Training Accuracy : 0.9169528301886792\n",
            "                    \t     Validation Accuracy : 0.8097754716981133\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19471604834464326\n",
            "                    \t     Validation Loss : 0.6241911555968462\n",
            "                    \t     Training Accuracy : 0.9171804511278195\n",
            "                    \t     Validation Accuracy : 0.8097827067669173\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19422769843444163\n",
            "                    \t     Validation Loss : 0.6246948429474485\n",
            "                    \t     Training Accuracy : 0.9174133895131086\n",
            "                    \t     Validation Accuracy : 0.8098078651685393\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19374679813116752\n",
            "                    \t     Validation Loss : 0.625418121838277\n",
            "                    \t     Training Accuracy : 0.9176236007462687\n",
            "                    \t     Validation Accuracy : 0.8098287313432836\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19331300918497993\n",
            "                    \t     Validation Loss : 0.6257445549289121\n",
            "                    \t     Training Accuracy : 0.9178252788104089\n",
            "                    \t     Validation Accuracy : 0.8098475836431227\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.1928414286058784\n",
            "                    \t     Validation Loss : 0.6263379819912358\n",
            "                    \t     Training Accuracy : 0.9180486111111111\n",
            "                    \t     Validation Accuracy : 0.8098566666666667\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.1923334634523861\n",
            "                    \t     Validation Loss : 0.6271629581986281\n",
            "                    \t     Training Accuracy : 0.9182749077490775\n",
            "                    \t     Validation Accuracy : 0.8098575645756457\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19188664889651752\n",
            "                    \t     Validation Loss : 0.6279218800335535\n",
            "                    \t     Training Accuracy : 0.9184788602941176\n",
            "                    \t     Validation Accuracy : 0.8098650735294117\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.1913754248117982\n",
            "                    \t     Validation Loss : 0.62859157751474\n",
            "                    \t     Training Accuracy : 0.9187065018315018\n",
            "                    \t     Validation Accuracy : 0.809884249084249\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19088174262214502\n",
            "                    \t     Validation Loss : 0.629422459021921\n",
            "                    \t     Training Accuracy : 0.9189324817518248\n",
            "                    \t     Validation Accuracy : 0.809887591240876\n",
            "                    \n",
            "    epoch: 11\n",
            "                    \t     Train Loss : 0.19038341939442113\n",
            "                    \t     Validation Loss : 0.6304915006135028\n",
            "                    \t     Training Accuracy : 0.9191545454545454\n",
            "                    \t     Validation Accuracy : 0.8098996363636364\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18982459518909361\n",
            "                    \t     Validation Loss : 0.6322565377937983\n",
            "                    \t     Training Accuracy : 0.9193976449275363\n",
            "                    \t     Validation Accuracy : 0.8098771739130435\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18934385397791945\n",
            "                    \t     Validation Loss : 0.6332514620702957\n",
            "                    \t     Training Accuracy : 0.9196119133574007\n",
            "                    \t     Validation Accuracy : 0.8098772563176895\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18883657560332237\n",
            "                    \t     Validation Loss : 0.6343014303668123\n",
            "                    \t     Training Accuracy : 0.9198313848920864\n",
            "                    \t     Validation Accuracy : 0.8098805755395684\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18834425045133632\n",
            "                    \t     Validation Loss : 0.6353132874056404\n",
            "                    \t     Training Accuracy : 0.9200403225806452\n",
            "                    \t     Validation Accuracy : 0.8098917562724014\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.1878097341875764\n",
            "                    \t     Validation Loss : 0.6371059349119164\n",
            "                    \t     Training Accuracy : 0.92028125\n",
            "                    \t     Validation Accuracy : 0.8098889285714286\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18735363815943842\n",
            "                    \t     Validation Loss : 0.6376363315320488\n",
            "                    \t     Training Accuracy : 0.9204848754448398\n",
            "                    \t     Validation Accuracy : 0.8098665480427046\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.1868702458527314\n",
            "                    \t     Validation Loss : 0.6392826659182137\n",
            "                    \t     Training Accuracy : 0.9206892730496454\n",
            "                    \t     Validation Accuracy : 0.8098524822695036\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18644797258719542\n",
            "                    \t     Validation Loss : 0.6398335295949198\n",
            "                    \t     Training Accuracy : 0.9208833922261485\n",
            "                    \t     Validation Accuracy : 0.8098519434628976\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18597004418456878\n",
            "                    \t     Validation Loss : 0.641340788347329\n",
            "                    \t     Training Accuracy : 0.9210717429577465\n",
            "                    \t     Validation Accuracy : 0.8098475352112676\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18547393857584368\n",
            "                    \t     Validation Loss : 0.6422104206635899\n",
            "                    \t     Training Accuracy : 0.9212828947368421\n",
            "                    \t     Validation Accuracy : 0.809840350877193\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18501643917542862\n",
            "                    \t     Validation Loss : 0.6429373301951751\n",
            "                    \t     Training Accuracy : 0.9214947552447552\n",
            "                    \t     Validation Accuracy : 0.8098356643356643\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18459758828595307\n",
            "                    \t     Validation Loss : 0.6436746814178562\n",
            "                    \t     Training Accuracy : 0.9216877177700349\n",
            "                    \t     Validation Accuracy : 0.8098372822299652\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.1842929112111839\n",
            "                    \t     Validation Loss : 0.6463830563966926\n",
            "                    \t     Training Accuracy : 0.9218402777777778\n",
            "                    \t     Validation Accuracy : 0.8098086805555555\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18394374116546244\n",
            "                    \t     Validation Loss : 0.6477186917690836\n",
            "                    \t     Training Accuracy : 0.921996107266436\n",
            "                    \t     Validation Accuracy : 0.8098076124567474\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.1835858472176699\n",
            "                    \t     Validation Loss : 0.6483694903704383\n",
            "                    \t     Training Accuracy : 0.9221681034482758\n",
            "                    \t     Validation Accuracy : 0.8098313793103449\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18331622104450127\n",
            "                    \t     Validation Loss : 0.6489907347644431\n",
            "                    \t     Training Accuracy : 0.922321735395189\n",
            "                    \t     Validation Accuracy : 0.809853264604811\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18294657418534657\n",
            "                    \t     Validation Loss : 0.6495033783285531\n",
            "                    \t     Training Accuracy : 0.922476455479452\n",
            "                    \t     Validation Accuracy : 0.8098582191780822\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18255952202954961\n",
            "                    \t     Validation Loss : 0.6503723439801523\n",
            "                    \t     Training Accuracy : 0.9226535836177474\n",
            "                    \t     Validation Accuracy : 0.8098573378839591\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18214362801527795\n",
            "                    \t     Validation Loss : 0.6510507995941432\n",
            "                    \t     Training Accuracy : 0.9228422619047619\n",
            "                    \t     Validation Accuracy : 0.8098734693877551\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18177038904194232\n",
            "                    \t     Validation Loss : 0.651937022254903\n",
            "                    \t     Training Accuracy : 0.9230275423728813\n",
            "                    \t     Validation Accuracy : 0.8098888135593221\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18135314650224785\n",
            "                    \t     Validation Loss : 0.6521301031653564\n",
            "                    \t     Training Accuracy : 0.9232200168918919\n",
            "                    \t     Validation Accuracy : 0.8098945945945946\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.1809697080204602\n",
            "                    \t     Validation Loss : 0.6525052156746936\n",
            "                    \t     Training Accuracy : 0.9233880471380471\n",
            "                    \t     Validation Accuracy : 0.8099171717171717\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18060263686371192\n",
            "                    \t     Validation Loss : 0.6528729770440331\n",
            "                    \t     Training Accuracy : 0.9235486577181208\n",
            "                    \t     Validation Accuracy : 0.8099385906040268\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.18019727000764207\n",
            "                    \t     Validation Loss : 0.6532636573929375\n",
            "                    \t     Training Accuracy : 0.9237290969899665\n",
            "                    \t     Validation Accuracy : 0.8099491638795987\n",
            "                    \n",
            "    epoch: 12\n",
            "                    \t     Train Loss : 0.17980319757061078\n",
            "                    \t     Validation Loss : 0.654810630484257\n",
            "                    \t     Training Accuracy : 0.9239145833333333\n",
            "                    \t     Validation Accuracy : 0.809973\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17934094770942707\n",
            "                    \t     Validation Loss : 0.6559428019779698\n",
            "                    \t     Training Accuracy : 0.924125830564784\n",
            "                    \t     Validation Accuracy : 0.8099744186046511\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17894557564505179\n",
            "                    \t     Validation Loss : 0.6562393490690748\n",
            "                    \t     Training Accuracy : 0.924310844370861\n",
            "                    \t     Validation Accuracy : 0.8099562913907284\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1785094588051718\n",
            "                    \t     Validation Loss : 0.6571563534544038\n",
            "                    \t     Training Accuracy : 0.9245070132013201\n",
            "                    \t     Validation Accuracy : 0.8099798679867987\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1780540417432243\n",
            "                    \t     Validation Loss : 0.6583099073736047\n",
            "                    \t     Training Accuracy : 0.9247018914473685\n",
            "                    \t     Validation Accuracy : 0.8099871710526316\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17763140200411418\n",
            "                    \t     Validation Loss : 0.6594146668664358\n",
            "                    \t     Training Accuracy : 0.9248913934426229\n",
            "                    \t     Validation Accuracy : 0.8100108196721312\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17718452086967124\n",
            "                    \t     Validation Loss : 0.6598429736161858\n",
            "                    \t     Training Accuracy : 0.9250919117647058\n",
            "                    \t     Validation Accuracy : 0.810028431372549\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17682482819383563\n",
            "                    \t     Validation Loss : 0.6608699509616118\n",
            "                    \t     Training Accuracy : 0.9252483713355049\n",
            "                    \t     Validation Accuracy : 0.8100332247557003\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17642153699538468\n",
            "                    \t     Validation Loss : 0.6617041505483842\n",
            "                    \t     Training Accuracy : 0.9254403409090909\n",
            "                    \t     Validation Accuracy : 0.810049025974026\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1759731948571809\n",
            "                    \t     Validation Loss : 0.6630928604826271\n",
            "                    \t     Training Accuracy : 0.9256290453074434\n",
            "                    \t     Validation Accuracy : 0.8100569579288026\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17557833562787123\n",
            "                    \t     Validation Loss : 0.6637781195220834\n",
            "                    \t     Training Accuracy : 0.9258004032258065\n",
            "                    \t     Validation Accuracy : 0.8100635483870968\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1751347246374873\n",
            "                    \t     Validation Loss : 0.6663454984939426\n",
            "                    \t     Training Accuracy : 0.9259807073954984\n",
            "                    \t     Validation Accuracy : 0.8100299035369775\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17472608247327745\n",
            "                    \t     Validation Loss : 0.6671727373290822\n",
            "                    \t     Training Accuracy : 0.9261578525641025\n",
            "                    \t     Validation Accuracy : 0.8100439102564102\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1743443705226708\n",
            "                    \t     Validation Loss : 0.669739784864066\n",
            "                    \t     Training Accuracy : 0.9263338658146965\n",
            "                    \t     Validation Accuracy : 0.8100568690095846\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17415576287244863\n",
            "                    \t     Validation Loss : 0.6698183648267251\n",
            "                    \t     Training Accuracy : 0.9264609872611465\n",
            "                    \t     Validation Accuracy : 0.8100735668789809\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1738018939040152\n",
            "                    \t     Validation Loss : 0.6700629148321516\n",
            "                    \t     Training Accuracy : 0.9266289682539682\n",
            "                    \t     Validation Accuracy : 0.81008\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1734761817376448\n",
            "                    \t     Validation Loss : 0.6705058880170506\n",
            "                    \t     Training Accuracy : 0.9267741297468355\n",
            "                    \t     Validation Accuracy : 0.8100981012658228\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17313625133191754\n",
            "                    \t     Validation Loss : 0.6709844258361645\n",
            "                    \t     Training Accuracy : 0.9269361198738171\n",
            "                    \t     Validation Accuracy : 0.8101154574132492\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1727866036114153\n",
            "                    \t     Validation Loss : 0.6719976763115069\n",
            "                    \t     Training Accuracy : 0.9270872641509434\n",
            "                    \t     Validation Accuracy : 0.8101050314465409\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17245931235472411\n",
            "                    \t     Validation Loss : 0.6725355562011106\n",
            "                    \t     Training Accuracy : 0.927237460815047\n",
            "                    \t     Validation Accuracy : 0.8101297805642633\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17213403472345545\n",
            "                    \t     Validation Loss : 0.6728280076259984\n",
            "                    \t     Training Accuracy : 0.927384765625\n",
            "                    \t     Validation Accuracy : 0.810120625\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17174950913981352\n",
            "                    \t     Validation Loss : 0.6732876822596194\n",
            "                    \t     Training Accuracy : 0.9275545171339564\n",
            "                    \t     Validation Accuracy : 0.8101380062305296\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1714064779806774\n",
            "                    \t     Validation Loss : 0.6735520681224832\n",
            "                    \t     Training Accuracy : 0.9277057453416149\n",
            "                    \t     Validation Accuracy : 0.8101552795031056\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17106249714235364\n",
            "                    \t     Validation Loss : 0.6741134075908682\n",
            "                    \t     Training Accuracy : 0.9278560371517028\n",
            "                    \t     Validation Accuracy : 0.8101640866873066\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.1707334068682978\n",
            "                    \t     Validation Loss : 0.6742323369666411\n",
            "                    \t     Training Accuracy : 0.9279976851851852\n",
            "                    \t     Validation Accuracy : 0.8101771604938272\n",
            "                    \n",
            "    epoch: 13\n",
            "                    \t     Train Loss : 0.17034763022502794\n",
            "                    \t     Validation Loss : 0.675553406288943\n",
            "                    \t     Training Accuracy : 0.9281692307692307\n",
            "                    \t     Validation Accuracy : 0.8101830769230769\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.17002052046039245\n",
            "                    \t     Validation Loss : 0.6759207165409409\n",
            "                    \t     Training Accuracy : 0.9283243865030675\n",
            "                    \t     Validation Accuracy : 0.8101969325153374\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1696212756813499\n",
            "                    \t     Validation Loss : 0.676689423499844\n",
            "                    \t     Training Accuracy : 0.9284881498470948\n",
            "                    \t     Validation Accuracy : 0.8102033639143731\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16923572789151034\n",
            "                    \t     Validation Loss : 0.6777000452626322\n",
            "                    \t     Training Accuracy : 0.928656631097561\n",
            "                    \t     Validation Accuracy : 0.8102146341463414\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1688506554039986\n",
            "                    \t     Validation Loss : 0.6789384360361875\n",
            "                    \t     Training Accuracy : 0.9288316869300912\n",
            "                    \t     Validation Accuracy : 0.8102300911854103\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16844540321152696\n",
            "                    \t     Validation Loss : 0.6797945443264003\n",
            "                    \t     Training Accuracy : 0.929\n",
            "                    \t     Validation Accuracy : 0.810240303030303\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16802851103617703\n",
            "                    \t     Validation Loss : 0.6812146686700308\n",
            "                    \t     Training Accuracy : 0.9291729607250755\n",
            "                    \t     Validation Accuracy : 0.8102546827794562\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16760706168528858\n",
            "                    \t     Validation Loss : 0.6827675883922509\n",
            "                    \t     Training Accuracy : 0.9293524096385543\n",
            "                    \t     Validation Accuracy : 0.8102373493975904\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16725700152575304\n",
            "                    \t     Validation Loss : 0.6834718625044531\n",
            "                    \t     Training Accuracy : 0.9295026276276276\n",
            "                    \t     Validation Accuracy : 0.8102306306306306\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16688571067541488\n",
            "                    \t     Validation Loss : 0.6848743528144988\n",
            "                    \t     Training Accuracy : 0.9296706586826348\n",
            "                    \t     Validation Accuracy : 0.8102544910179641\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1665703422382479\n",
            "                    \t     Validation Loss : 0.68536983532923\n",
            "                    \t     Training Accuracy : 0.9298134328358209\n",
            "                    \t     Validation Accuracy : 0.8102698507462687\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16623706491680423\n",
            "                    \t     Validation Loss : 0.6859004901795469\n",
            "                    \t     Training Accuracy : 0.9299627976190477\n",
            "                    \t     Validation Accuracy : 0.8102741071428572\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16587312080868805\n",
            "                    \t     Validation Loss : 0.6865139825687753\n",
            "                    \t     Training Accuracy : 0.930129821958457\n",
            "                    \t     Validation Accuracy : 0.8102896142433235\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16551907162504156\n",
            "                    \t     Validation Loss : 0.6872554249758824\n",
            "                    \t     Training Accuracy : 0.9302847633136094\n",
            "                    \t     Validation Accuracy : 0.810296449704142\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1651714231432675\n",
            "                    \t     Validation Loss : 0.6879811467309006\n",
            "                    \t     Training Accuracy : 0.9304351032448378\n",
            "                    \t     Validation Accuracy : 0.8103212389380531\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1648563849532297\n",
            "                    \t     Validation Loss : 0.6883414777376988\n",
            "                    \t     Training Accuracy : 0.9305772058823529\n",
            "                    \t     Validation Accuracy : 0.8103326470588236\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16452745887910306\n",
            "                    \t     Validation Loss : 0.6884679604723555\n",
            "                    \t     Training Accuracy : 0.9307349706744869\n",
            "                    \t     Validation Accuracy : 0.8103428152492669\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16418429452083017\n",
            "                    \t     Validation Loss : 0.6890639445054685\n",
            "                    \t     Training Accuracy : 0.9308881578947369\n",
            "                    \t     Validation Accuracy : 0.8103587719298245\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16387529459154643\n",
            "                    \t     Validation Loss : 0.6894759974951731\n",
            "                    \t     Training Accuracy : 0.9310258746355685\n",
            "                    \t     Validation Accuracy : 0.8103752186588922\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16352927572150336\n",
            "                    \t     Validation Loss : 0.6900783888044189\n",
            "                    \t     Training Accuracy : 0.9311627906976744\n",
            "                    \t     Validation Accuracy : 0.8103848837209302\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16316243207939407\n",
            "                    \t     Validation Loss : 0.691049270266796\n",
            "                    \t     Training Accuracy : 0.9313260869565217\n",
            "                    \t     Validation Accuracy : 0.8103863768115942\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16279512404755728\n",
            "                    \t     Validation Loss : 0.6924735522901938\n",
            "                    \t     Training Accuracy : 0.9314794075144509\n",
            "                    \t     Validation Accuracy : 0.8104023121387284\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16255034267578458\n",
            "                    \t     Validation Loss : 0.6926384147436787\n",
            "                    \t     Training Accuracy : 0.9315940201729107\n",
            "                    \t     Validation Accuracy : 0.8104268011527378\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.1622253578460736\n",
            "                    \t     Validation Loss : 0.6930760562290681\n",
            "                    \t     Training Accuracy : 0.9317385057471265\n",
            "                    \t     Validation Accuracy : 0.810442816091954\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.16189913866525021\n",
            "                    \t     Validation Loss : 0.6939757052335892\n",
            "                    \t     Training Accuracy : 0.9318803724928367\n",
            "                    \t     Validation Accuracy : 0.8104495702005731\n",
            "                    \n",
            "    epoch: 14\n",
            "                    \t     Train Loss : 0.161560495392372\n",
            "                    \t     Validation Loss : 0.6951163097973259\n",
            "                    \t     Training Accuracy : 0.9320339285714285\n",
            "                    \t     Validation Accuracy : 0.8104582857142857\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.16124354350701944\n",
            "                    \t     Validation Loss : 0.6958705033182726\n",
            "                    \t     Training Accuracy : 0.9321812678062678\n",
            "                    \t     Validation Accuracy : 0.8104643874643874\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.16088480260601418\n",
            "                    \t     Validation Loss : 0.6967114793715953\n",
            "                    \t     Training Accuracy : 0.9323401988636364\n",
            "                    \t     Validation Accuracy : 0.8104798295454545\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.16054698406256226\n",
            "                    \t     Validation Loss : 0.6979597802525664\n",
            "                    \t     Training Accuracy : 0.9324929178470255\n",
            "                    \t     Validation Accuracy : 0.8104813031161473\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1602432471882191\n",
            "                    \t     Validation Loss : 0.6988750412110291\n",
            "                    \t     Training Accuracy : 0.9326288841807909\n",
            "                    \t     Validation Accuracy : 0.810495197740113\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15991172555010705\n",
            "                    \t     Validation Loss : 0.6992033721318479\n",
            "                    \t     Training Accuracy : 0.9327799295774648\n",
            "                    \t     Validation Accuracy : 0.8105047887323944\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15958302799519167\n",
            "                    \t     Validation Loss : 0.699854497817997\n",
            "                    \t     Training Accuracy : 0.9329213483146067\n",
            "                    \t     Validation Accuracy : 0.810514606741573\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15927849060531424\n",
            "                    \t     Validation Loss : 0.6999292297547667\n",
            "                    \t     Training Accuracy : 0.9330584733893558\n",
            "                    \t     Validation Accuracy : 0.8105201680672269\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15895532743088714\n",
            "                    \t     Validation Loss : 0.7007909202252052\n",
            "                    \t     Training Accuracy : 0.9331965782122905\n",
            "                    \t     Validation Accuracy : 0.8105421787709497\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1586549678066926\n",
            "                    \t     Validation Loss : 0.7013325310589063\n",
            "                    \t     Training Accuracy : 0.9333234679665738\n",
            "                    \t     Validation Accuracy : 0.8105481894150418\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15830887412370795\n",
            "                    \t     Validation Loss : 0.7023058420185854\n",
            "                    \t     Training Accuracy : 0.9334774305555555\n",
            "                    \t     Validation Accuracy : 0.8105475\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15799813828301512\n",
            "                    \t     Validation Loss : 0.7030425869309326\n",
            "                    \t     Training Accuracy : 0.9336114958448753\n",
            "                    \t     Validation Accuracy : 0.8105601108033241\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15766407404774693\n",
            "                    \t     Validation Loss : 0.7038785360648556\n",
            "                    \t     Training Accuracy : 0.9337620856353591\n",
            "                    \t     Validation Accuracy : 0.8105828729281768\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15736657997625916\n",
            "                    \t     Validation Loss : 0.7039664174301635\n",
            "                    \t     Training Accuracy : 0.9338946280991736\n",
            "                    \t     Validation Accuracy : 0.8105873278236915\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15707701651156789\n",
            "                    \t     Validation Loss : 0.7045048564081692\n",
            "                    \t     Training Accuracy : 0.9340247252747252\n",
            "                    \t     Validation Accuracy : 0.8105777472527472\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.1568230291366799\n",
            "                    \t     Validation Loss : 0.7051127705052139\n",
            "                    \t     Training Accuracy : 0.9341575342465753\n",
            "                    \t     Validation Accuracy : 0.8105906849315069\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15647157239656664\n",
            "                    \t     Validation Loss : 0.7064549983777687\n",
            "                    \t     Training Accuracy : 0.9343101092896174\n",
            "                    \t     Validation Accuracy : 0.8105860655737704\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15620901939505696\n",
            "                    \t     Validation Loss : 0.7063178168928284\n",
            "                    \t     Training Accuracy : 0.934432901907357\n",
            "                    \t     Validation Accuracy : 0.8105882833787466\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15590646704839736\n",
            "                    \t     Validation Loss : 0.7076847938440894\n",
            "                    \t     Training Accuracy : 0.9345720108695652\n",
            "                    \t     Validation Accuracy : 0.8106054347826087\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15565686582604618\n",
            "                    \t     Validation Loss : 0.7078531272417466\n",
            "                    \t     Training Accuracy : 0.9346764905149052\n",
            "                    \t     Validation Accuracy : 0.8106037940379404\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15537717470116175\n",
            "                    \t     Validation Loss : 0.7084100030278649\n",
            "                    \t     Training Accuracy : 0.9348125\n",
            "                    \t     Validation Accuracy : 0.8106121621621621\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15512418656455648\n",
            "                    \t     Validation Loss : 0.708976209845137\n",
            "                    \t     Training Accuracy : 0.9349191374663073\n",
            "                    \t     Validation Accuracy : 0.8106153638814017\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15487907313268962\n",
            "                    \t     Validation Loss : 0.7098503167832952\n",
            "                    \t     Training Accuracy : 0.9350336021505377\n",
            "                    \t     Validation Accuracy : 0.8105841397849463\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15463883284610855\n",
            "                    \t     Validation Loss : 0.7101577336735392\n",
            "                    \t     Training Accuracy : 0.9351407506702413\n",
            "                    \t     Validation Accuracy : 0.8105908847184986\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15436290204104544\n",
            "                    \t     Validation Loss : 0.7104715291467234\n",
            "                    \t     Training Accuracy : 0.9352590240641712\n",
            "                    \t     Validation Accuracy : 0.8106061497326204\n",
            "                    \n",
            "    epoch: 15\n",
            "                    \t     Train Loss : 0.15414447860330732\n",
            "                    \t     Validation Loss : 0.7109511025344062\n",
            "                    \t     Training Accuracy : 0.9353716666666667\n",
            "                    \t     Validation Accuracy : 0.8106218666666667\n",
            "                    \n"
          ]
        }
      ]
    }
  ]
}